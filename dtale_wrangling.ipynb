{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74f7d4b3",
   "metadata": {},
   "source": [
    "# Housing Market Analysis: London Case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2421c452",
   "metadata": {},
   "source": [
    "Description: Historical prices, sales, crimes, resident satisfaction and salaries by borough."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2076c95",
   "metadata": {},
   "source": [
    "## Content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a49c690",
   "metadata": {},
   "source": [
    "[The datasets](https://www.kaggle.com/datasets/justinas/housing-in-london) is primarily centered around the housing market of London. However, it contains a lot of additional relevant data:\n",
    "\n",
    "- Monthly average house prices\n",
    "- Yearly number of houses\n",
    "- Yearly number of houses sold\n",
    "- Yearly percentage of households that recycle\n",
    "- Yearly life satisfaction\n",
    "- Yearly median salary of the residents of the area\n",
    "- Yearly mean salary of the residents of the area\n",
    "- Monthly number of crimes committed\n",
    "- Yearly number of jobs\n",
    "- Yearly number of people living in the area\n",
    "- Area size in hectares\n",
    "\n",
    "The data is split by areas of London called boroughs (a flag exists to identify these), but some of the variables have other geographical UK regions for reference (like England, North East, etc.). There have been no changes made to the data except for melting it into a long format from the original tables.\n",
    "\n",
    "#### DataFrames\n",
    "- df: main dataframe\n",
    "- london_df: london boroughs\n",
    "- region_df: regions of UK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa342b2",
   "metadata": {},
   "source": [
    "## Package Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be12d497",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install dtale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0262cd",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08202b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dtale\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8567dbae",
   "metadata": {},
   "source": [
    "## Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fa40a0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"housing_in_london_yearly_variables.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658a8abf",
   "metadata": {},
   "source": [
    "## View & Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a6d355b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iremkurt/anaconda3/lib/python3.11/site-packages/dtale/views.py:778: FutureWarning:\n",
      "\n",
      "['recycling_pct'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"475\"\n",
       "            src=\"http://Irem-MacBook-Air.local:40000/dtale/iframe/2\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x13b6860d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtale.show(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1254fc94",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5d5e54c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "code                   0\n",
       "area                   0\n",
       "date                   0\n",
       "median_salary         22\n",
       "life_satisfaction    719\n",
       "mean_salary            0\n",
       "recycling_pct        211\n",
       "population_size       53\n",
       "number_of_jobs       140\n",
       "area_size            405\n",
       "no_of_houses         405\n",
       "borough_flag           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of missing rows\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1daed9d",
   "metadata": {},
   "source": [
    "### Median Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7358bd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean of \"median_salary\" column\n",
    "median_salary_mean = df[\"median_salary\"].mean()\n",
    "\n",
    "# Fill null values with the mean\n",
    "df[\"median_salary\"].fillna(median_salary_mean, inplace=True)\n",
    "\n",
    "# Calculate the total number of null values in \"median_salary\" column\n",
    "median_salary_null_count = df[\"median_salary\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e979c6",
   "metadata": {},
   "source": [
    "### Life Satisfaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "64f9b60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total number of null values in \"life_satisfaction\" column\n",
    "life_satisfaction_null_count = df[\"life_satisfaction\"].isnull().sum()\n",
    "\n",
    "# Fill NaN values with random values between 6.5 and 7 because the value is 6.8 in OECD Better Life Index\n",
    "df['life_satisfaction'].fillna(pd.Series(np.random.uniform(6.5, 7, size=len(df))), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df93ed7",
   "metadata": {},
   "source": [
    "### Mean Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f45ec71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data type of 'mean_salary' column: float64\n"
     ]
    }
   ],
   "source": [
    "# Convert non-numeric values to NaN in the 'mean_salary' column\n",
    "df['mean_salary'] = pd.to_numeric(df['mean_salary'], errors='coerce')\n",
    "\n",
    "# Convert the 'mean_salary' column to float data type\n",
    "df['mean_salary'] = df['mean_salary'].astype(float)\n",
    "\n",
    "# Check the new data type of the 'mean_salary' column\n",
    "print(\"New data type of 'mean_salary' column:\", df['mean_salary'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3846562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total number of null values in \"mean_salary\" column\n",
    "mean_salary_null_count = df[\"mean_salary\"].isnull().sum()\n",
    "\n",
    "# Calculate the mean of \"mean_salary\" column\n",
    "mean_salary_mean = df[\"mean_salary\"].mean()\n",
    "\n",
    "# Fill null values with the mean\n",
    "df[\"mean_salary\"].fillna(mean_salary_mean, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86c6db0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['city of london', 'barking and dagenham', 'barnet', 'bexley',\n",
       "       'brent', 'bromley', 'camden', 'croydon', 'ealing', 'enfield',\n",
       "       'greenwich', 'hackney', 'hammersmith and fulham', 'haringey',\n",
       "       'harrow', 'havering', 'hillingdon', 'hounslow', 'islington',\n",
       "       'kensington and chelsea', 'kingston upon thames', 'lambeth',\n",
       "       'lewisham', 'merton', 'newham', 'redbridge',\n",
       "       'richmond upon thames', 'southwark', 'sutton', 'tower hamlets',\n",
       "       'waltham forest', 'wandsworth', 'westminster', 'north east',\n",
       "       'north west', 'yorkshire and the humber', 'east midlands',\n",
       "       'west midlands', 'east', 'london', 'south east', 'south west',\n",
       "       'inner london', 'outer london', 'england', 'united kingdom',\n",
       "       'great britain', 'england and wales', 'northern ireland',\n",
       "       'scotland', 'wales'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all distinct values from the 'area' column\n",
    "distinct_area_names = df['area'].unique()\n",
    "distinct_area_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2826972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate 'region_df' and 'london_df' into a single DataFrame\n",
    "# combined_df = pd.concat([region_df, london_df], ignore_index=True)\n",
    "\n",
    "# Find the rows in 'df' that are not in 'combined_df'\n",
    "# different_rows = df[~df['area'].isin(combined_df['area'])]\n",
    "\n",
    "# Get distinct values in the 'area' column of 'different_rows'\n",
    "# distinct_areas_in_different_rows = different_rows['area'].unique()\n",
    "# distinct_areas_in_different_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a75a886",
   "metadata": {},
   "source": [
    "### Recycling Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "656161b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the \"recycling_pct\" column to numeric type\n",
    "df[\"recycling_pct\"] = pd.to_numeric(df[\"recycling_pct\"], errors=\"coerce\")\n",
    "\n",
    "# Print the updated data type of the column\n",
    "df[\"recycling_pct\"].dtypes\n",
    "\n",
    "# Group the DataFrame by \"area\" and calculate the mean recycling percentage for each area\n",
    "mean_recycling_pct = df.groupby(\"area\")[\"recycling_pct\"].mean()\n",
    "mean_recycling_pct\n",
    "\n",
    "# Convert Series to DataFrame\n",
    "mean_recycling_pct = mean_recycling_pct.reset_index()\n",
    "mean_recycling_pct\n",
    "\n",
    "# Merging DataFrames based on the 'city' column (common key)\n",
    "df = df.merge(mean_recycling_pct, on='area', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df8ae9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN values in \"recycling_pct_x\" with values from \"recycling_pct_y\"\n",
    "df['recycling_pct_x'] = df['recycling_pct_x'].fillna(df['recycling_pct_y'])\n",
    "\n",
    "# Calculate the median of \"recycling_pct_x\" column\n",
    "recycling_pct_x_median = df['recycling_pct_x'].median()\n",
    "\n",
    "# Fill NaN values in \"recycling_pct_x\" column with the median value\n",
    "df['recycling_pct_x'] = df['recycling_pct_x'].fillna(recycling_pct_x_median)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d06594",
   "metadata": {},
   "source": [
    "### Population Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac53de8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting population size data by year\n",
    "pop_size = pd.read_csv(\"population_size.csv\")\n",
    "\n",
    "# List of columns to drop\n",
    "columns_to_drop = [\"sample\", \"2001\", \"2011\", \"2021\", \"Data.1\"]\n",
    "\n",
    "# Drop the specified columns from the DataFrame\n",
    "pop_size.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d4b9919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging DataFrames based on the 'city' column (common key)\n",
    "df = df.merge(pop_size, on='area', how='left')\n",
    "\n",
    "# Rename the columns as required\n",
    "df.rename(columns={\n",
    "    \"recycling_pct_x\": \"recycling_pct\",\n",
    "    \"recycling_pct_y\": \"mean_recycle_pct\",\n",
    "    \"Data\": \"extended_pop_size\"\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cbcdc701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify rows where \"population_size\" is NaN\n",
    "mask = df['population_size'].isnull()\n",
    "\n",
    "# Fill NaN values in \"population_size\" column with corresponding values from \"extended_pop_size\"\n",
    "df.loc[mask, 'population_size'] = df.loc[mask, 'extended_pop_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a369fd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df['population_size'].isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "76c0b5a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>barking and dagenham</td>\n",
       "      <td>190,533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>barnet</td>\n",
       "      <td>355,461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bexley</td>\n",
       "      <td>232,682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>brent</td>\n",
       "      <td>307,220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bromley</td>\n",
       "      <td>312,248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>camden</td>\n",
       "      <td>210,941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>city of westminster</td>\n",
       "      <td>209,039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>croydon</td>\n",
       "      <td>363,545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ealing</td>\n",
       "      <td>337,910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>enfield</td>\n",
       "      <td>307,073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>greenwich</td>\n",
       "      <td>254,017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hackney</td>\n",
       "      <td>237,843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hammersmith and fulham</td>\n",
       "      <td>178,334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>haringey</td>\n",
       "      <td>247,026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>harrow</td>\n",
       "      <td>237,234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>havering</td>\n",
       "      <td>241,560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>hillingdon</td>\n",
       "      <td>275,669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>hounslow</td>\n",
       "      <td>253,036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>islington</td>\n",
       "      <td>200,758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>kensington and chelsea</td>\n",
       "      <td>154,609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>kingston upon thames</td>\n",
       "      <td>159,166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>lambeth</td>\n",
       "      <td>298,512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>lewisham</td>\n",
       "      <td>277,264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>merton</td>\n",
       "      <td>202,277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>newham</td>\n",
       "      <td>303,632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>redbridge</td>\n",
       "      <td>277,852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>richmond upon thames</td>\n",
       "      <td>185,702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>southwark</td>\n",
       "      <td>284,351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>sutton</td>\n",
       "      <td>194,087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>tower Hamlets</td>\n",
       "      <td>255,806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>waltham forest</td>\n",
       "      <td>253,389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>wandsworth</td>\n",
       "      <td>302,305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>city of london</td>\n",
       "      <td>7,798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      area       Data\n",
       "0     barking and dagenham   190,533 \n",
       "1                   barnet   355,461 \n",
       "2                   bexley   232,682 \n",
       "3                    brent   307,220 \n",
       "4                  bromley   312,248 \n",
       "5                   camden   210,941 \n",
       "6      city of westminster   209,039 \n",
       "7                  croydon   363,545 \n",
       "8                   ealing   337,910 \n",
       "9                  enfield   307,073 \n",
       "10               greenwich   254,017 \n",
       "11                 hackney   237,843 \n",
       "12  hammersmith and fulham   178,334 \n",
       "13                haringey   247,026 \n",
       "14                  harrow   237,234 \n",
       "15                havering   241,560 \n",
       "16              hillingdon   275,669 \n",
       "17                hounslow   253,036 \n",
       "18               islington   200,758 \n",
       "19  kensington and chelsea   154,609 \n",
       "20    kingston upon thames   159,166 \n",
       "21                 lambeth   298,512 \n",
       "22                lewisham   277,264 \n",
       "23                  merton   202,277 \n",
       "24                  newham   303,632 \n",
       "25               redbridge   277,852 \n",
       "26    richmond upon thames   185,702 \n",
       "27               southwark   284,351 \n",
       "28                  sutton   194,087 \n",
       "29           tower Hamlets   255,806 \n",
       "30          waltham forest   253,389 \n",
       "31              wandsworth   302,305 \n",
       "32          city of london     7,798 "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a8ef7e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1071 entries, 0 to 1070\n",
      "Data columns (total 14 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   code               1071 non-null   object \n",
      " 1   area               1071 non-null   object \n",
      " 2   date               1071 non-null   object \n",
      " 3   median_salary      1071 non-null   float64\n",
      " 4   life_satisfaction  1071 non-null   float64\n",
      " 5   mean_salary        1071 non-null   float64\n",
      " 6   recycling_pct      1071 non-null   float64\n",
      " 7   population_size    31 non-null     float64\n",
      " 8   number_of_jobs     931 non-null    float64\n",
      " 9   area_size          666 non-null    float64\n",
      " 10  no_of_houses       666 non-null    float64\n",
      " 11  borough_flag       1071 non-null   int64  \n",
      " 12  mean_recycle_pct   903 non-null    float64\n",
      " 13  extended_pop_size  651 non-null    object \n",
      "dtypes: float64(9), int64(1), object(4)\n",
      "memory usage: 125.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5da4e743",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use .str accessor with string values!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Only 22 rows have NaN values in population_size column\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Remove commas and convert the \"population_size\" column to numeric\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpopulation_size\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_numeric(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpopulation_size\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m), errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:5902\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5895\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   5896\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[1;32m   5897\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[1;32m   5898\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[1;32m   5899\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   5900\u001b[0m ):\n\u001b[1;32m   5901\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[0;32m-> 5902\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/accessor.py:182\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;66;03m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor\n\u001b[0;32m--> 182\u001b[0m accessor_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor(obj)\n\u001b[1;32m    183\u001b[0m \u001b[38;5;66;03m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;66;03m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;66;03m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;66;03m# NDFrame\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, accessor_obj)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/strings/accessor.py:181\u001b[0m, in \u001b[0;36mStringMethods.__init__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstring_\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StringDtype\n\u001b[0;32m--> 181\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate(data)\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_categorical \u001b[38;5;241m=\u001b[39m is_categorical_dtype(data\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, StringDtype)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/strings/accessor.py:235\u001b[0m, in \u001b[0;36mStringMethods._validate\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    232\u001b[0m inferred_dtype \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39minfer_dtype(values, skipna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inferred_dtype \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m allowed_types:\n\u001b[0;32m--> 235\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only use .str accessor with string values!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inferred_dtype\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can only use .str accessor with string values!"
     ]
    }
   ],
   "source": [
    "# Only 22 rows have NaN values in population_size column\n",
    "# Remove commas and convert the \"population_size\" column to numeric\n",
    "df['population_size'] = pd.to_numeric(df['population_size'].str.replace(',', ''), errors='coerce')\n",
    "\n",
    "# Calculate the median of the \"population_size\" column\n",
    "# median_population_size = df['population_size'].median()\n",
    "\n",
    "# Fill NaN values in \"population_size\" column with the median value\n",
    "# df['population_size'].fillna(median_population_size, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d881f2",
   "metadata": {},
   "source": [
    "### Number of Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b683d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only 42 out of 140 NaN value remained\n",
    "# Getting number of jobs data from csv\n",
    "total_jobs = pd.read_csv(\"number_of_jobs.csv\")\n",
    "\n",
    "# List of columns to drop\n",
    "columns_to_drop = [\"name\", \"2000\", \"2001\", \"2002\", \"2003\", \"2004\", \"2005\", \"2006\", \"2007\", \"2008\", \"2009\", \"2010\", \"2011\", \"2012\", \"2013\", \"2014\", \"2015\", \"2016\", \"2017\", \"2018\", \"2019\", \"2020\", \"2021\"]\n",
    "\n",
    "# Drop the specified columns from the DataFrame\n",
    "total_jobs.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# Merging DataFrames based on the 'city' column (common key)\n",
    "df = df.merge(total_jobs, on='area', how='left')\n",
    "\n",
    "# Identify rows where \"population_size\" is NaN\n",
    "mask = df['number_of_jobs'].isnull()\n",
    "\n",
    "# Fill NaN values in \"population_size\" column with corresponding values from \"extended_pop_size\"\n",
    "df.loc[mask, 'number_of_jobs'] = df.loc[mask, 'number_of_jobs_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5787c4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove commas and convert the \"number_of_jobs\" column to numeric\n",
    "df['number_of_jobs'] = pd.to_numeric(df['number_of_jobs'].str.replace(',', ''), errors='coerce')\n",
    "\n",
    "# Calculate the median of the \"number_of_jobs\" column\n",
    "median_number_of_jobs = df['number_of_jobs'].median()\n",
    "\n",
    "# Fill NaN values in \"number_of_jobs\" column with the median value\n",
    "df['number_of_jobs'].fillna(median_number_of_jobs, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b2c5b5",
   "metadata": {},
   "source": [
    "### Area Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5fb56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only 105 out of 405 NaN value remained\n",
    "# The correlation of 0.621 between population_size & area_size indicates a positive moderate-strong relationship.\n",
    "\n",
    "# Rows where \"area_size\" column is not empty\n",
    "non_empty_rows = df[df['area_size'].notna()]\n",
    "\n",
    "# Only 42 out of 140 NaN value remained\n",
    "# Getting number of jobs data from csv\n",
    "total_hectar = pd.read_csv(\"total_hectar.csv\")\n",
    "\n",
    "# List of columns to drop\n",
    "columns_to_drop = [\"sample\"]\n",
    "\n",
    "# Drop the specified columns from the DataFrame\n",
    "total_hectar.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# Merging DataFrames based on the 'city' column (common key)\n",
    "df = df.merge(total_hectar, on='area', how='left')\n",
    "\n",
    "# Identify rows where \"population_size\" is NaN\n",
    "mask = df['area_size'].isnull()\n",
    "\n",
    "# Fill NaN values in \"population_size\" column with corresponding values from \"extended_pop_size\"\n",
    "df.loc[mask, 'area_size'] = df.loc[mask, 'total_hectar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8a8330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove commas and convert the \"area_size\" column to numeric\n",
    "df['area_size'] = pd.to_numeric(df['area_size'].str.replace(',', ''), errors='coerce')\n",
    "\n",
    "# Calculate the median of the \"area_size\" column\n",
    "median_number_of_jobs = df['area_size'].median()\n",
    "\n",
    "# Fill NaN values in \"area_size\" column with the median value\n",
    "df['area_size'].fillna(median_number_of_jobs, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5085da1b",
   "metadata": {},
   "source": [
    "### Number of Houses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a250c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating person per house\n",
    "# df['persons_per_house'] = df['population_size'] / df['no_of_houses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34394567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN values in \"no_of_houses\" column with 0 - There is no number of house data for UK Regions\n",
    "df[\"no_of_houses\"].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e096c00a",
   "metadata": {},
   "source": [
    "### Dataframe Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99529d99",
   "metadata": {},
   "source": [
    "#### London Boroughs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ce480b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The list of values you want to keep\n",
    "london_values = ['city of london', 'barking and dagenham', 'barnet', 'bexley', 'brent', 'bromley', 'camden', 'croydon', 'ealing', 'enfield',\n",
    "                  'greenwich', 'hackney', 'hammersmith and fulham', 'haringey', 'harrow', 'havering', 'hillingdon', 'hounslow', 'islington',\n",
    "                  'kensington and chelsea', 'kingston upon thames', 'lambeth', 'lewisham', 'merton', 'newham', 'redbridge',\n",
    "                  'richmond upon thames', 'southwark', 'sutton', 'tower hamlets', 'waltham forest', 'wandsworth', 'westminster']\n",
    "\n",
    "# Filter the DataFrame to keep only rows with the desired values in the 'area' column\n",
    "london_df = df[df['area'].isin(london_values)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc7e6b8",
   "metadata": {},
   "source": [
    "#### UK Regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c615d660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The list of values you want to keep\n",
    "region_values = ['north east', 'north west', 'yorkshire and the humber', 'east midlands', 'west midlands', 'east',\n",
    "                  'south east', 'south west', 'england', 'united kingdom', 'great britain', 'england and wales',\n",
    "                  'northern ireland', 'scotland', 'wales', \"inner london\", \"outer london\", \"london\"]\n",
    "\n",
    "# Filter the DataFrame to keep only rows with the desired values in the 'area' column\n",
    "region_df = df[df['area'].isin(region_values)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cc8e54",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f3283e",
   "metadata": {},
   "source": [
    "### 1- Is there a correlation between the median salary and the life satisfaction for residents in London's boroughs?\n",
    "\n",
    "- The correlation coefficient of -0.21936922410940793 suggests a weak negative correlation between \"median_salary\" and \"life_satisfaction\" in the dataset.\n",
    "\n",
    "- Cost of living: London's high living costs might lead to higher salaries but potentially reduced life satisfaction due to financial stress.\n",
    "\n",
    "- Work-life balance: Demanding jobs with higher salaries may lead to decreased life satisfaction if individuals experience limited leisure time or increased stress levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af85c96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up seaborn style for better aesthetics\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Create the histogram with customizations\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(london_df[\"median_salary\"], bins=20, color=\"#007acc\", edgecolor=\"k\", alpha=0.7)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(\"Median Salary\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Median Salary of London Boroughs\", fontsize=16)\n",
    "\n",
    "# Add grid lines for better readability\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "# Remove the right and top spines for cleaner look\n",
    "plt.gca().spines[\"right\"].set_visible(False)\n",
    "plt.gca().spines[\"top\"].set_visible(False)\n",
    "\n",
    "# Add a legend (optional) - if you have relevant data, like source or data year\n",
    "#plt.legend([\"2022 Data\"])\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d0ee11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up seaborn style for better aesthetics\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Create the histogram with customizations\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(region_df[\"median_salary\"], bins=20, color=\"#007acc\", edgecolor=\"k\", alpha=0.7)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(\"Median Salary\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Median Salary of UK Regions\", fontsize=16)\n",
    "\n",
    "# Add grid lines for better readability\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "# Remove the right and top spines for cleaner look\n",
    "plt.gca().spines[\"right\"].set_visible(False)\n",
    "plt.gca().spines[\"top\"].set_visible(False)\n",
    "\n",
    "# Add a legend (optional) - if you have relevant data, like source or data year\n",
    "#plt.legend([\"2022 Data\"])\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f255402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up seaborn style for better aesthetics\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Create the histogram with customizations\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(london_df[\"life_satisfaction\"], bins=20, color=\"#4caf50\", edgecolor=\"k\", alpha=0.7)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(\"Life Satisfaction\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Life Satisfaction of London Boroughs\", fontsize=16)\n",
    "\n",
    "# Add grid lines for better readability\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "# Remove the right and top spines for cleaner look\n",
    "plt.gca().spines[\"right\"].set_visible(False)\n",
    "plt.gca().spines[\"top\"].set_visible(False)\n",
    "\n",
    "# Add a legend (optional) - if you have relevant data, like source or data year\n",
    "# plt.legend([\"2022 Data\"])\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1229c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up seaborn style for better aesthetics\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Create the histogram with customizations\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(region_df[\"life_satisfaction\"], bins=20, color=\"#4caf50\", edgecolor=\"k\", alpha=0.7)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(\"Life Satisfaction\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Life Satisfaction of UK Regions\", fontsize=16)\n",
    "\n",
    "# Add grid lines for better readability\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "# Remove the right and top spines for cleaner look\n",
    "plt.gca().spines[\"right\"].set_visible(False)\n",
    "plt.gca().spines[\"top\"].set_visible(False)\n",
    "\n",
    "# Add a legend (optional) - if you have relevant data, like source or data year\n",
    "# plt.legend([\"2022 Data\"])\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a884aa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Spearman's rank correlation coefficient between \"median_salary\" and \"life_satisfaction\"\n",
    "correlation_coefficient = df[\"median_salary\"].corr(df[\"life_satisfaction\"], method=\"spearman\")\n",
    "correlation_coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb39d1bc",
   "metadata": {},
   "source": [
    "### 2- How does the recycling percentage vary across different boroughs of London? Are there any patterns or trends?\n",
    "\n",
    "- Out of the 20 boroughs, the average recycling rate is above 26.9%.\n",
    "\n",
    "- A correlation coefficient of 0.12 should be interpreted as a weak positive correlation between the mean_salary and recycle_pct_x being compared.\n",
    "\n",
    "- The recycling rate increased until 2012, then entered a plateau phase, and in 2020, there was a drastic decline. The COVID-19 pandemic could have disrupted recycling operations and collection services. With lockdowns and social distancing measures, people might have been more reliant on single-use products, leading to increased waste generation.\n",
    "\n",
    "- London 2012 won gold in the Environmental and Sustainability category at the 6th International Sports Event Management awards. However, after the success of the 2012 Olympics, priorities may have shifted, and there could have been a decrease in financial and political support for recycling projects. This reduction in investments may have affected the effectiveness and capacity of recycling activities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7111a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any rows with missing values (NaN)\n",
    "mean_recycling_pct = mean_recycling_pct.dropna(subset=['recycling_pct'])\n",
    "\n",
    "# Sort the data in descending order based on the mean of 'recycling_pct' column\n",
    "mean_recycling_pct = mean_recycling_pct.sort_values(by='recycling_pct', ascending=False)\n",
    "\n",
    "# Calculate the mean of 'recycling_pct' column\n",
    "mean_value = mean_recycling_pct['recycling_pct'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dee3651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up seaborn style for better aesthetics\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Plot the histogram\n",
    "plt.figure(figsize=(20, 8))\n",
    "bars = sns.barplot(x='area', y='recycling_pct', data=mean_recycling_pct, palette='viridis')\n",
    "\n",
    "# Color bars above the mean line in green\n",
    "for bar in bars.patches:\n",
    "    if bar.get_height() > mean_value:\n",
    "        bar.set_color('green')\n",
    "\n",
    "# Add the mean line\n",
    "plt.axhline(mean_value, color='red', linestyle='dashed', label='Mean')\n",
    "\n",
    "plt.xlabel('Area', fontsize=16)\n",
    "plt.ylabel('Recycling Percentage', fontsize=14)\n",
    "plt.title('Recycling Percentages by Area', fontsize=16)\n",
    "plt.xticks(rotation=90, fontsize=16)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "# Add a background color for the plot (optional)\n",
    "plt.gca().set_facecolor('#f2f2f2')\n",
    "\n",
    "# Remove the top and right spines for cleaner look\n",
    "sns.despine()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f762e122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean of the 'recycling_pct_y' column\n",
    "# mean_recycling_pct_y = df['recycling_pct_x'].mean()\n",
    "\n",
    "# Fill the NaN values in the 'recycling_pct_y' column with the calculated mean\n",
    "# df['recycling_pct_x'].fillna(mean_recycling_pct_y, inplace=True)\n",
    "\n",
    "# has_nan_values = df['recycling_pct_x'].isnull().any()\n",
    "# has_nan_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80986109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'date' and calculate the mean of 'recycling_pct_x'\n",
    "grouped_df = df.groupby('date')['recycling_pct'].mean().reset_index()\n",
    "\n",
    "# Create the trendline graph\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(grouped_df['date'], grouped_df['recycling_pct'], marker='o', linestyle='-', color='b')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Recycling Percentage (%)')\n",
    "plt.title('Trendline Graph of Recycling Percentage')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a689db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation coefficient between 'mean_salary' and 'recycling_pct_x'\n",
    "correlation_coefficient = df['mean_salary'].corr(df['recycling_pct'])\n",
    "correlation_coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98674c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write London Boroughs data to CSV file\n",
    "london_df.to_csv('london_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9863fcec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Filter rows where mean_salary is below 20,504\n",
    "filtered_df = london_df[london_df['mean_salary'] < 20504]\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6c2c00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
