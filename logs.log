2023-07-24 16:47:52,219:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-24 16:47:52,221:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-24 16:47:52,221:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-24 16:47:52,221:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-24 16:49:06,975:INFO:PyCaret RegressionExperiment
2023-07-24 16:49:06,975:INFO:Logging name: reg-default-name
2023-07-24 16:49:06,975:INFO:ML Usecase: MLUsecase.REGRESSION
2023-07-24 16:49:06,976:INFO:version 3.0.4
2023-07-24 16:49:06,976:INFO:Initializing setup()
2023-07-24 16:49:06,976:INFO:self.USI: 9119
2023-07-24 16:49:06,977:INFO:self._variable_keys: {'exp_id', 'gpu_param', 'y_train', 'pipeline', 'idx', 'seed', 'target_param', 'gpu_n_jobs_param', 'X_train', '_available_plots', 'X_test', 'y_test', 'fold_shuffle_param', 'USI', 'transform_target_param', '_ml_usecase', 'log_plots_param', 'html_param', 'X', 'fold_groups_param', 'fold_generator', 'data', 'exp_name_log', 'logging_param', 'y', 'memory', 'n_jobs_param'}
2023-07-24 16:49:06,977:INFO:Checking environment
2023-07-24 16:49:06,977:INFO:python_version: 3.9.13
2023-07-24 16:49:06,977:INFO:python_build: ('main', 'Aug 25 2022 18:29:29')
2023-07-24 16:49:06,978:INFO:machine: x86_64
2023-07-24 16:49:06,978:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-07-24 16:49:06,980:INFO:Memory: svmem(total=8589934592, available=2631200768, percent=69.4, used=4085559296, free=53661696, active=2578874368, inactive=2555154432, wired=1506684928)
2023-07-24 16:49:06,981:INFO:Physical Core: 2
2023-07-24 16:49:06,981:INFO:Logical Core: 4
2023-07-24 16:49:06,981:INFO:Checking libraries
2023-07-24 16:49:06,981:INFO:System:
2023-07-24 16:49:06,982:INFO:    python: 3.9.13 (main, Aug 25 2022, 18:29:29)  [Clang 12.0.0 ]
2023-07-24 16:49:06,982:INFO:executable: /Users/iremkurt/opt/anaconda3/bin/python
2023-07-24 16:49:06,982:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-07-24 16:49:06,982:INFO:PyCaret required dependencies:
2023-07-24 16:49:07,224:INFO:                 pip: 23.2
2023-07-24 16:49:07,224:INFO:          setuptools: 63.4.1
2023-07-24 16:49:07,224:INFO:             pycaret: 3.0.4
2023-07-24 16:49:07,224:INFO:             IPython: 8.14.0
2023-07-24 16:49:07,225:INFO:          ipywidgets: 7.7.5
2023-07-24 16:49:07,225:INFO:                tqdm: 4.64.1
2023-07-24 16:49:07,225:INFO:               numpy: 1.23.5
2023-07-24 16:49:07,225:INFO:              pandas: 1.3.1
2023-07-24 16:49:07,225:INFO:              jinja2: 3.1.2
2023-07-24 16:49:07,225:INFO:               scipy: 1.9.1
2023-07-24 16:49:07,225:INFO:              joblib: 1.3.1
2023-07-24 16:49:07,225:INFO:             sklearn: 1.0.2
2023-07-24 16:49:07,226:INFO:                pyod: 1.1.0
2023-07-24 16:49:07,226:INFO:            imblearn: 0.11.0
2023-07-24 16:49:07,226:INFO:   category_encoders: 2.6.1
2023-07-24 16:49:07,226:INFO:            lightgbm: 4.0.0
2023-07-24 16:49:07,226:INFO:               numba: 0.57.1
2023-07-24 16:49:07,226:INFO:            requests: 2.28.1
2023-07-24 16:49:07,226:INFO:          matplotlib: 3.6.0
2023-07-24 16:49:07,226:INFO:          scikitplot: 0.3.7
2023-07-24 16:49:07,227:INFO:         yellowbrick: 1.5
2023-07-24 16:49:07,227:INFO:              plotly: 5.15.0
2023-07-24 16:49:07,227:INFO:    plotly-resampler: Not installed
2023-07-24 16:49:07,227:INFO:             kaleido: 0.2.1
2023-07-24 16:49:07,227:INFO:           schemdraw: 0.15
2023-07-24 16:49:07,227:INFO:         statsmodels: 0.13.2
2023-07-24 16:49:07,227:INFO:              sktime: 0.20.0
2023-07-24 16:49:07,227:INFO:               tbats: 1.1.3
2023-07-24 16:49:07,227:INFO:            pmdarima: 2.0.3
2023-07-24 16:49:07,227:INFO:              psutil: 5.9.5
2023-07-24 16:49:07,227:INFO:          markupsafe: 2.1.3
2023-07-24 16:49:07,227:INFO:             pickle5: Not installed
2023-07-24 16:49:07,228:INFO:         cloudpickle: 2.2.1
2023-07-24 16:49:07,228:INFO:         deprecation: 2.1.0
2023-07-24 16:49:07,228:INFO:              xxhash: 3.2.0
2023-07-24 16:49:07,228:INFO:           wurlitzer: 3.0.2
2023-07-24 16:49:07,228:INFO:PyCaret optional dependencies:
2023-07-24 16:49:09,195:INFO:                shap: 0.42.1
2023-07-24 16:49:09,196:INFO:           interpret: Not installed
2023-07-24 16:49:09,196:INFO:                umap: Not installed
2023-07-24 16:49:09,196:INFO:    pandas_profiling: 0.0.dev0
2023-07-24 16:49:09,196:INFO:  explainerdashboard: Not installed
2023-07-24 16:49:09,196:INFO:             autoviz: Not installed
2023-07-24 16:49:09,196:INFO:           fairlearn: Not installed
2023-07-24 16:49:09,196:INFO:          deepchecks: Not installed
2023-07-24 16:49:09,196:INFO:             xgboost: 1.7.6
2023-07-24 16:49:09,196:INFO:            catboost: Not installed
2023-07-24 16:49:09,196:INFO:              kmodes: Not installed
2023-07-24 16:49:09,197:INFO:             mlxtend: Not installed
2023-07-24 16:49:09,197:INFO:       statsforecast: Not installed
2023-07-24 16:49:09,197:INFO:        tune_sklearn: Not installed
2023-07-24 16:49:09,197:INFO:                 ray: Not installed
2023-07-24 16:49:09,197:INFO:            hyperopt: Not installed
2023-07-24 16:49:09,197:INFO:              optuna: Not installed
2023-07-24 16:49:09,197:INFO:               skopt: Not installed
2023-07-24 16:49:09,197:INFO:              mlflow: Not installed
2023-07-24 16:49:09,197:INFO:              gradio: Not installed
2023-07-24 16:49:09,197:INFO:             fastapi: 0.100.0
2023-07-24 16:49:09,197:INFO:             uvicorn: 0.23.0
2023-07-24 16:49:09,197:INFO:              m2cgen: Not installed
2023-07-24 16:49:09,197:INFO:           evidently: Not installed
2023-07-24 16:49:09,198:INFO:               fugue: Not installed
2023-07-24 16:49:09,198:INFO:           streamlit: 1.24.1
2023-07-24 16:49:09,198:INFO:             prophet: 1.1.4
2023-07-24 16:49:09,198:INFO:None
2023-07-24 16:49:09,198:INFO:Set up data.
2023-07-24 16:51:05,515:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-24 16:51:05,516:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-24 16:51:05,516:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-24 16:51:05,516:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-24 16:54:20,904:INFO:PyCaret RegressionExperiment
2023-07-24 16:54:20,904:INFO:Logging name: reg-default-name
2023-07-24 16:54:20,905:INFO:ML Usecase: MLUsecase.REGRESSION
2023-07-24 16:54:20,905:INFO:version 3.0.4
2023-07-24 16:54:20,905:INFO:Initializing setup()
2023-07-24 16:54:20,905:INFO:self.USI: 395e
2023-07-24 16:54:20,905:INFO:self._variable_keys: {'html_param', 'fold_generator', 'X_train', 'transform_target_param', 'memory', 'exp_id', 'y_test', 'y_train', 'gpu_param', 'gpu_n_jobs_param', 'target_param', 'exp_name_log', 'seed', 'pipeline', 'USI', '_ml_usecase', '_available_plots', 'y', 'idx', 'X_test', 'data', 'n_jobs_param', 'logging_param', 'fold_groups_param', 'X', 'fold_shuffle_param', 'log_plots_param'}
2023-07-24 16:54:20,905:INFO:Checking environment
2023-07-24 16:54:20,905:INFO:python_version: 3.9.13
2023-07-24 16:54:20,905:INFO:python_build: ('main', 'Aug 25 2022 18:29:29')
2023-07-24 16:54:20,905:INFO:machine: x86_64
2023-07-24 16:54:20,905:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-07-24 16:54:20,905:INFO:Memory: svmem(total=8589934592, available=2750320640, percent=68.0, used=4250140672, free=23306240, active=2728816640, inactive=2682695680, wired=1521324032)
2023-07-24 16:54:20,906:INFO:Physical Core: 2
2023-07-24 16:54:20,906:INFO:Logical Core: 4
2023-07-24 16:54:20,906:INFO:Checking libraries
2023-07-24 16:54:20,906:INFO:System:
2023-07-24 16:54:20,906:INFO:    python: 3.9.13 (main, Aug 25 2022, 18:29:29)  [Clang 12.0.0 ]
2023-07-24 16:54:20,906:INFO:executable: /Users/iremkurt/opt/anaconda3/bin/python
2023-07-24 16:54:20,906:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-07-24 16:54:20,906:INFO:PyCaret required dependencies:
2023-07-24 16:54:21,124:INFO:                 pip: 23.2
2023-07-24 16:54:21,124:INFO:          setuptools: 63.4.1
2023-07-24 16:54:21,125:INFO:             pycaret: 3.0.4
2023-07-24 16:54:21,125:INFO:             IPython: 8.14.0
2023-07-24 16:54:21,125:INFO:          ipywidgets: 7.7.5
2023-07-24 16:54:21,125:INFO:                tqdm: 4.64.1
2023-07-24 16:54:21,125:INFO:               numpy: 1.23.5
2023-07-24 16:54:21,125:INFO:              pandas: 1.3.1
2023-07-24 16:54:21,125:INFO:              jinja2: 3.1.2
2023-07-24 16:54:21,125:INFO:               scipy: 1.9.1
2023-07-24 16:54:21,125:INFO:              joblib: 1.3.1
2023-07-24 16:54:21,125:INFO:             sklearn: 1.0.2
2023-07-24 16:54:21,125:INFO:                pyod: 1.1.0
2023-07-24 16:54:21,125:INFO:            imblearn: 0.11.0
2023-07-24 16:54:21,126:INFO:   category_encoders: 2.6.1
2023-07-24 16:54:21,126:INFO:            lightgbm: 4.0.0
2023-07-24 16:54:21,126:INFO:               numba: 0.57.1
2023-07-24 16:54:21,126:INFO:            requests: 2.28.1
2023-07-24 16:54:21,126:INFO:          matplotlib: 3.6.0
2023-07-24 16:54:21,126:INFO:          scikitplot: 0.3.7
2023-07-24 16:54:21,126:INFO:         yellowbrick: 1.5
2023-07-24 16:54:21,126:INFO:              plotly: 5.15.0
2023-07-24 16:54:21,126:INFO:    plotly-resampler: Not installed
2023-07-24 16:54:21,126:INFO:             kaleido: 0.2.1
2023-07-24 16:54:21,126:INFO:           schemdraw: 0.15
2023-07-24 16:54:21,127:INFO:         statsmodels: 0.13.2
2023-07-24 16:54:21,127:INFO:              sktime: 0.20.0
2023-07-24 16:54:21,127:INFO:               tbats: 1.1.3
2023-07-24 16:54:21,127:INFO:            pmdarima: 2.0.3
2023-07-24 16:54:21,127:INFO:              psutil: 5.9.5
2023-07-24 16:54:21,127:INFO:          markupsafe: 2.1.3
2023-07-24 16:54:21,127:INFO:             pickle5: Not installed
2023-07-24 16:54:21,127:INFO:         cloudpickle: 2.2.1
2023-07-24 16:54:21,127:INFO:         deprecation: 2.1.0
2023-07-24 16:54:21,127:INFO:              xxhash: 3.2.0
2023-07-24 16:54:21,127:INFO:           wurlitzer: 3.0.2
2023-07-24 16:54:21,127:INFO:PyCaret optional dependencies:
2023-07-24 16:54:21,829:INFO:                shap: 0.42.1
2023-07-24 16:54:21,829:INFO:           interpret: Not installed
2023-07-24 16:54:21,829:INFO:                umap: Not installed
2023-07-24 16:54:21,829:INFO:    pandas_profiling: 0.0.dev0
2023-07-24 16:54:21,830:INFO:  explainerdashboard: Not installed
2023-07-24 16:54:21,830:INFO:             autoviz: Not installed
2023-07-24 16:54:21,830:INFO:           fairlearn: Not installed
2023-07-24 16:54:21,830:INFO:          deepchecks: Not installed
2023-07-24 16:54:21,830:INFO:             xgboost: 1.7.6
2023-07-24 16:54:21,830:INFO:            catboost: Not installed
2023-07-24 16:54:21,830:INFO:              kmodes: Not installed
2023-07-24 16:54:21,830:INFO:             mlxtend: Not installed
2023-07-24 16:54:21,830:INFO:       statsforecast: Not installed
2023-07-24 16:54:21,830:INFO:        tune_sklearn: Not installed
2023-07-24 16:54:21,830:INFO:                 ray: Not installed
2023-07-24 16:54:21,830:INFO:            hyperopt: Not installed
2023-07-24 16:54:21,830:INFO:              optuna: Not installed
2023-07-24 16:54:21,830:INFO:               skopt: Not installed
2023-07-24 16:54:21,830:INFO:              mlflow: Not installed
2023-07-24 16:54:21,830:INFO:              gradio: Not installed
2023-07-24 16:54:21,830:INFO:             fastapi: 0.100.0
2023-07-24 16:54:21,831:INFO:             uvicorn: 0.23.0
2023-07-24 16:54:21,831:INFO:              m2cgen: Not installed
2023-07-24 16:54:21,831:INFO:           evidently: Not installed
2023-07-24 16:54:21,831:INFO:               fugue: Not installed
2023-07-24 16:54:21,831:INFO:           streamlit: 1.24.1
2023-07-24 16:54:21,831:INFO:             prophet: 1.1.4
2023-07-24 16:54:21,831:INFO:None
2023-07-24 16:54:21,831:INFO:Set up data.
2023-07-24 16:54:22,179:INFO:Set up train/test split.
2023-07-24 16:54:22,252:INFO:Set up index.
2023-07-24 16:54:22,256:INFO:Set up folding strategy.
2023-07-24 16:54:22,256:INFO:Assigning column types.
2023-07-24 16:54:22,300:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-07-24 16:54:22,303:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-07-24 16:54:22,321:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-07-24 16:54:22,336:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-24 16:54:22,822:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-24 16:54:22,943:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-24 16:54:22,945:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-24 16:54:23,213:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-24 16:54:23,214:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-07-24 16:54:23,228:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-07-24 16:54:23,245:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-24 16:54:23,431:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-24 16:54:23,539:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-24 16:54:23,542:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-24 16:54:23,547:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-24 16:54:23,547:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-07-24 16:54:23,564:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-07-24 16:54:23,580:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-24 16:54:23,727:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-24 16:54:23,813:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-24 16:54:23,814:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-24 16:54:23,819:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-24 16:54:23,827:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-07-24 16:54:23,835:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-24 16:54:23,946:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-24 16:54:24,028:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-24 16:54:24,029:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-24 16:54:24,035:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-24 16:54:24,035:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-07-24 16:54:24,052:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-24 16:54:24,178:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-24 16:54:24,295:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-24 16:54:24,301:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-24 16:54:24,306:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-24 16:54:24,323:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-24 16:54:24,441:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-24 16:54:24,519:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-24 16:54:24,520:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-24 16:54:24,524:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-24 16:54:24,525:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-07-24 16:54:24,638:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-24 16:54:24,712:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-24 16:54:24,713:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-24 16:54:24,717:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-24 16:54:24,844:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-24 16:54:24,922:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-24 16:54:24,924:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-24 16:54:24,928:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-24 16:54:24,928:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-07-24 16:54:25,054:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-24 16:54:25,142:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-24 16:54:25,146:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-24 16:54:25,263:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-24 16:54:25,351:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-24 16:54:25,355:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-24 16:54:25,355:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-07-24 16:54:25,758:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-24 16:54:25,764:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-24 16:54:26,034:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-24 16:54:26,038:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-24 16:54:26,044:INFO:Preparing preprocessing pipeline...
2023-07-24 16:54:26,044:INFO:Set up simple imputation.
2023-07-24 16:54:26,056:INFO:Set up encoding of categorical features.
2023-07-24 16:54:26,058:INFO:Set up column name cleaning.
2023-07-24 16:54:27,088:INFO:Finished creating preprocessing pipeline.
2023-07-24 16:54:27,109:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/q_/m4c7kcfx23lfngmh1d06_9_c0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['NDB_No', 'Water_(g)',
                                             'Protein_(g)', 'Lipid_Tot_(g)',
                                             'Ash_(g)', 'Carbohydrt_(g)',
                                             'Fiber_TD_(g)', 'Sugar_Tot_(g)',
                                             'Calcium_(mg)', 'Iron_(mg)',
                                             'Magnesium_(mg)',
                                             'Phosphorus_(mg)',
                                             'Potassium_(mg)', 'Sodium_(mg)'...
                 TransformerWrapper(include=['Shrt_Desc', 'GmWt_Desc1',
                                             'GmWt_Desc2'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(include=['Shrt_Desc', 'GmWt_Desc1',
                                             'GmWt_Desc2'],
                                    transformer=TargetEncoder(cols=['Shrt_Desc',
                                                                    'GmWt_Desc1',
                                                                    'GmWt_Desc2'],
                                                              handle_missing='return_nan'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-07-24 16:54:27,110:INFO:Creating final display dataframe.
2023-07-24 16:54:28,429:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target        Energ_Kcal
2                   Target type        Regression
3           Original data shape        (8790, 53)
4        Transformed data shape        (8790, 53)
5   Transformed train set shape        (6153, 53)
6    Transformed test set shape        (2637, 53)
7              Numeric features                49
8          Categorical features                 3
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator             KFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              395e
2023-07-24 16:54:28,964:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-24 16:54:28,973:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-24 16:54:29,249:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-24 16:54:29,256:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-24 16:54:29,257:INFO:setup() successfully completed in 8.36s...............
2023-07-24 16:55:14,174:INFO:PyCaret RegressionExperiment
2023-07-24 16:55:14,174:INFO:Logging name: reg-default-name
2023-07-24 16:55:14,174:INFO:ML Usecase: MLUsecase.REGRESSION
2023-07-24 16:55:14,175:INFO:version 3.0.4
2023-07-24 16:55:14,175:INFO:Initializing setup()
2023-07-24 16:55:14,175:INFO:self.USI: 74fd
2023-07-24 16:55:14,175:INFO:self._variable_keys: {'html_param', 'fold_generator', 'X_train', 'transform_target_param', 'memory', 'exp_id', 'y_test', 'y_train', 'gpu_param', 'gpu_n_jobs_param', 'target_param', 'exp_name_log', 'seed', 'pipeline', 'USI', '_ml_usecase', '_available_plots', 'y', 'idx', 'X_test', 'data', 'n_jobs_param', 'logging_param', 'fold_groups_param', 'X', 'fold_shuffle_param', 'log_plots_param'}
2023-07-24 16:55:14,175:INFO:Checking environment
2023-07-24 16:55:14,175:INFO:python_version: 3.9.13
2023-07-24 16:55:14,175:INFO:python_build: ('main', 'Aug 25 2022 18:29:29')
2023-07-24 16:55:14,175:INFO:machine: x86_64
2023-07-24 16:55:14,175:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-07-24 16:55:14,175:INFO:Memory: svmem(total=8589934592, available=2901651456, percent=66.2, used=4359282688, free=39161856, active=2864979968, inactive=2857598976, wired=1494302720)
2023-07-24 16:55:14,175:INFO:Physical Core: 2
2023-07-24 16:55:14,175:INFO:Logical Core: 4
2023-07-24 16:55:14,175:INFO:Checking libraries
2023-07-24 16:55:14,175:INFO:System:
2023-07-24 16:55:14,175:INFO:    python: 3.9.13 (main, Aug 25 2022, 18:29:29)  [Clang 12.0.0 ]
2023-07-24 16:55:14,176:INFO:executable: /Users/iremkurt/opt/anaconda3/bin/python
2023-07-24 16:55:14,176:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-07-24 16:55:14,176:INFO:PyCaret required dependencies:
2023-07-24 16:55:14,176:INFO:                 pip: 23.2
2023-07-24 16:55:14,176:INFO:          setuptools: 63.4.1
2023-07-24 16:55:14,176:INFO:             pycaret: 3.0.4
2023-07-24 16:55:14,176:INFO:             IPython: 8.14.0
2023-07-24 16:55:14,176:INFO:          ipywidgets: 7.7.5
2023-07-24 16:55:14,176:INFO:                tqdm: 4.64.1
2023-07-24 16:55:14,176:INFO:               numpy: 1.23.5
2023-07-24 16:55:14,176:INFO:              pandas: 1.3.1
2023-07-24 16:55:14,176:INFO:              jinja2: 3.1.2
2023-07-24 16:55:14,176:INFO:               scipy: 1.9.1
2023-07-24 16:55:14,177:INFO:              joblib: 1.3.1
2023-07-24 16:55:14,177:INFO:             sklearn: 1.0.2
2023-07-24 16:55:14,177:INFO:                pyod: 1.1.0
2023-07-24 16:55:14,177:INFO:            imblearn: 0.11.0
2023-07-24 16:55:14,177:INFO:   category_encoders: 2.6.1
2023-07-24 16:55:14,177:INFO:            lightgbm: 4.0.0
2023-07-24 16:55:14,177:INFO:               numba: 0.57.1
2023-07-24 16:55:14,177:INFO:            requests: 2.28.1
2023-07-24 16:55:14,177:INFO:          matplotlib: 3.6.0
2023-07-24 16:55:14,177:INFO:          scikitplot: 0.3.7
2023-07-24 16:55:14,177:INFO:         yellowbrick: 1.5
2023-07-24 16:55:14,177:INFO:              plotly: 5.15.0
2023-07-24 16:55:14,177:INFO:    plotly-resampler: Not installed
2023-07-24 16:55:14,178:INFO:             kaleido: 0.2.1
2023-07-24 16:55:14,178:INFO:           schemdraw: 0.15
2023-07-24 16:55:14,178:INFO:         statsmodels: 0.13.2
2023-07-24 16:55:14,178:INFO:              sktime: 0.20.0
2023-07-24 16:55:14,178:INFO:               tbats: 1.1.3
2023-07-24 16:55:14,178:INFO:            pmdarima: 2.0.3
2023-07-24 16:55:14,178:INFO:              psutil: 5.9.5
2023-07-24 16:55:14,178:INFO:          markupsafe: 2.1.3
2023-07-24 16:55:14,178:INFO:             pickle5: Not installed
2023-07-24 16:55:14,178:INFO:         cloudpickle: 2.2.1
2023-07-24 16:55:14,178:INFO:         deprecation: 2.1.0
2023-07-24 16:55:14,178:INFO:              xxhash: 3.2.0
2023-07-24 16:55:14,178:INFO:           wurlitzer: 3.0.2
2023-07-24 16:55:14,178:INFO:PyCaret optional dependencies:
2023-07-24 16:55:14,178:INFO:                shap: 0.42.1
2023-07-24 16:55:14,178:INFO:           interpret: Not installed
2023-07-24 16:55:14,178:INFO:                umap: Not installed
2023-07-24 16:55:14,178:INFO:    pandas_profiling: 0.0.dev0
2023-07-24 16:55:14,179:INFO:  explainerdashboard: Not installed
2023-07-24 16:55:14,179:INFO:             autoviz: Not installed
2023-07-24 16:55:14,179:INFO:           fairlearn: Not installed
2023-07-24 16:55:14,179:INFO:          deepchecks: Not installed
2023-07-24 16:55:14,179:INFO:             xgboost: 1.7.6
2023-07-24 16:55:14,179:INFO:            catboost: Not installed
2023-07-24 16:55:14,179:INFO:              kmodes: Not installed
2023-07-24 16:55:14,179:INFO:             mlxtend: Not installed
2023-07-24 16:55:14,179:INFO:       statsforecast: Not installed
2023-07-24 16:55:14,179:INFO:        tune_sklearn: Not installed
2023-07-24 16:55:14,179:INFO:                 ray: Not installed
2023-07-24 16:55:14,179:INFO:            hyperopt: Not installed
2023-07-24 16:55:14,179:INFO:              optuna: Not installed
2023-07-24 16:55:14,181:INFO:               skopt: Not installed
2023-07-24 16:55:14,181:INFO:              mlflow: Not installed
2023-07-24 16:55:14,181:INFO:              gradio: Not installed
2023-07-24 16:55:14,181:INFO:             fastapi: 0.100.0
2023-07-24 16:55:14,181:INFO:             uvicorn: 0.23.0
2023-07-24 16:55:14,181:INFO:              m2cgen: Not installed
2023-07-24 16:55:14,181:INFO:           evidently: Not installed
2023-07-24 16:55:14,181:INFO:               fugue: Not installed
2023-07-24 16:55:14,182:INFO:           streamlit: 1.24.1
2023-07-24 16:55:14,182:INFO:             prophet: 1.1.4
2023-07-24 16:55:14,182:INFO:None
2023-07-24 16:55:14,182:INFO:Set up data.
2023-07-24 16:55:14,313:INFO:Set up train/test split.
2023-07-24 16:55:14,341:INFO:Set up index.
2023-07-24 16:55:14,342:INFO:Set up folding strategy.
2023-07-24 16:55:14,342:INFO:Assigning column types.
2023-07-24 16:55:14,374:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-07-24 16:55:14,374:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-07-24 16:55:14,383:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-07-24 16:55:14,392:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-24 16:55:14,503:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-24 16:55:14,599:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-24 16:55:14,601:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-24 16:55:14,609:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-24 16:55:14,610:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-07-24 16:55:14,623:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-07-24 16:55:14,635:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-24 16:55:14,827:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-24 16:55:14,918:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-24 16:55:14,918:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-24 16:55:14,924:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-24 16:55:14,924:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-07-24 16:55:14,934:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-07-24 16:55:14,944:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-24 16:55:15,111:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-24 16:55:15,264:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-24 16:55:15,265:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-24 16:55:15,274:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-24 16:55:15,297:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-07-24 16:55:15,310:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-24 16:55:15,946:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-24 16:55:16,085:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-24 16:55:16,086:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-24 16:55:16,093:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-24 16:55:16,094:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-07-24 16:55:16,111:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-24 16:55:16,217:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-24 16:55:16,429:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-24 16:55:16,430:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-24 16:55:16,435:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-24 16:55:16,465:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-07-24 16:55:16,796:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-24 16:55:16,969:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-24 16:55:16,976:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-24 16:55:16,985:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-24 16:55:16,987:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-07-24 16:55:17,221:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-24 16:55:17,414:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-24 16:55:17,415:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-24 16:55:17,423:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-24 16:55:17,624:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-24 16:55:17,820:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-24 16:55:17,821:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-24 16:55:17,831:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-24 16:55:17,832:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-07-24 16:55:17,997:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-24 16:55:18,067:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-24 16:55:18,072:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-24 16:55:18,315:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-07-24 16:55:18,530:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-24 16:55:18,535:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-24 16:55:18,536:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-07-24 16:55:18,826:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-24 16:55:18,831:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-24 16:55:19,181:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-24 16:55:19,190:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-24 16:55:19,191:INFO:Preparing preprocessing pipeline...
2023-07-24 16:55:19,191:INFO:Set up simple imputation.
2023-07-24 16:55:19,199:INFO:Set up encoding of categorical features.
2023-07-24 16:55:19,201:INFO:Set up column name cleaning.
2023-07-24 16:55:19,718:INFO:Finished creating preprocessing pipeline.
2023-07-24 16:55:19,747:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/q_/m4c7kcfx23lfngmh1d06_9_c0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['NDB_No', 'Water_(g)',
                                             'Protein_(g)', 'Lipid_Tot_(g)',
                                             'Ash_(g)', 'Carbohydrt_(g)',
                                             'Fiber_TD_(g)', 'Sugar_Tot_(g)',
                                             'Calcium_(mg)', 'Iron_(mg)',
                                             'Magnesium_(mg)',
                                             'Phosphorus_(mg)',
                                             'Potassium_(mg)', 'Sodium_(mg)'...
                 TransformerWrapper(include=['Shrt_Desc', 'GmWt_Desc1',
                                             'GmWt_Desc2'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(include=['Shrt_Desc', 'GmWt_Desc1',
                                             'GmWt_Desc2'],
                                    transformer=TargetEncoder(cols=['Shrt_Desc',
                                                                    'GmWt_Desc1',
                                                                    'GmWt_Desc2'],
                                                              handle_missing='return_nan'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-07-24 16:55:19,748:INFO:Creating final display dataframe.
2023-07-24 16:55:21,293:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target        Energ_Kcal
2                   Target type        Regression
3           Original data shape        (8790, 53)
4        Transformed data shape        (8790, 53)
5   Transformed train set shape        (6153, 53)
6    Transformed test set shape        (2637, 53)
7              Numeric features                49
8          Categorical features                 3
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator             KFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              74fd
2023-07-24 16:55:21,760:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-24 16:55:21,765:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-24 16:55:22,044:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-24 16:55:22,053:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-24 16:55:22,055:INFO:setup() successfully completed in 7.89s...............
2023-07-24 16:55:31,169:INFO:Initializing compare_models()
2023-07-24 16:55:31,173:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-07-24 16:55:31,174:INFO:Checking exceptions
2023-07-24 16:55:31,178:INFO:Preparing display monitor
2023-07-24 16:55:31,333:INFO:Initializing Linear Regression
2023-07-24 16:55:31,333:INFO:Total runtime is 1.0351339975992838e-05 minutes
2023-07-24 16:55:31,347:INFO:SubProcess create_model() called ==================================
2023-07-24 16:55:31,348:INFO:Initializing create_model()
2023-07-24 16:55:31,349:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcb90274c10>, model_only=True, return_train_score=False, kwargs={})
2023-07-24 16:55:31,349:INFO:Checking exceptions
2023-07-24 16:55:31,349:INFO:Importing libraries
2023-07-24 16:55:31,350:INFO:Copying training dataset
2023-07-24 16:55:31,380:INFO:Defining folds
2023-07-24 16:55:31,380:INFO:Declaring metric variables
2023-07-24 16:55:31,394:INFO:Importing untrained model
2023-07-24 16:55:31,413:INFO:Linear Regression Imported successfully
2023-07-24 16:55:31,465:INFO:Starting cross validation
2023-07-24 16:55:31,615:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-24 16:55:45,709:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.54s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_transformer = self._memory_fit(

2023-07-24 16:55:45,719:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.54s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_transformer = self._memory_fit(

2023-07-24 16:55:45,719:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.53s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_transformer = self._memory_fit(

2023-07-24 16:55:46,639:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.67s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_transform(

2023-07-24 16:55:55,131:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:55:57,582:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.61s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_transform(

2023-07-24 16:55:57,985:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.64s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_transform(

2023-07-24 16:55:58,420:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:56:00,563:INFO:Calculating mean and std
2023-07-24 16:56:00,566:INFO:Creating metrics dataframe
2023-07-24 16:56:00,587:INFO:Uploading results into container
2023-07-24 16:56:00,588:INFO:Uploading model into container now
2023-07-24 16:56:00,590:INFO:_master_model_container: 1
2023-07-24 16:56:00,590:INFO:_display_container: 2
2023-07-24 16:56:00,591:INFO:LinearRegression(n_jobs=-1)
2023-07-24 16:56:00,591:INFO:create_model() successfully completed......................................
2023-07-24 16:56:00,860:INFO:SubProcess create_model() end ==================================
2023-07-24 16:56:00,860:INFO:Creating metrics dataframe
2023-07-24 16:56:00,896:INFO:Initializing Lasso Regression
2023-07-24 16:56:00,896:INFO:Total runtime is 0.49272518555323286 minutes
2023-07-24 16:56:00,934:INFO:SubProcess create_model() called ==================================
2023-07-24 16:56:00,935:INFO:Initializing create_model()
2023-07-24 16:56:00,938:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcb90274c10>, model_only=True, return_train_score=False, kwargs={})
2023-07-24 16:56:00,938:INFO:Checking exceptions
2023-07-24 16:56:00,938:INFO:Importing libraries
2023-07-24 16:56:00,938:INFO:Copying training dataset
2023-07-24 16:56:01,007:INFO:Defining folds
2023-07-24 16:56:01,007:INFO:Declaring metric variables
2023-07-24 16:56:01,033:INFO:Importing untrained model
2023-07-24 16:56:01,051:INFO:Lasso Regression Imported successfully
2023-07-24 16:56:01,073:INFO:Starting cross validation
2023-07-24 16:56:01,080:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-24 16:56:02,718:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.71s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_transform(

2023-07-24 16:56:03,978:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:56:04,920:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.54s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_transform(

2023-07-24 16:56:04,921:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.57s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_transform(

2023-07-24 16:56:06,099:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.98s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_transform(

2023-07-24 16:56:06,147:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.73s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_transform(

2023-07-24 16:56:06,168:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.74s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_transform(

2023-07-24 16:56:06,419:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.92s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_transform(

2023-07-24 16:56:07,389:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.62s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_transform(

2023-07-24 16:56:07,404:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.60s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_transform(

2023-07-24 16:56:08,072:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.81s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:56:08,185:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.76s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:56:09,678:INFO:Calculating mean and std
2023-07-24 16:56:09,681:INFO:Creating metrics dataframe
2023-07-24 16:56:09,711:INFO:Uploading results into container
2023-07-24 16:56:09,713:INFO:Uploading model into container now
2023-07-24 16:56:09,714:INFO:_master_model_container: 2
2023-07-24 16:56:09,714:INFO:_display_container: 2
2023-07-24 16:56:09,715:INFO:Lasso(random_state=123)
2023-07-24 16:56:09,715:INFO:create_model() successfully completed......................................
2023-07-24 16:56:09,833:INFO:SubProcess create_model() end ==================================
2023-07-24 16:56:09,833:INFO:Creating metrics dataframe
2023-07-24 16:56:09,866:INFO:Initializing Ridge Regression
2023-07-24 16:56:09,866:INFO:Total runtime is 0.6422327160835266 minutes
2023-07-24 16:56:09,875:INFO:SubProcess create_model() called ==================================
2023-07-24 16:56:09,876:INFO:Initializing create_model()
2023-07-24 16:56:09,878:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcb90274c10>, model_only=True, return_train_score=False, kwargs={})
2023-07-24 16:56:09,878:INFO:Checking exceptions
2023-07-24 16:56:09,880:INFO:Importing libraries
2023-07-24 16:56:09,880:INFO:Copying training dataset
2023-07-24 16:56:09,905:INFO:Defining folds
2023-07-24 16:56:09,905:INFO:Declaring metric variables
2023-07-24 16:56:09,942:INFO:Importing untrained model
2023-07-24 16:56:09,969:INFO:Ridge Regression Imported successfully
2023-07-24 16:56:10,007:INFO:Starting cross validation
2023-07-24 16:56:10,017:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-24 16:56:12,367:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:56:12,470:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:56:13,245:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.07s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:56:13,732:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.88s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_transformer = self._memory_fit(

2023-07-24 16:56:14,119:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.74s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_transform(

2023-07-24 16:56:14,634:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.71s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_transform(

2023-07-24 16:56:16,083:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.96s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:56:16,128:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:108: UserWarning: Persisting input arguments took 0.68s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-07-24 16:56:16,529:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.78s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:56:16,914:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.76s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:56:16,988:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:108: UserWarning: Persisting input arguments took 0.63s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-07-24 16:56:17,569:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.68s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_transform(

2023-07-24 16:56:17,848:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.83s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:56:18,886:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.87s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_transform(

2023-07-24 16:56:19,182:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.66s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_transform(

2023-07-24 16:56:20,068:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:56:20,499:INFO:Calculating mean and std
2023-07-24 16:56:20,501:INFO:Creating metrics dataframe
2023-07-24 16:56:20,543:INFO:Uploading results into container
2023-07-24 16:56:20,549:INFO:Uploading model into container now
2023-07-24 16:56:20,550:INFO:_master_model_container: 3
2023-07-24 16:56:20,551:INFO:_display_container: 2
2023-07-24 16:56:20,551:INFO:Ridge(random_state=123)
2023-07-24 16:56:20,552:INFO:create_model() successfully completed......................................
2023-07-24 16:56:20,699:INFO:SubProcess create_model() end ==================================
2023-07-24 16:56:20,700:INFO:Creating metrics dataframe
2023-07-24 16:56:20,747:INFO:Initializing Elastic Net
2023-07-24 16:56:20,750:INFO:Total runtime is 0.8236207326253255 minutes
2023-07-24 16:56:20,769:INFO:SubProcess create_model() called ==================================
2023-07-24 16:56:20,769:INFO:Initializing create_model()
2023-07-24 16:56:20,770:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcb90274c10>, model_only=True, return_train_score=False, kwargs={})
2023-07-24 16:56:20,770:INFO:Checking exceptions
2023-07-24 16:56:20,770:INFO:Importing libraries
2023-07-24 16:56:20,771:INFO:Copying training dataset
2023-07-24 16:56:20,788:INFO:Defining folds
2023-07-24 16:56:20,789:INFO:Declaring metric variables
2023-07-24 16:56:20,803:INFO:Importing untrained model
2023-07-24 16:56:20,824:INFO:Elastic Net Imported successfully
2023-07-24 16:56:20,967:INFO:Starting cross validation
2023-07-24 16:56:20,981:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-24 16:56:22,570:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.63s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_transform(

2023-07-24 16:56:22,584:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.61s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_transform(

2023-07-24 16:56:22,592:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.54s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_transform(

2023-07-24 16:56:22,858:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-07-24 16:56:24,401:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.74s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:56:25,003:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:56:25,130:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:56:25,173:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:56:25,933:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.54s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_transformer = self._memory_fit(

2023-07-24 16:56:27,581:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:56:28,099:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:108: UserWarning: Persisting input arguments took 0.56s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-07-24 16:56:30,175:INFO:Calculating mean and std
2023-07-24 16:56:30,177:INFO:Creating metrics dataframe
2023-07-24 16:56:30,236:INFO:Uploading results into container
2023-07-24 16:56:30,237:INFO:Uploading model into container now
2023-07-24 16:56:30,237:INFO:_master_model_container: 4
2023-07-24 16:56:30,237:INFO:_display_container: 2
2023-07-24 16:56:30,238:INFO:ElasticNet(random_state=123)
2023-07-24 16:56:30,238:INFO:create_model() successfully completed......................................
2023-07-24 16:56:30,340:INFO:SubProcess create_model() end ==================================
2023-07-24 16:56:30,340:INFO:Creating metrics dataframe
2023-07-24 16:56:30,373:INFO:Initializing Least Angle Regression
2023-07-24 16:56:30,373:INFO:Total runtime is 0.9840111653010051 minutes
2023-07-24 16:56:30,383:INFO:SubProcess create_model() called ==================================
2023-07-24 16:56:30,384:INFO:Initializing create_model()
2023-07-24 16:56:30,384:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcb90274c10>, model_only=True, return_train_score=False, kwargs={})
2023-07-24 16:56:30,385:INFO:Checking exceptions
2023-07-24 16:56:30,385:INFO:Importing libraries
2023-07-24 16:56:30,385:INFO:Copying training dataset
2023-07-24 16:56:30,400:INFO:Defining folds
2023-07-24 16:56:30,401:INFO:Declaring metric variables
2023-07-24 16:56:30,409:INFO:Importing untrained model
2023-07-24 16:56:30,422:INFO:Least Angle Regression Imported successfully
2023-07-24 16:56:30,466:INFO:Starting cross validation
2023-07-24 16:56:30,469:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-24 16:56:31,122:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-24 16:56:31,189:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-24 16:56:31,205:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-24 16:56:31,208:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-24 16:56:32,677:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-24 16:56:32,771:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-24 16:56:32,818:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-24 16:56:32,956:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-24 16:56:33,974:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:56:34,147:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:56:34,629:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:56:34,732:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:56:34,885:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-24 16:56:35,258:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-24 16:56:35,994:INFO:Calculating mean and std
2023-07-24 16:56:35,999:INFO:Creating metrics dataframe
2023-07-24 16:56:36,054:INFO:Uploading results into container
2023-07-24 16:56:36,056:INFO:Uploading model into container now
2023-07-24 16:56:36,057:INFO:_master_model_container: 5
2023-07-24 16:56:36,057:INFO:_display_container: 2
2023-07-24 16:56:36,057:INFO:Lars(random_state=123)
2023-07-24 16:56:36,057:INFO:create_model() successfully completed......................................
2023-07-24 16:56:36,214:INFO:SubProcess create_model() end ==================================
2023-07-24 16:56:36,215:INFO:Creating metrics dataframe
2023-07-24 16:56:36,241:INFO:Initializing Lasso Least Angle Regression
2023-07-24 16:56:36,241:INFO:Total runtime is 1.0818116307258607 minutes
2023-07-24 16:56:36,257:INFO:SubProcess create_model() called ==================================
2023-07-24 16:56:36,258:INFO:Initializing create_model()
2023-07-24 16:56:36,258:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcb90274c10>, model_only=True, return_train_score=False, kwargs={})
2023-07-24 16:56:36,258:INFO:Checking exceptions
2023-07-24 16:56:36,258:INFO:Importing libraries
2023-07-24 16:56:36,258:INFO:Copying training dataset
2023-07-24 16:56:36,286:INFO:Defining folds
2023-07-24 16:56:36,287:INFO:Declaring metric variables
2023-07-24 16:56:36,303:INFO:Importing untrained model
2023-07-24 16:56:36,312:INFO:Lasso Least Angle Regression Imported successfully
2023-07-24 16:56:36,345:INFO:Starting cross validation
2023-07-24 16:56:36,349:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-24 16:56:37,221:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-24 16:56:37,243:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-24 16:56:37,282:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-24 16:56:37,508:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-24 16:56:38,362:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.74s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:56:38,386:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:56:38,498:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.68s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:56:38,719:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:56:39,065:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-24 16:56:39,220:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-24 16:56:39,323:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-24 16:56:39,738:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-24 16:56:40,325:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:56:40,469:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:56:40,971:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-24 16:56:41,027:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-24 16:56:41,948:INFO:Calculating mean and std
2023-07-24 16:56:41,955:INFO:Creating metrics dataframe
2023-07-24 16:56:42,013:INFO:Uploading results into container
2023-07-24 16:56:42,014:INFO:Uploading model into container now
2023-07-24 16:56:42,015:INFO:_master_model_container: 6
2023-07-24 16:56:42,015:INFO:_display_container: 2
2023-07-24 16:56:42,018:INFO:LassoLars(random_state=123)
2023-07-24 16:56:42,019:INFO:create_model() successfully completed......................................
2023-07-24 16:56:42,173:INFO:SubProcess create_model() end ==================================
2023-07-24 16:56:42,174:INFO:Creating metrics dataframe
2023-07-24 16:56:42,216:INFO:Initializing Orthogonal Matching Pursuit
2023-07-24 16:56:42,216:INFO:Total runtime is 1.1813973506291708 minutes
2023-07-24 16:56:42,223:INFO:SubProcess create_model() called ==================================
2023-07-24 16:56:42,224:INFO:Initializing create_model()
2023-07-24 16:56:42,224:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcb90274c10>, model_only=True, return_train_score=False, kwargs={})
2023-07-24 16:56:42,224:INFO:Checking exceptions
2023-07-24 16:56:42,224:INFO:Importing libraries
2023-07-24 16:56:42,225:INFO:Copying training dataset
2023-07-24 16:56:42,240:INFO:Defining folds
2023-07-24 16:56:42,241:INFO:Declaring metric variables
2023-07-24 16:56:42,260:INFO:Importing untrained model
2023-07-24 16:56:42,271:INFO:Orthogonal Matching Pursuit Imported successfully
2023-07-24 16:56:42,288:INFO:Starting cross validation
2023-07-24 16:56:42,291:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-24 16:56:43,019:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-24 16:56:43,055:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-24 16:56:43,108:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2023-07-24 16:56:43,117:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-24 16:56:43,164:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-24 16:56:44,551:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:56:45,170:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-24 16:56:45,290:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-24 16:56:45,386:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-24 16:56:45,427:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-24 16:56:46,281:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:56:46,325:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:56:46,560:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:56:46,574:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:56:46,961:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-24 16:56:46,965:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-24 16:56:46,981:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2023-07-24 16:56:47,818:INFO:Calculating mean and std
2023-07-24 16:56:47,820:INFO:Creating metrics dataframe
2023-07-24 16:56:47,859:INFO:Uploading results into container
2023-07-24 16:56:47,860:INFO:Uploading model into container now
2023-07-24 16:56:47,861:INFO:_master_model_container: 7
2023-07-24 16:56:47,862:INFO:_display_container: 2
2023-07-24 16:56:47,862:INFO:OrthogonalMatchingPursuit()
2023-07-24 16:56:47,862:INFO:create_model() successfully completed......................................
2023-07-24 16:56:47,998:INFO:SubProcess create_model() end ==================================
2023-07-24 16:56:47,999:INFO:Creating metrics dataframe
2023-07-24 16:56:48,031:INFO:Initializing Bayesian Ridge
2023-07-24 16:56:48,032:INFO:Total runtime is 1.2783210317293805 minutes
2023-07-24 16:56:48,039:INFO:SubProcess create_model() called ==================================
2023-07-24 16:56:48,039:INFO:Initializing create_model()
2023-07-24 16:56:48,039:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcb90274c10>, model_only=True, return_train_score=False, kwargs={})
2023-07-24 16:56:48,039:INFO:Checking exceptions
2023-07-24 16:56:48,040:INFO:Importing libraries
2023-07-24 16:56:48,040:INFO:Copying training dataset
2023-07-24 16:56:48,057:INFO:Defining folds
2023-07-24 16:56:48,062:INFO:Declaring metric variables
2023-07-24 16:56:48,074:INFO:Importing untrained model
2023-07-24 16:56:48,092:INFO:Bayesian Ridge Imported successfully
2023-07-24 16:56:48,136:INFO:Starting cross validation
2023-07-24 16:56:48,139:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-24 16:56:50,169:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.68s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:56:50,225:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.68s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:56:50,405:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.77s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:56:51,016:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.84s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:56:51,906:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.90s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_transformer = self._memory_fit(

2023-07-24 16:56:53,193:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.86s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_transform(

2023-07-24 16:56:53,443:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.77s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-07-24 16:56:53,676:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:108: UserWarning: Persisting input arguments took 0.95s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-07-24 16:56:53,958:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-07-24 16:56:54,229:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.90s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:56:55,149:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:56:56,250:INFO:Calculating mean and std
2023-07-24 16:56:56,252:INFO:Creating metrics dataframe
2023-07-24 16:56:56,293:INFO:Uploading results into container
2023-07-24 16:56:56,294:INFO:Uploading model into container now
2023-07-24 16:56:56,295:INFO:_master_model_container: 8
2023-07-24 16:56:56,296:INFO:_display_container: 2
2023-07-24 16:56:56,296:INFO:BayesianRidge()
2023-07-24 16:56:56,297:INFO:create_model() successfully completed......................................
2023-07-24 16:56:56,408:INFO:SubProcess create_model() end ==================================
2023-07-24 16:56:56,408:INFO:Creating metrics dataframe
2023-07-24 16:56:56,430:INFO:Initializing Passive Aggressive Regressor
2023-07-24 16:56:56,431:INFO:Total runtime is 1.4183113018671674 minutes
2023-07-24 16:56:56,438:INFO:SubProcess create_model() called ==================================
2023-07-24 16:56:56,438:INFO:Initializing create_model()
2023-07-24 16:56:56,438:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcb90274c10>, model_only=True, return_train_score=False, kwargs={})
2023-07-24 16:56:56,439:INFO:Checking exceptions
2023-07-24 16:56:56,439:INFO:Importing libraries
2023-07-24 16:56:56,440:INFO:Copying training dataset
2023-07-24 16:56:56,458:INFO:Defining folds
2023-07-24 16:56:56,458:INFO:Declaring metric variables
2023-07-24 16:56:56,468:INFO:Importing untrained model
2023-07-24 16:56:56,477:INFO:Passive Aggressive Regressor Imported successfully
2023-07-24 16:56:56,507:INFO:Starting cross validation
2023-07-24 16:56:56,510:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-24 16:56:57,545:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.59s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_transform(

2023-07-24 16:56:57,561:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.59s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_transform(

2023-07-24 16:56:59,341:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:57:00,989:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.63s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-07-24 16:57:01,102:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.63s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-07-24 16:57:01,179:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-07-24 16:57:02,214:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:108: UserWarning: Persisting input arguments took 0.58s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-07-24 16:57:02,659:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.85s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:57:02,845:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.86s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:57:02,878:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.84s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:57:03,418:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.79s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:57:04,908:INFO:Calculating mean and std
2023-07-24 16:57:04,910:INFO:Creating metrics dataframe
2023-07-24 16:57:04,959:INFO:Uploading results into container
2023-07-24 16:57:04,960:INFO:Uploading model into container now
2023-07-24 16:57:04,961:INFO:_master_model_container: 9
2023-07-24 16:57:04,961:INFO:_display_container: 2
2023-07-24 16:57:04,961:INFO:PassiveAggressiveRegressor(random_state=123)
2023-07-24 16:57:04,961:INFO:create_model() successfully completed......................................
2023-07-24 16:57:05,084:INFO:SubProcess create_model() end ==================================
2023-07-24 16:57:05,084:INFO:Creating metrics dataframe
2023-07-24 16:57:05,117:INFO:Initializing Huber Regressor
2023-07-24 16:57:05,117:INFO:Total runtime is 1.5630793809890748 minutes
2023-07-24 16:57:05,124:INFO:SubProcess create_model() called ==================================
2023-07-24 16:57:05,125:INFO:Initializing create_model()
2023-07-24 16:57:05,125:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcb90274c10>, model_only=True, return_train_score=False, kwargs={})
2023-07-24 16:57:05,125:INFO:Checking exceptions
2023-07-24 16:57:05,125:INFO:Importing libraries
2023-07-24 16:57:05,125:INFO:Copying training dataset
2023-07-24 16:57:05,141:INFO:Defining folds
2023-07-24 16:57:05,141:INFO:Declaring metric variables
2023-07-24 16:57:05,156:INFO:Importing untrained model
2023-07-24 16:57:05,163:INFO:Huber Regressor Imported successfully
2023-07-24 16:57:05,178:INFO:Starting cross validation
2023-07-24 16:57:05,181:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-24 16:57:07,077:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-07-24 16:57:07,077:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-07-24 16:57:07,119:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-07-24 16:57:07,190:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-07-24 16:57:08,229:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:57:08,258:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:57:08,338:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:57:08,475:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:57:10,411:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-07-24 16:57:10,428:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-07-24 16:57:10,455:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-07-24 16:57:10,806:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-07-24 16:57:11,488:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-07-24 16:57:12,071:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:108: UserWarning: Persisting input arguments took 0.54s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-07-24 16:57:12,405:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:57:12,492:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:57:12,842:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:57:12,843:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:57:13,549:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-07-24 16:57:13,585:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-07-24 16:57:14,135:INFO:Calculating mean and std
2023-07-24 16:57:14,136:INFO:Creating metrics dataframe
2023-07-24 16:57:14,217:INFO:Uploading results into container
2023-07-24 16:57:14,217:INFO:Uploading model into container now
2023-07-24 16:57:14,218:INFO:_master_model_container: 10
2023-07-24 16:57:14,218:INFO:_display_container: 2
2023-07-24 16:57:14,218:INFO:HuberRegressor()
2023-07-24 16:57:14,218:INFO:create_model() successfully completed......................................
2023-07-24 16:57:14,319:INFO:SubProcess create_model() end ==================================
2023-07-24 16:57:14,320:INFO:Creating metrics dataframe
2023-07-24 16:57:14,344:INFO:Initializing K Neighbors Regressor
2023-07-24 16:57:14,344:INFO:Total runtime is 1.7168617169062297 minutes
2023-07-24 16:57:14,353:INFO:SubProcess create_model() called ==================================
2023-07-24 16:57:14,353:INFO:Initializing create_model()
2023-07-24 16:57:14,354:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcb90274c10>, model_only=True, return_train_score=False, kwargs={})
2023-07-24 16:57:14,354:INFO:Checking exceptions
2023-07-24 16:57:14,354:INFO:Importing libraries
2023-07-24 16:57:14,355:INFO:Copying training dataset
2023-07-24 16:57:14,372:INFO:Defining folds
2023-07-24 16:57:14,372:INFO:Declaring metric variables
2023-07-24 16:57:14,405:INFO:Importing untrained model
2023-07-24 16:57:14,421:INFO:K Neighbors Regressor Imported successfully
2023-07-24 16:57:14,451:INFO:Starting cross validation
2023-07-24 16:57:14,455:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-24 16:57:16,220:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:57:18,054:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:57:19,416:INFO:Calculating mean and std
2023-07-24 16:57:19,421:INFO:Creating metrics dataframe
2023-07-24 16:57:19,479:INFO:Uploading results into container
2023-07-24 16:57:19,480:INFO:Uploading model into container now
2023-07-24 16:57:19,480:INFO:_master_model_container: 11
2023-07-24 16:57:19,480:INFO:_display_container: 2
2023-07-24 16:57:19,480:INFO:KNeighborsRegressor(n_jobs=-1)
2023-07-24 16:57:19,480:INFO:create_model() successfully completed......................................
2023-07-24 16:57:19,593:INFO:SubProcess create_model() end ==================================
2023-07-24 16:57:19,593:INFO:Creating metrics dataframe
2023-07-24 16:57:19,619:INFO:Initializing Decision Tree Regressor
2023-07-24 16:57:19,619:INFO:Total runtime is 1.8047838966051737 minutes
2023-07-24 16:57:19,625:INFO:SubProcess create_model() called ==================================
2023-07-24 16:57:19,625:INFO:Initializing create_model()
2023-07-24 16:57:19,625:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcb90274c10>, model_only=True, return_train_score=False, kwargs={})
2023-07-24 16:57:19,625:INFO:Checking exceptions
2023-07-24 16:57:19,626:INFO:Importing libraries
2023-07-24 16:57:19,626:INFO:Copying training dataset
2023-07-24 16:57:19,643:INFO:Defining folds
2023-07-24 16:57:19,644:INFO:Declaring metric variables
2023-07-24 16:57:19,687:INFO:Importing untrained model
2023-07-24 16:57:19,711:INFO:Decision Tree Regressor Imported successfully
2023-07-24 16:57:19,744:INFO:Starting cross validation
2023-07-24 16:57:19,759:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-24 16:57:24,628:INFO:Calculating mean and std
2023-07-24 16:57:24,630:INFO:Creating metrics dataframe
2023-07-24 16:57:24,720:INFO:Uploading results into container
2023-07-24 16:57:24,721:INFO:Uploading model into container now
2023-07-24 16:57:24,721:INFO:_master_model_container: 12
2023-07-24 16:57:24,721:INFO:_display_container: 2
2023-07-24 16:57:24,722:INFO:DecisionTreeRegressor(random_state=123)
2023-07-24 16:57:24,722:INFO:create_model() successfully completed......................................
2023-07-24 16:57:24,822:INFO:SubProcess create_model() end ==================================
2023-07-24 16:57:24,823:INFO:Creating metrics dataframe
2023-07-24 16:57:24,846:INFO:Initializing Random Forest Regressor
2023-07-24 16:57:24,846:INFO:Total runtime is 1.891894201437632 minutes
2023-07-24 16:57:24,855:INFO:SubProcess create_model() called ==================================
2023-07-24 16:57:24,856:INFO:Initializing create_model()
2023-07-24 16:57:24,856:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcb90274c10>, model_only=True, return_train_score=False, kwargs={})
2023-07-24 16:57:24,857:INFO:Checking exceptions
2023-07-24 16:57:24,857:INFO:Importing libraries
2023-07-24 16:57:24,857:INFO:Copying training dataset
2023-07-24 16:57:24,879:INFO:Defining folds
2023-07-24 16:57:24,881:INFO:Declaring metric variables
2023-07-24 16:57:24,913:INFO:Importing untrained model
2023-07-24 16:57:24,928:INFO:Random Forest Regressor Imported successfully
2023-07-24 16:57:24,953:INFO:Starting cross validation
2023-07-24 16:57:24,958:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-24 16:57:43,599:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:57:43,700:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:57:43,722:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:58:03,078:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.74s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-07-24 16:58:03,196:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-07-24 16:58:03,327:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-07-24 16:58:03,617:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-07-24 16:58:04,834:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.89s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:58:04,929:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.77s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:58:05,086:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.83s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:58:05,474:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.98s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:58:16,025:INFO:Calculating mean and std
2023-07-24 16:58:16,035:INFO:Creating metrics dataframe
2023-07-24 16:58:16,196:INFO:Uploading results into container
2023-07-24 16:58:16,200:INFO:Uploading model into container now
2023-07-24 16:58:16,201:INFO:_master_model_container: 13
2023-07-24 16:58:16,201:INFO:_display_container: 2
2023-07-24 16:58:16,202:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-07-24 16:58:16,202:INFO:create_model() successfully completed......................................
2023-07-24 16:58:16,385:INFO:SubProcess create_model() end ==================================
2023-07-24 16:58:16,386:INFO:Creating metrics dataframe
2023-07-24 16:58:16,425:INFO:Initializing Extra Trees Regressor
2023-07-24 16:58:16,426:INFO:Total runtime is 2.751554501056671 minutes
2023-07-24 16:58:16,434:INFO:SubProcess create_model() called ==================================
2023-07-24 16:58:16,435:INFO:Initializing create_model()
2023-07-24 16:58:16,435:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcb90274c10>, model_only=True, return_train_score=False, kwargs={})
2023-07-24 16:58:16,435:INFO:Checking exceptions
2023-07-24 16:58:16,437:INFO:Importing libraries
2023-07-24 16:58:16,437:INFO:Copying training dataset
2023-07-24 16:58:16,469:INFO:Defining folds
2023-07-24 16:58:16,469:INFO:Declaring metric variables
2023-07-24 16:58:16,496:INFO:Importing untrained model
2023-07-24 16:58:16,512:INFO:Extra Trees Regressor Imported successfully
2023-07-24 16:58:16,533:INFO:Starting cross validation
2023-07-24 16:58:16,544:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-24 16:58:25,128:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.00s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-07-24 16:58:25,487:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.82s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-07-24 16:58:25,603:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.75s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-07-24 16:58:25,635:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.74s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-07-24 16:58:26,909:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:58:27,065:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:58:27,177:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:58:27,214:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:58:36,644:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.21s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-07-24 16:58:36,938:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-07-24 16:58:37,069:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-07-24 16:58:37,940:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:58:38,388:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.86s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:58:38,581:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.84s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:58:39,334:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.40s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:58:44,171:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-07-24 16:58:45,734:INFO:Calculating mean and std
2023-07-24 16:58:45,738:INFO:Creating metrics dataframe
2023-07-24 16:58:45,831:INFO:Uploading results into container
2023-07-24 16:58:45,832:INFO:Uploading model into container now
2023-07-24 16:58:45,832:INFO:_master_model_container: 14
2023-07-24 16:58:45,832:INFO:_display_container: 2
2023-07-24 16:58:45,833:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-07-24 16:58:45,833:INFO:create_model() successfully completed......................................
2023-07-24 16:58:45,944:INFO:SubProcess create_model() end ==================================
2023-07-24 16:58:45,944:INFO:Creating metrics dataframe
2023-07-24 16:58:45,971:INFO:Initializing AdaBoost Regressor
2023-07-24 16:58:45,972:INFO:Total runtime is 3.243988466262817 minutes
2023-07-24 16:58:45,980:INFO:SubProcess create_model() called ==================================
2023-07-24 16:58:45,981:INFO:Initializing create_model()
2023-07-24 16:58:45,981:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcb90274c10>, model_only=True, return_train_score=False, kwargs={})
2023-07-24 16:58:45,981:INFO:Checking exceptions
2023-07-24 16:58:45,982:INFO:Importing libraries
2023-07-24 16:58:45,983:INFO:Copying training dataset
2023-07-24 16:58:46,016:INFO:Defining folds
2023-07-24 16:58:46,017:INFO:Declaring metric variables
2023-07-24 16:58:46,150:INFO:Importing untrained model
2023-07-24 16:58:46,169:INFO:AdaBoost Regressor Imported successfully
2023-07-24 16:58:46,194:INFO:Starting cross validation
2023-07-24 16:58:46,196:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-24 16:59:00,482:INFO:Calculating mean and std
2023-07-24 16:59:00,485:INFO:Creating metrics dataframe
2023-07-24 16:59:00,598:INFO:Uploading results into container
2023-07-24 16:59:00,599:INFO:Uploading model into container now
2023-07-24 16:59:00,600:INFO:_master_model_container: 15
2023-07-24 16:59:00,600:INFO:_display_container: 2
2023-07-24 16:59:00,601:INFO:AdaBoostRegressor(random_state=123)
2023-07-24 16:59:00,601:INFO:create_model() successfully completed......................................
2023-07-24 16:59:00,699:INFO:SubProcess create_model() end ==================================
2023-07-24 16:59:00,699:INFO:Creating metrics dataframe
2023-07-24 16:59:00,724:INFO:Initializing Gradient Boosting Regressor
2023-07-24 16:59:00,725:INFO:Total runtime is 3.4898721496264136 minutes
2023-07-24 16:59:00,732:INFO:SubProcess create_model() called ==================================
2023-07-24 16:59:00,733:INFO:Initializing create_model()
2023-07-24 16:59:00,734:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcb90274c10>, model_only=True, return_train_score=False, kwargs={})
2023-07-24 16:59:00,734:INFO:Checking exceptions
2023-07-24 16:59:00,734:INFO:Importing libraries
2023-07-24 16:59:00,734:INFO:Copying training dataset
2023-07-24 16:59:00,752:INFO:Defining folds
2023-07-24 16:59:00,752:INFO:Declaring metric variables
2023-07-24 16:59:00,764:INFO:Importing untrained model
2023-07-24 16:59:00,824:INFO:Gradient Boosting Regressor Imported successfully
2023-07-24 16:59:00,853:INFO:Starting cross validation
2023-07-24 16:59:00,859:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-24 16:59:19,101:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 16:59:25,025:INFO:Calculating mean and std
2023-07-24 16:59:25,029:INFO:Creating metrics dataframe
2023-07-24 16:59:25,088:INFO:Uploading results into container
2023-07-24 16:59:25,089:INFO:Uploading model into container now
2023-07-24 16:59:25,089:INFO:_master_model_container: 16
2023-07-24 16:59:25,089:INFO:_display_container: 2
2023-07-24 16:59:25,090:INFO:GradientBoostingRegressor(random_state=123)
2023-07-24 16:59:25,090:INFO:create_model() successfully completed......................................
2023-07-24 16:59:25,187:INFO:SubProcess create_model() end ==================================
2023-07-24 16:59:25,188:INFO:Creating metrics dataframe
2023-07-24 16:59:25,210:INFO:Initializing Extreme Gradient Boosting
2023-07-24 16:59:25,211:INFO:Total runtime is 3.8979725837707515 minutes
2023-07-24 16:59:25,218:INFO:SubProcess create_model() called ==================================
2023-07-24 16:59:25,219:INFO:Initializing create_model()
2023-07-24 16:59:25,219:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcb90274c10>, model_only=True, return_train_score=False, kwargs={})
2023-07-24 16:59:25,219:INFO:Checking exceptions
2023-07-24 16:59:25,220:INFO:Importing libraries
2023-07-24 16:59:25,220:INFO:Copying training dataset
2023-07-24 16:59:25,236:INFO:Defining folds
2023-07-24 16:59:25,237:INFO:Declaring metric variables
2023-07-24 16:59:25,263:INFO:Importing untrained model
2023-07-24 16:59:25,274:INFO:Extreme Gradient Boosting Imported successfully
2023-07-24 16:59:25,298:INFO:Starting cross validation
2023-07-24 16:59:25,301:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-24 16:59:46,376:INFO:Calculating mean and std
2023-07-24 16:59:46,377:INFO:Creating metrics dataframe
2023-07-24 16:59:46,496:INFO:Uploading results into container
2023-07-24 16:59:46,497:INFO:Uploading model into container now
2023-07-24 16:59:46,498:INFO:_master_model_container: 17
2023-07-24 16:59:46,499:INFO:_display_container: 2
2023-07-24 16:59:46,500:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=123, ...)
2023-07-24 16:59:46,501:INFO:create_model() successfully completed......................................
2023-07-24 16:59:46,601:INFO:SubProcess create_model() end ==================================
2023-07-24 16:59:46,601:INFO:Creating metrics dataframe
2023-07-24 16:59:46,633:INFO:Initializing Light Gradient Boosting Machine
2023-07-24 16:59:46,634:INFO:Total runtime is 4.255022251605987 minutes
2023-07-24 16:59:46,642:INFO:SubProcess create_model() called ==================================
2023-07-24 16:59:46,643:INFO:Initializing create_model()
2023-07-24 16:59:46,644:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcb90274c10>, model_only=True, return_train_score=False, kwargs={})
2023-07-24 16:59:46,644:INFO:Checking exceptions
2023-07-24 16:59:46,644:INFO:Importing libraries
2023-07-24 16:59:46,645:INFO:Copying training dataset
2023-07-24 16:59:46,669:INFO:Defining folds
2023-07-24 16:59:46,671:INFO:Declaring metric variables
2023-07-24 16:59:46,695:INFO:Importing untrained model
2023-07-24 16:59:46,726:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-24 16:59:46,754:INFO:Starting cross validation
2023-07-24 16:59:46,756:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-24 16:59:48,203:WARNING:create_model() for lightgbm raised an exception or returned all 0.0, trying without fit_kwargs:
2023-07-24 16:59:48,217:WARNING:Traceback (most recent call last):
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1521, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1116, in _create_model_with_cv
    scores = cross_validate(
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 267, in cross_validate
    results = parallel(
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 1944, in __call__
    return output if self.return_generator else list(output)
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 1587, in _get_outputs
    yield from self._retrieve()
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 1691, in _retrieve
    self._raise_error_fast()
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 1726, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 735, in get_result
    return self._return_or_raise()
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 753, in _return_or_raise
    raise self._result
joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.

The exit codes of the workers are {SIGSEGV(-11)}

2023-07-24 16:59:48,218:INFO:Initializing create_model()
2023-07-24 16:59:48,218:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcb90274c10>, model_only=True, return_train_score=False, kwargs={})
2023-07-24 16:59:48,218:INFO:Checking exceptions
2023-07-24 16:59:48,218:INFO:Importing libraries
2023-07-24 16:59:48,218:INFO:Copying training dataset
2023-07-24 16:59:48,230:INFO:Defining folds
2023-07-24 16:59:48,230:INFO:Declaring metric variables
2023-07-24 16:59:48,240:INFO:Importing untrained model
2023-07-24 16:59:48,246:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-24 16:59:48,270:INFO:Starting cross validation
2023-07-24 16:59:48,273:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-24 16:59:58,058:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-07-24 16:59:58,075:INFO:[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010120 seconds.
2023-07-24 16:59:58,075:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-07-24 16:59:58,076:INFO:[LightGBM] [Info] Total Bins 11785
2023-07-24 16:59:58,081:INFO:[LightGBM] [Info] Number of data points in the train set: 5537, number of used features: 52
2023-07-24 16:59:58,084:INFO:[LightGBM] [Info] Start training from score 224.349106
2023-07-24 16:59:58,980:ERROR:create_model() for lightgbm raised an exception or returned all 0.0:
2023-07-24 16:59:58,981:ERROR:Traceback (most recent call last):
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1521, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1116, in _create_model_with_cv
    scores = cross_validate(
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 267, in cross_validate
    results = parallel(
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 1944, in __call__
    return output if self.return_generator else list(output)
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 1587, in _get_outputs
    yield from self._retrieve()
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 1691, in _retrieve
    self._raise_error_fast()
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 1726, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 735, in get_result
    return self._return_or_raise()
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 753, in _return_or_raise
    raise self._result
joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.

The exit codes of the workers are {SIGSEGV(-11)}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1521, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1116, in _create_model_with_cv
    scores = cross_validate(
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 267, in cross_validate
    results = parallel(
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 1944, in __call__
    return output if self.return_generator else list(output)
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 1587, in _get_outputs
    yield from self._retrieve()
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 1691, in _retrieve
    self._raise_error_fast()
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 1726, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 735, in get_result
    return self._return_or_raise()
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 753, in _return_or_raise
    raise self._result
joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.

The exit codes of the workers are {SIGSEGV(-11)}

2023-07-24 16:59:58,981:INFO:Initializing Dummy Regressor
2023-07-24 16:59:58,981:INFO:Total runtime is 4.460818334420521 minutes
2023-07-24 16:59:58,988:INFO:SubProcess create_model() called ==================================
2023-07-24 16:59:58,989:INFO:Initializing create_model()
2023-07-24 16:59:58,989:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcb90274c10>, model_only=True, return_train_score=False, kwargs={})
2023-07-24 16:59:58,989:INFO:Checking exceptions
2023-07-24 16:59:58,990:INFO:Importing libraries
2023-07-24 16:59:58,990:INFO:Copying training dataset
2023-07-24 16:59:59,008:INFO:Defining folds
2023-07-24 16:59:59,008:INFO:Declaring metric variables
2023-07-24 16:59:59,017:INFO:Importing untrained model
2023-07-24 16:59:59,025:INFO:Dummy Regressor Imported successfully
2023-07-24 16:59:59,053:INFO:Starting cross validation
2023-07-24 16:59:59,057:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-24 17:00:07,862:INFO:Calculating mean and std
2023-07-24 17:00:07,865:INFO:Creating metrics dataframe
2023-07-24 17:00:08,002:INFO:Uploading results into container
2023-07-24 17:00:08,003:INFO:Uploading model into container now
2023-07-24 17:00:08,005:INFO:_master_model_container: 18
2023-07-24 17:00:08,005:INFO:_display_container: 2
2023-07-24 17:00:08,005:INFO:DummyRegressor()
2023-07-24 17:00:08,005:INFO:create_model() successfully completed......................................
2023-07-24 17:00:08,120:INFO:SubProcess create_model() end ==================================
2023-07-24 17:00:08,120:INFO:Creating metrics dataframe
2023-07-24 17:00:08,170:INFO:Initializing create_model()
2023-07-24 17:00:08,171:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=PassiveAggressiveRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-24 17:00:08,171:INFO:Checking exceptions
2023-07-24 17:00:08,174:INFO:Importing libraries
2023-07-24 17:00:08,174:INFO:Copying training dataset
2023-07-24 17:00:08,187:INFO:Defining folds
2023-07-24 17:00:08,188:INFO:Declaring metric variables
2023-07-24 17:00:08,188:INFO:Importing untrained model
2023-07-24 17:00:08,188:INFO:Declaring custom model
2023-07-24 17:00:08,189:INFO:Passive Aggressive Regressor Imported successfully
2023-07-24 17:00:08,192:INFO:Cross validation set to False
2023-07-24 17:00:08,192:INFO:Fitting Model
2023-07-24 17:00:11,878:INFO:PassiveAggressiveRegressor(random_state=123)
2023-07-24 17:00:11,878:INFO:create_model() successfully completed......................................
2023-07-24 17:00:12,066:INFO:_master_model_container: 18
2023-07-24 17:00:12,067:INFO:_display_container: 2
2023-07-24 17:00:12,068:INFO:PassiveAggressiveRegressor(random_state=123)
2023-07-24 17:00:12,069:INFO:compare_models() successfully completed......................................
2023-07-24 17:00:55,728:INFO:Initializing evaluate_model()
2023-07-24 17:00:55,728:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=PassiveAggressiveRegressor(random_state=123), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-24 17:00:55,768:INFO:Initializing plot_model()
2023-07-24 17:00:55,768:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=PassiveAggressiveRegressor(random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, system=True)
2023-07-24 17:00:55,769:INFO:Checking exceptions
2023-07-24 17:00:55,775:INFO:Preloading libraries
2023-07-24 17:00:55,775:INFO:Copying training dataset
2023-07-24 17:00:55,778:INFO:Plot type: pipeline
2023-07-24 17:00:56,543:INFO:Visual Rendered Successfully
2023-07-24 17:00:56,677:INFO:plot_model() successfully completed......................................
2023-07-24 17:01:04,801:INFO:Initializing plot_model()
2023-07-24 17:01:04,804:INFO:plot_model(plot=learning, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=PassiveAggressiveRegressor(random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, system=True)
2023-07-24 17:01:04,806:INFO:Checking exceptions
2023-07-24 17:01:04,813:INFO:Preloading libraries
2023-07-24 17:01:04,814:INFO:Copying training dataset
2023-07-24 17:01:04,814:INFO:Plot type: learning
2023-07-24 17:01:05,111:INFO:Fitting Model
2023-07-24 17:01:15,033:INFO:Visual Rendered Successfully
2023-07-24 17:01:15,124:INFO:plot_model() successfully completed......................................
2023-07-24 17:02:14,700:INFO:Initializing plot_model()
2023-07-24 17:02:14,700:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=PassiveAggressiveRegressor(random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, system=True)
2023-07-24 17:02:14,701:INFO:Checking exceptions
2023-07-24 17:02:14,721:INFO:Preloading libraries
2023-07-24 17:02:14,721:INFO:Copying training dataset
2023-07-24 17:02:14,721:INFO:Plot type: residuals
2023-07-24 17:02:15,422:INFO:Fitting Model
2023-07-24 17:02:15,426:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but PassiveAggressiveRegressor was fitted with feature names
  warnings.warn(

2023-07-24 17:02:15,508:INFO:Scoring test/hold-out set
2023-07-24 17:02:16,532:INFO:Visual Rendered Successfully
2023-07-24 17:02:16,753:INFO:plot_model() successfully completed......................................
2023-07-24 17:03:10,642:INFO:Initializing plot_model()
2023-07-24 17:03:10,645:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=PassiveAggressiveRegressor(random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, system=True)
2023-07-24 17:03:10,646:INFO:Checking exceptions
2023-07-24 17:03:10,654:INFO:Preloading libraries
2023-07-24 17:03:10,654:INFO:Copying training dataset
2023-07-24 17:03:10,654:INFO:Plot type: feature
2023-07-24 17:03:11,771:INFO:Visual Rendered Successfully
2023-07-24 17:03:12,043:INFO:plot_model() successfully completed......................................
2023-07-24 17:04:05,742:INFO:Initializing predict_model()
2023-07-24 17:04:05,744:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=PassiveAggressiveRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fcb8c852550>)
2023-07-24 17:04:05,745:INFO:Checking exceptions
2023-07-24 17:04:05,745:INFO:Preloading libraries
2023-07-24 17:05:12,255:INFO:Initializing compare_models()
2023-07-24 17:05:12,256:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-07-24 17:05:12,256:INFO:Checking exceptions
2023-07-24 17:05:12,264:INFO:Preparing display monitor
2023-07-24 17:05:12,374:INFO:Initializing Linear Regression
2023-07-24 17:05:12,374:INFO:Total runtime is 6.218751271565755e-06 minutes
2023-07-24 17:05:12,380:INFO:SubProcess create_model() called ==================================
2023-07-24 17:05:12,380:INFO:Initializing create_model()
2023-07-24 17:05:12,380:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcb91b682e0>, model_only=True, return_train_score=False, kwargs={})
2023-07-24 17:05:12,381:INFO:Checking exceptions
2023-07-24 17:05:12,381:INFO:Importing libraries
2023-07-24 17:05:12,381:INFO:Copying training dataset
2023-07-24 17:05:12,409:INFO:Defining folds
2023-07-24 17:05:12,409:INFO:Declaring metric variables
2023-07-24 17:05:12,417:INFO:Importing untrained model
2023-07-24 17:05:12,428:INFO:Linear Regression Imported successfully
2023-07-24 17:05:12,460:INFO:Starting cross validation
2023-07-24 17:05:12,464:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-24 17:05:15,525:INFO:Calculating mean and std
2023-07-24 17:05:15,527:INFO:Creating metrics dataframe
2023-07-24 17:05:15,597:INFO:Uploading results into container
2023-07-24 17:05:15,598:INFO:Uploading model into container now
2023-07-24 17:05:15,598:INFO:_master_model_container: 19
2023-07-24 17:05:15,598:INFO:_display_container: 4
2023-07-24 17:05:15,599:INFO:LinearRegression(n_jobs=-1)
2023-07-24 17:05:15,599:INFO:create_model() successfully completed......................................
2023-07-24 17:05:15,702:INFO:SubProcess create_model() end ==================================
2023-07-24 17:05:15,702:INFO:Creating metrics dataframe
2023-07-24 17:05:15,721:INFO:Initializing Lasso Regression
2023-07-24 17:05:15,721:INFO:Total runtime is 0.055785504976908366 minutes
2023-07-24 17:05:15,730:INFO:SubProcess create_model() called ==================================
2023-07-24 17:05:15,731:INFO:Initializing create_model()
2023-07-24 17:05:15,731:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcb91b682e0>, model_only=True, return_train_score=False, kwargs={})
2023-07-24 17:05:15,732:INFO:Checking exceptions
2023-07-24 17:05:15,732:INFO:Importing libraries
2023-07-24 17:05:15,732:INFO:Copying training dataset
2023-07-24 17:05:15,745:INFO:Defining folds
2023-07-24 17:05:15,745:INFO:Declaring metric variables
2023-07-24 17:05:15,760:INFO:Importing untrained model
2023-07-24 17:05:15,769:INFO:Lasso Regression Imported successfully
2023-07-24 17:05:15,794:INFO:Starting cross validation
2023-07-24 17:05:15,797:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-24 17:05:18,127:INFO:Calculating mean and std
2023-07-24 17:05:18,129:INFO:Creating metrics dataframe
2023-07-24 17:05:18,285:INFO:Uploading results into container
2023-07-24 17:05:18,286:INFO:Uploading model into container now
2023-07-24 17:05:18,287:INFO:_master_model_container: 20
2023-07-24 17:05:18,287:INFO:_display_container: 4
2023-07-24 17:05:18,288:INFO:Lasso(random_state=123)
2023-07-24 17:05:18,288:INFO:create_model() successfully completed......................................
2023-07-24 17:05:18,433:INFO:SubProcess create_model() end ==================================
2023-07-24 17:05:18,433:INFO:Creating metrics dataframe
2023-07-24 17:05:18,484:INFO:Initializing Ridge Regression
2023-07-24 17:05:18,484:INFO:Total runtime is 0.10184231599171956 minutes
2023-07-24 17:05:18,499:INFO:SubProcess create_model() called ==================================
2023-07-24 17:05:18,500:INFO:Initializing create_model()
2023-07-24 17:05:18,500:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcb91b682e0>, model_only=True, return_train_score=False, kwargs={})
2023-07-24 17:05:18,500:INFO:Checking exceptions
2023-07-24 17:05:18,500:INFO:Importing libraries
2023-07-24 17:05:18,500:INFO:Copying training dataset
2023-07-24 17:05:18,534:INFO:Defining folds
2023-07-24 17:05:18,534:INFO:Declaring metric variables
2023-07-24 17:05:18,563:INFO:Importing untrained model
2023-07-24 17:05:18,584:INFO:Ridge Regression Imported successfully
2023-07-24 17:05:18,616:INFO:Starting cross validation
2023-07-24 17:05:18,623:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-24 17:05:21,078:INFO:Calculating mean and std
2023-07-24 17:05:21,080:INFO:Creating metrics dataframe
2023-07-24 17:05:21,148:INFO:Uploading results into container
2023-07-24 17:05:21,149:INFO:Uploading model into container now
2023-07-24 17:05:21,149:INFO:_master_model_container: 21
2023-07-24 17:05:21,149:INFO:_display_container: 4
2023-07-24 17:05:21,150:INFO:Ridge(random_state=123)
2023-07-24 17:05:21,150:INFO:create_model() successfully completed......................................
2023-07-24 17:05:21,251:INFO:SubProcess create_model() end ==================================
2023-07-24 17:05:21,251:INFO:Creating metrics dataframe
2023-07-24 17:05:21,270:INFO:Initializing Elastic Net
2023-07-24 17:05:21,271:INFO:Total runtime is 0.14827965100606283 minutes
2023-07-24 17:05:21,278:INFO:SubProcess create_model() called ==================================
2023-07-24 17:05:21,278:INFO:Initializing create_model()
2023-07-24 17:05:21,278:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcb91b682e0>, model_only=True, return_train_score=False, kwargs={})
2023-07-24 17:05:21,278:INFO:Checking exceptions
2023-07-24 17:05:21,278:INFO:Importing libraries
2023-07-24 17:05:21,279:INFO:Copying training dataset
2023-07-24 17:05:21,295:INFO:Defining folds
2023-07-24 17:05:21,295:INFO:Declaring metric variables
2023-07-24 17:05:21,315:INFO:Importing untrained model
2023-07-24 17:05:21,321:INFO:Elastic Net Imported successfully
2023-07-24 17:05:21,361:INFO:Starting cross validation
2023-07-24 17:05:21,367:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-24 17:05:25,527:INFO:Calculating mean and std
2023-07-24 17:05:25,531:INFO:Creating metrics dataframe
2023-07-24 17:05:25,680:INFO:Uploading results into container
2023-07-24 17:05:25,681:INFO:Uploading model into container now
2023-07-24 17:05:25,683:INFO:_master_model_container: 22
2023-07-24 17:05:25,683:INFO:_display_container: 4
2023-07-24 17:05:25,684:INFO:ElasticNet(random_state=123)
2023-07-24 17:05:25,684:INFO:create_model() successfully completed......................................
2023-07-24 17:05:25,912:INFO:SubProcess create_model() end ==================================
2023-07-24 17:05:25,913:INFO:Creating metrics dataframe
2023-07-24 17:05:25,958:INFO:Initializing Least Angle Regression
2023-07-24 17:05:25,958:INFO:Total runtime is 0.2264087677001953 minutes
2023-07-24 17:05:25,966:INFO:SubProcess create_model() called ==================================
2023-07-24 17:05:25,967:INFO:Initializing create_model()
2023-07-24 17:05:25,967:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcb91b682e0>, model_only=True, return_train_score=False, kwargs={})
2023-07-24 17:05:25,967:INFO:Checking exceptions
2023-07-24 17:05:25,967:INFO:Importing libraries
2023-07-24 17:05:25,967:INFO:Copying training dataset
2023-07-24 17:05:25,987:INFO:Defining folds
2023-07-24 17:05:25,987:INFO:Declaring metric variables
2023-07-24 17:05:26,052:INFO:Importing untrained model
2023-07-24 17:05:26,085:INFO:Least Angle Regression Imported successfully
2023-07-24 17:05:26,131:INFO:Starting cross validation
2023-07-24 17:05:26,136:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-24 17:05:27,150:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-24 17:05:27,200:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-24 17:05:27,298:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-24 17:05:27,320:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.51s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_transform(

2023-07-24 17:05:27,866:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-24 17:05:28,783:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-24 17:05:28,964:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-24 17:05:29,269:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.57s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_transform(

2023-07-24 17:05:29,299:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-24 17:05:29,531:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-07-24 17:05:29,638:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-07-24 17:05:30,176:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-24 17:05:30,698:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-24 17:05:30,868:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-24 17:05:31,485:INFO:Calculating mean and std
2023-07-24 17:05:31,488:INFO:Creating metrics dataframe
2023-07-24 17:05:31,601:INFO:Uploading results into container
2023-07-24 17:05:31,602:INFO:Uploading model into container now
2023-07-24 17:05:31,603:INFO:_master_model_container: 23
2023-07-24 17:05:31,603:INFO:_display_container: 4
2023-07-24 17:05:31,604:INFO:Lars(random_state=123)
2023-07-24 17:05:31,605:INFO:create_model() successfully completed......................................
2023-07-24 17:05:31,807:INFO:SubProcess create_model() end ==================================
2023-07-24 17:05:31,808:INFO:Creating metrics dataframe
2023-07-24 17:05:31,878:INFO:Initializing Lasso Least Angle Regression
2023-07-24 17:05:31,879:INFO:Total runtime is 0.3250885208447774 minutes
2023-07-24 17:05:31,897:INFO:SubProcess create_model() called ==================================
2023-07-24 17:05:31,898:INFO:Initializing create_model()
2023-07-24 17:05:31,898:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcb91b682e0>, model_only=True, return_train_score=False, kwargs={})
2023-07-24 17:05:31,898:INFO:Checking exceptions
2023-07-24 17:05:31,898:INFO:Importing libraries
2023-07-24 17:05:31,898:INFO:Copying training dataset
2023-07-24 17:05:31,921:INFO:Defining folds
2023-07-24 17:05:31,921:INFO:Declaring metric variables
2023-07-24 17:05:31,950:INFO:Importing untrained model
2023-07-24 17:05:32,001:INFO:Lasso Least Angle Regression Imported successfully
2023-07-24 17:05:32,035:INFO:Starting cross validation
2023-07-24 17:05:32,039:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-24 17:05:33,004:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-24 17:05:33,038:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-24 17:05:33,085:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-24 17:05:33,209:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-24 17:05:34,540:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-24 17:05:34,636:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-24 17:05:34,638:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-24 17:05:34,782:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-24 17:05:35,789:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-24 17:05:35,928:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-24 17:05:36,299:INFO:Calculating mean and std
2023-07-24 17:05:36,302:INFO:Creating metrics dataframe
2023-07-24 17:05:36,375:INFO:Uploading results into container
2023-07-24 17:05:36,376:INFO:Uploading model into container now
2023-07-24 17:05:36,377:INFO:_master_model_container: 24
2023-07-24 17:05:36,377:INFO:_display_container: 4
2023-07-24 17:05:36,378:INFO:LassoLars(random_state=123)
2023-07-24 17:05:36,378:INFO:create_model() successfully completed......................................
2023-07-24 17:05:36,485:INFO:SubProcess create_model() end ==================================
2023-07-24 17:05:36,485:INFO:Creating metrics dataframe
2023-07-24 17:05:36,509:INFO:Initializing Orthogonal Matching Pursuit
2023-07-24 17:05:36,510:INFO:Total runtime is 0.4022623538970947 minutes
2023-07-24 17:05:36,516:INFO:SubProcess create_model() called ==================================
2023-07-24 17:05:36,517:INFO:Initializing create_model()
2023-07-24 17:05:36,517:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcb91b682e0>, model_only=True, return_train_score=False, kwargs={})
2023-07-24 17:05:36,517:INFO:Checking exceptions
2023-07-24 17:05:36,518:INFO:Importing libraries
2023-07-24 17:05:36,519:INFO:Copying training dataset
2023-07-24 17:05:36,534:INFO:Defining folds
2023-07-24 17:05:36,535:INFO:Declaring metric variables
2023-07-24 17:05:36,543:INFO:Importing untrained model
2023-07-24 17:05:36,551:INFO:Orthogonal Matching Pursuit Imported successfully
2023-07-24 17:05:36,567:INFO:Starting cross validation
2023-07-24 17:05:36,571:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-24 17:05:37,195:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-24 17:05:37,210:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-24 17:05:37,234:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-24 17:05:37,235:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2023-07-24 17:05:37,265:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-24 17:05:38,355:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-24 17:05:38,384:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-24 17:05:38,395:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-24 17:05:38,452:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-24 17:05:39,058:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-24 17:05:39,068:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-24 17:05:39,079:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2023-07-24 17:05:39,235:INFO:Calculating mean and std
2023-07-24 17:05:39,237:INFO:Creating metrics dataframe
2023-07-24 17:05:39,368:INFO:Uploading results into container
2023-07-24 17:05:39,369:INFO:Uploading model into container now
2023-07-24 17:05:39,370:INFO:_master_model_container: 25
2023-07-24 17:05:39,371:INFO:_display_container: 4
2023-07-24 17:05:39,371:INFO:OrthogonalMatchingPursuit()
2023-07-24 17:05:39,371:INFO:create_model() successfully completed......................................
2023-07-24 17:05:39,476:INFO:SubProcess create_model() end ==================================
2023-07-24 17:05:39,476:INFO:Creating metrics dataframe
2023-07-24 17:05:39,506:INFO:Initializing Bayesian Ridge
2023-07-24 17:05:39,506:INFO:Total runtime is 0.4521989027659098 minutes
2023-07-24 17:05:39,516:INFO:SubProcess create_model() called ==================================
2023-07-24 17:05:39,516:INFO:Initializing create_model()
2023-07-24 17:05:39,516:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcb91b682e0>, model_only=True, return_train_score=False, kwargs={})
2023-07-24 17:05:39,517:INFO:Checking exceptions
2023-07-24 17:05:39,518:INFO:Importing libraries
2023-07-24 17:05:39,518:INFO:Copying training dataset
2023-07-24 17:05:39,538:INFO:Defining folds
2023-07-24 17:05:39,539:INFO:Declaring metric variables
2023-07-24 17:05:39,563:INFO:Importing untrained model
2023-07-24 17:05:39,572:INFO:Bayesian Ridge Imported successfully
2023-07-24 17:05:39,606:INFO:Starting cross validation
2023-07-24 17:05:39,612:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-24 17:05:42,249:INFO:Calculating mean and std
2023-07-24 17:05:42,252:INFO:Creating metrics dataframe
2023-07-24 17:05:42,323:INFO:Uploading results into container
2023-07-24 17:05:42,324:INFO:Uploading model into container now
2023-07-24 17:05:42,325:INFO:_master_model_container: 26
2023-07-24 17:05:42,325:INFO:_display_container: 4
2023-07-24 17:05:42,326:INFO:BayesianRidge()
2023-07-24 17:05:42,326:INFO:create_model() successfully completed......................................
2023-07-24 17:05:42,430:INFO:SubProcess create_model() end ==================================
2023-07-24 17:05:42,430:INFO:Creating metrics dataframe
2023-07-24 17:05:42,455:INFO:Initializing Passive Aggressive Regressor
2023-07-24 17:05:42,455:INFO:Total runtime is 0.5013529022534688 minutes
2023-07-24 17:05:42,462:INFO:SubProcess create_model() called ==================================
2023-07-24 17:05:42,463:INFO:Initializing create_model()
2023-07-24 17:05:42,463:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcb91b682e0>, model_only=True, return_train_score=False, kwargs={})
2023-07-24 17:05:42,463:INFO:Checking exceptions
2023-07-24 17:05:42,463:INFO:Importing libraries
2023-07-24 17:05:42,463:INFO:Copying training dataset
2023-07-24 17:05:42,479:INFO:Defining folds
2023-07-24 17:05:42,479:INFO:Declaring metric variables
2023-07-24 17:05:42,496:INFO:Importing untrained model
2023-07-24 17:05:42,503:INFO:Passive Aggressive Regressor Imported successfully
2023-07-24 17:05:42,522:INFO:Starting cross validation
2023-07-24 17:05:42,525:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-24 17:05:44,949:INFO:Calculating mean and std
2023-07-24 17:05:44,950:INFO:Creating metrics dataframe
2023-07-24 17:05:45,029:INFO:Uploading results into container
2023-07-24 17:05:45,030:INFO:Uploading model into container now
2023-07-24 17:05:45,031:INFO:_master_model_container: 27
2023-07-24 17:05:45,031:INFO:_display_container: 4
2023-07-24 17:05:45,032:INFO:PassiveAggressiveRegressor(random_state=123)
2023-07-24 17:05:45,032:INFO:create_model() successfully completed......................................
2023-07-24 17:05:45,143:INFO:SubProcess create_model() end ==================================
2023-07-24 17:05:45,144:INFO:Creating metrics dataframe
2023-07-24 17:05:45,168:INFO:Initializing Huber Regressor
2023-07-24 17:05:45,168:INFO:Total runtime is 0.5465658664703369 minutes
2023-07-24 17:05:45,177:INFO:SubProcess create_model() called ==================================
2023-07-24 17:05:45,178:INFO:Initializing create_model()
2023-07-24 17:05:45,178:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcb91b682e0>, model_only=True, return_train_score=False, kwargs={})
2023-07-24 17:05:45,178:INFO:Checking exceptions
2023-07-24 17:05:45,178:INFO:Importing libraries
2023-07-24 17:05:45,179:INFO:Copying training dataset
2023-07-24 17:05:45,197:INFO:Defining folds
2023-07-24 17:05:45,197:INFO:Declaring metric variables
2023-07-24 17:05:45,213:INFO:Importing untrained model
2023-07-24 17:05:45,231:INFO:Huber Regressor Imported successfully
2023-07-24 17:05:45,256:INFO:Starting cross validation
2023-07-24 17:05:45,261:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-24 17:05:48,711:INFO:Calculating mean and std
2023-07-24 17:05:48,715:INFO:Creating metrics dataframe
2023-07-24 17:05:48,902:INFO:Uploading results into container
2023-07-24 17:05:48,904:INFO:Uploading model into container now
2023-07-24 17:05:48,906:INFO:_master_model_container: 28
2023-07-24 17:05:48,908:INFO:_display_container: 4
2023-07-24 17:05:48,908:INFO:HuberRegressor()
2023-07-24 17:05:48,908:INFO:create_model() successfully completed......................................
2023-07-24 17:05:49,038:INFO:SubProcess create_model() end ==================================
2023-07-24 17:05:49,038:INFO:Creating metrics dataframe
2023-07-24 17:05:49,064:INFO:Initializing K Neighbors Regressor
2023-07-24 17:05:49,064:INFO:Total runtime is 0.611505119005839 minutes
2023-07-24 17:05:49,070:INFO:SubProcess create_model() called ==================================
2023-07-24 17:05:49,071:INFO:Initializing create_model()
2023-07-24 17:05:49,071:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcb91b682e0>, model_only=True, return_train_score=False, kwargs={})
2023-07-24 17:05:49,071:INFO:Checking exceptions
2023-07-24 17:05:49,072:INFO:Importing libraries
2023-07-24 17:05:49,072:INFO:Copying training dataset
2023-07-24 17:05:49,088:INFO:Defining folds
2023-07-24 17:05:49,089:INFO:Declaring metric variables
2023-07-24 17:05:49,101:INFO:Importing untrained model
2023-07-24 17:05:49,116:INFO:K Neighbors Regressor Imported successfully
2023-07-24 17:05:49,137:INFO:Starting cross validation
2023-07-24 17:05:49,144:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-24 17:05:53,119:INFO:Calculating mean and std
2023-07-24 17:05:53,122:INFO:Creating metrics dataframe
2023-07-24 17:05:53,191:INFO:Uploading results into container
2023-07-24 17:05:53,193:INFO:Uploading model into container now
2023-07-24 17:05:53,194:INFO:_master_model_container: 29
2023-07-24 17:05:53,194:INFO:_display_container: 4
2023-07-24 17:05:53,194:INFO:KNeighborsRegressor(n_jobs=-1)
2023-07-24 17:05:53,194:INFO:create_model() successfully completed......................................
2023-07-24 17:05:53,296:INFO:SubProcess create_model() end ==================================
2023-07-24 17:05:53,296:INFO:Creating metrics dataframe
2023-07-24 17:05:53,319:INFO:Initializing Decision Tree Regressor
2023-07-24 17:05:53,319:INFO:Total runtime is 0.6824229677518209 minutes
2023-07-24 17:05:53,327:INFO:SubProcess create_model() called ==================================
2023-07-24 17:05:53,327:INFO:Initializing create_model()
2023-07-24 17:05:53,328:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcb91b682e0>, model_only=True, return_train_score=False, kwargs={})
2023-07-24 17:05:53,328:INFO:Checking exceptions
2023-07-24 17:05:53,328:INFO:Importing libraries
2023-07-24 17:05:53,328:INFO:Copying training dataset
2023-07-24 17:05:53,342:INFO:Defining folds
2023-07-24 17:05:53,342:INFO:Declaring metric variables
2023-07-24 17:05:53,356:INFO:Importing untrained model
2023-07-24 17:05:53,365:INFO:Decision Tree Regressor Imported successfully
2023-07-24 17:05:53,382:INFO:Starting cross validation
2023-07-24 17:05:53,384:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-24 17:05:55,702:INFO:Calculating mean and std
2023-07-24 17:05:55,703:INFO:Creating metrics dataframe
2023-07-24 17:05:55,817:INFO:Uploading results into container
2023-07-24 17:05:55,819:INFO:Uploading model into container now
2023-07-24 17:05:55,829:INFO:_master_model_container: 30
2023-07-24 17:05:55,829:INFO:_display_container: 4
2023-07-24 17:05:55,830:INFO:DecisionTreeRegressor(random_state=123)
2023-07-24 17:05:55,830:INFO:create_model() successfully completed......................................
2023-07-24 17:05:55,939:INFO:SubProcess create_model() end ==================================
2023-07-24 17:05:55,940:INFO:Creating metrics dataframe
2023-07-24 17:05:55,967:INFO:Initializing Random Forest Regressor
2023-07-24 17:05:55,967:INFO:Total runtime is 0.7265547355016072 minutes
2023-07-24 17:05:55,975:INFO:SubProcess create_model() called ==================================
2023-07-24 17:05:55,976:INFO:Initializing create_model()
2023-07-24 17:05:55,976:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcb91b682e0>, model_only=True, return_train_score=False, kwargs={})
2023-07-24 17:05:55,976:INFO:Checking exceptions
2023-07-24 17:05:55,976:INFO:Importing libraries
2023-07-24 17:05:55,976:INFO:Copying training dataset
2023-07-24 17:05:56,002:INFO:Defining folds
2023-07-24 17:05:56,002:INFO:Declaring metric variables
2023-07-24 17:05:56,021:INFO:Importing untrained model
2023-07-24 17:05:56,032:INFO:Random Forest Regressor Imported successfully
2023-07-24 17:05:56,054:INFO:Starting cross validation
2023-07-24 17:05:56,056:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-24 17:05:59,101:INFO:Calculating mean and std
2023-07-24 17:05:59,102:INFO:Creating metrics dataframe
2023-07-24 17:05:59,246:INFO:Uploading results into container
2023-07-24 17:05:59,247:INFO:Uploading model into container now
2023-07-24 17:05:59,248:INFO:_master_model_container: 31
2023-07-24 17:05:59,248:INFO:_display_container: 4
2023-07-24 17:05:59,248:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-07-24 17:05:59,249:INFO:create_model() successfully completed......................................
2023-07-24 17:05:59,351:INFO:SubProcess create_model() end ==================================
2023-07-24 17:05:59,351:INFO:Creating metrics dataframe
2023-07-24 17:05:59,382:INFO:Initializing Extra Trees Regressor
2023-07-24 17:05:59,382:INFO:Total runtime is 0.7834737380345662 minutes
2023-07-24 17:05:59,391:INFO:SubProcess create_model() called ==================================
2023-07-24 17:05:59,391:INFO:Initializing create_model()
2023-07-24 17:05:59,392:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcb91b682e0>, model_only=True, return_train_score=False, kwargs={})
2023-07-24 17:05:59,392:INFO:Checking exceptions
2023-07-24 17:05:59,392:INFO:Importing libraries
2023-07-24 17:05:59,392:INFO:Copying training dataset
2023-07-24 17:05:59,413:INFO:Defining folds
2023-07-24 17:05:59,413:INFO:Declaring metric variables
2023-07-24 17:05:59,424:INFO:Importing untrained model
2023-07-24 17:05:59,463:INFO:Extra Trees Regressor Imported successfully
2023-07-24 17:05:59,481:INFO:Starting cross validation
2023-07-24 17:05:59,484:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-24 17:06:04,039:INFO:Calculating mean and std
2023-07-24 17:06:04,042:INFO:Creating metrics dataframe
2023-07-24 17:06:04,112:INFO:Uploading results into container
2023-07-24 17:06:04,113:INFO:Uploading model into container now
2023-07-24 17:06:04,113:INFO:_master_model_container: 32
2023-07-24 17:06:04,113:INFO:_display_container: 4
2023-07-24 17:06:04,114:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-07-24 17:06:04,114:INFO:create_model() successfully completed......................................
2023-07-24 17:06:04,229:INFO:SubProcess create_model() end ==================================
2023-07-24 17:06:04,229:INFO:Creating metrics dataframe
2023-07-24 17:06:04,254:INFO:Initializing AdaBoost Regressor
2023-07-24 17:06:04,254:INFO:Total runtime is 0.8646710356076558 minutes
2023-07-24 17:06:04,263:INFO:SubProcess create_model() called ==================================
2023-07-24 17:06:04,264:INFO:Initializing create_model()
2023-07-24 17:06:04,264:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcb91b682e0>, model_only=True, return_train_score=False, kwargs={})
2023-07-24 17:06:04,264:INFO:Checking exceptions
2023-07-24 17:06:04,264:INFO:Importing libraries
2023-07-24 17:06:04,265:INFO:Copying training dataset
2023-07-24 17:06:04,279:INFO:Defining folds
2023-07-24 17:06:04,279:INFO:Declaring metric variables
2023-07-24 17:06:04,297:INFO:Importing untrained model
2023-07-24 17:06:04,303:INFO:AdaBoost Regressor Imported successfully
2023-07-24 17:06:04,330:INFO:Starting cross validation
2023-07-24 17:06:04,333:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-24 17:06:06,982:INFO:Calculating mean and std
2023-07-24 17:06:06,984:INFO:Creating metrics dataframe
2023-07-24 17:06:07,124:INFO:Uploading results into container
2023-07-24 17:06:07,125:INFO:Uploading model into container now
2023-07-24 17:06:07,126:INFO:_master_model_container: 33
2023-07-24 17:06:07,127:INFO:_display_container: 4
2023-07-24 17:06:07,127:INFO:AdaBoostRegressor(random_state=123)
2023-07-24 17:06:07,129:INFO:create_model() successfully completed......................................
2023-07-24 17:06:07,233:INFO:SubProcess create_model() end ==================================
2023-07-24 17:06:07,233:INFO:Creating metrics dataframe
2023-07-24 17:06:07,263:INFO:Initializing Gradient Boosting Regressor
2023-07-24 17:06:07,263:INFO:Total runtime is 0.9148194352785746 minutes
2023-07-24 17:06:07,273:INFO:SubProcess create_model() called ==================================
2023-07-24 17:06:07,273:INFO:Initializing create_model()
2023-07-24 17:06:07,274:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcb91b682e0>, model_only=True, return_train_score=False, kwargs={})
2023-07-24 17:06:07,274:INFO:Checking exceptions
2023-07-24 17:06:07,274:INFO:Importing libraries
2023-07-24 17:06:07,274:INFO:Copying training dataset
2023-07-24 17:06:07,306:INFO:Defining folds
2023-07-24 17:06:07,306:INFO:Declaring metric variables
2023-07-24 17:06:07,315:INFO:Importing untrained model
2023-07-24 17:06:07,322:INFO:Gradient Boosting Regressor Imported successfully
2023-07-24 17:06:07,349:INFO:Starting cross validation
2023-07-24 17:06:07,354:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-24 17:06:08,932:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 17:06:08,959:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 17:06:10,651:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 17:06:10,670:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 17:06:10,752:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 17:06:11,722:INFO:Calculating mean and std
2023-07-24 17:06:11,724:INFO:Creating metrics dataframe
2023-07-24 17:06:11,848:INFO:Uploading results into container
2023-07-24 17:06:11,849:INFO:Uploading model into container now
2023-07-24 17:06:11,851:INFO:_master_model_container: 34
2023-07-24 17:06:11,852:INFO:_display_container: 4
2023-07-24 17:06:11,852:INFO:GradientBoostingRegressor(random_state=123)
2023-07-24 17:06:11,852:INFO:create_model() successfully completed......................................
2023-07-24 17:06:11,970:INFO:SubProcess create_model() end ==================================
2023-07-24 17:06:11,970:INFO:Creating metrics dataframe
2023-07-24 17:06:12,004:INFO:Initializing Extreme Gradient Boosting
2023-07-24 17:06:12,004:INFO:Total runtime is 0.9938318332036336 minutes
2023-07-24 17:06:12,014:INFO:SubProcess create_model() called ==================================
2023-07-24 17:06:12,015:INFO:Initializing create_model()
2023-07-24 17:06:12,015:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcb91b682e0>, model_only=True, return_train_score=False, kwargs={})
2023-07-24 17:06:12,016:INFO:Checking exceptions
2023-07-24 17:06:12,017:INFO:Importing libraries
2023-07-24 17:06:12,017:INFO:Copying training dataset
2023-07-24 17:06:12,037:INFO:Defining folds
2023-07-24 17:06:12,037:INFO:Declaring metric variables
2023-07-24 17:06:12,054:INFO:Importing untrained model
2023-07-24 17:06:12,075:INFO:Extreme Gradient Boosting Imported successfully
2023-07-24 17:06:12,099:INFO:Starting cross validation
2023-07-24 17:06:12,101:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-24 17:06:14,684:INFO:Calculating mean and std
2023-07-24 17:06:14,686:INFO:Creating metrics dataframe
2023-07-24 17:06:14,755:INFO:Uploading results into container
2023-07-24 17:06:14,756:INFO:Uploading model into container now
2023-07-24 17:06:14,756:INFO:_master_model_container: 35
2023-07-24 17:06:14,756:INFO:_display_container: 4
2023-07-24 17:06:14,757:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=123, ...)
2023-07-24 17:06:14,757:INFO:create_model() successfully completed......................................
2023-07-24 17:06:14,858:INFO:SubProcess create_model() end ==================================
2023-07-24 17:06:14,858:INFO:Creating metrics dataframe
2023-07-24 17:06:14,883:INFO:Initializing Light Gradient Boosting Machine
2023-07-24 17:06:14,884:INFO:Total runtime is 1.0418291529019672 minutes
2023-07-24 17:06:14,890:INFO:SubProcess create_model() called ==================================
2023-07-24 17:06:14,891:INFO:Initializing create_model()
2023-07-24 17:06:14,891:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcb91b682e0>, model_only=True, return_train_score=False, kwargs={})
2023-07-24 17:06:14,891:INFO:Checking exceptions
2023-07-24 17:06:14,891:INFO:Importing libraries
2023-07-24 17:06:14,892:INFO:Copying training dataset
2023-07-24 17:06:14,906:INFO:Defining folds
2023-07-24 17:06:14,906:INFO:Declaring metric variables
2023-07-24 17:06:14,927:INFO:Importing untrained model
2023-07-24 17:06:14,936:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-24 17:06:14,953:INFO:Starting cross validation
2023-07-24 17:06:14,955:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-24 17:06:16,430:WARNING:create_model() for lightgbm raised an exception or returned all 0.0, trying without fit_kwargs:
2023-07-24 17:06:16,439:WARNING:Traceback (most recent call last):
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1521, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1116, in _create_model_with_cv
    scores = cross_validate(
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 267, in cross_validate
    results = parallel(
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 1944, in __call__
    return output if self.return_generator else list(output)
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 1587, in _get_outputs
    yield from self._retrieve()
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 1691, in _retrieve
    self._raise_error_fast()
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 1726, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 735, in get_result
    return self._return_or_raise()
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 753, in _return_or_raise
    raise self._result
joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.

The exit codes of the workers are {SIGSEGV(-11)}

2023-07-24 17:06:16,440:INFO:Initializing create_model()
2023-07-24 17:06:16,440:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcb91b682e0>, model_only=True, return_train_score=False, kwargs={})
2023-07-24 17:06:16,440:INFO:Checking exceptions
2023-07-24 17:06:16,441:INFO:Importing libraries
2023-07-24 17:06:16,441:INFO:Copying training dataset
2023-07-24 17:06:16,463:INFO:Defining folds
2023-07-24 17:06:16,464:INFO:Declaring metric variables
2023-07-24 17:06:16,472:INFO:Importing untrained model
2023-07-24 17:06:16,482:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-24 17:06:16,500:INFO:Starting cross validation
2023-07-24 17:06:16,502:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-24 17:06:27,822:ERROR:create_model() for lightgbm raised an exception or returned all 0.0:
2023-07-24 17:06:27,824:ERROR:Traceback (most recent call last):
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1521, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1116, in _create_model_with_cv
    scores = cross_validate(
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 267, in cross_validate
    results = parallel(
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 1944, in __call__
    return output if self.return_generator else list(output)
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 1587, in _get_outputs
    yield from self._retrieve()
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 1691, in _retrieve
    self._raise_error_fast()
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 1726, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 735, in get_result
    return self._return_or_raise()
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 753, in _return_or_raise
    raise self._result
joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.

The exit codes of the workers are {SIGSEGV(-11)}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1521, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1116, in _create_model_with_cv
    scores = cross_validate(
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 267, in cross_validate
    results = parallel(
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 1944, in __call__
    return output if self.return_generator else list(output)
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 1587, in _get_outputs
    yield from self._retrieve()
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 1691, in _retrieve
    self._raise_error_fast()
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 1726, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 735, in get_result
    return self._return_or_raise()
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 753, in _return_or_raise
    raise self._result
joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.

The exit codes of the workers are {SIGSEGV(-11)}

2023-07-24 17:06:27,824:INFO:Initializing Dummy Regressor
2023-07-24 17:06:27,824:INFO:Total runtime is 1.2575079162915546 minutes
2023-07-24 17:06:27,836:INFO:SubProcess create_model() called ==================================
2023-07-24 17:06:27,837:INFO:Initializing create_model()
2023-07-24 17:06:27,837:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcb91b682e0>, model_only=True, return_train_score=False, kwargs={})
2023-07-24 17:06:27,837:INFO:Checking exceptions
2023-07-24 17:06:27,838:INFO:Importing libraries
2023-07-24 17:06:27,838:INFO:Copying training dataset
2023-07-24 17:06:27,861:INFO:Defining folds
2023-07-24 17:06:27,861:INFO:Declaring metric variables
2023-07-24 17:06:27,876:INFO:Importing untrained model
2023-07-24 17:06:27,890:INFO:Dummy Regressor Imported successfully
2023-07-24 17:06:27,911:INFO:Starting cross validation
2023-07-24 17:06:27,915:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-24 17:06:37,843:INFO:Calculating mean and std
2023-07-24 17:06:37,849:INFO:Creating metrics dataframe
2023-07-24 17:06:37,957:INFO:Uploading results into container
2023-07-24 17:06:37,958:INFO:Uploading model into container now
2023-07-24 17:06:37,959:INFO:_master_model_container: 36
2023-07-24 17:06:37,959:INFO:_display_container: 4
2023-07-24 17:06:37,960:INFO:DummyRegressor()
2023-07-24 17:06:37,960:INFO:create_model() successfully completed......................................
2023-07-24 17:06:38,125:INFO:SubProcess create_model() end ==================================
2023-07-24 17:06:38,125:INFO:Creating metrics dataframe
2023-07-24 17:06:38,201:INFO:Initializing create_model()
2023-07-24 17:06:38,201:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=PassiveAggressiveRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-24 17:06:38,201:INFO:Checking exceptions
2023-07-24 17:06:38,204:INFO:Importing libraries
2023-07-24 17:06:38,205:INFO:Copying training dataset
2023-07-24 17:06:38,219:INFO:Defining folds
2023-07-24 17:06:38,219:INFO:Declaring metric variables
2023-07-24 17:06:38,220:INFO:Importing untrained model
2023-07-24 17:06:38,220:INFO:Declaring custom model
2023-07-24 17:06:38,222:INFO:Passive Aggressive Regressor Imported successfully
2023-07-24 17:06:38,224:INFO:Cross validation set to False
2023-07-24 17:06:38,225:INFO:Fitting Model
2023-07-24 17:06:38,756:INFO:PassiveAggressiveRegressor(random_state=123)
2023-07-24 17:06:38,756:INFO:create_model() successfully completed......................................
2023-07-24 17:06:39,011:INFO:_master_model_container: 36
2023-07-24 17:06:39,012:INFO:_display_container: 4
2023-07-24 17:06:39,018:INFO:PassiveAggressiveRegressor(random_state=123)
2023-07-24 17:06:39,018:INFO:compare_models() successfully completed......................................
2023-07-24 17:06:51,441:INFO:Initializing compare_models()
2023-07-24 17:06:51,441:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-07-24 17:06:51,442:INFO:Checking exceptions
2023-07-24 17:06:51,449:INFO:Preparing display monitor
2023-07-24 17:06:51,544:INFO:Initializing Linear Regression
2023-07-24 17:06:51,544:INFO:Total runtime is 2.6365121205647785e-05 minutes
2023-07-24 17:06:51,558:INFO:SubProcess create_model() called ==================================
2023-07-24 17:06:51,558:INFO:Initializing create_model()
2023-07-24 17:06:51,559:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcb9140a280>, model_only=True, return_train_score=False, kwargs={})
2023-07-24 17:06:51,559:INFO:Checking exceptions
2023-07-24 17:06:51,559:INFO:Importing libraries
2023-07-24 17:06:51,559:INFO:Copying training dataset
2023-07-24 17:06:51,577:INFO:Defining folds
2023-07-24 17:06:51,577:INFO:Declaring metric variables
2023-07-24 17:06:51,590:INFO:Importing untrained model
2023-07-24 17:06:51,602:INFO:Linear Regression Imported successfully
2023-07-24 17:06:51,635:INFO:Starting cross validation
2023-07-24 17:06:51,637:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-24 17:07:00,636:INFO:Calculating mean and std
2023-07-24 17:07:00,639:INFO:Creating metrics dataframe
2023-07-24 17:07:00,768:INFO:Uploading results into container
2023-07-24 17:07:00,769:INFO:Uploading model into container now
2023-07-24 17:07:00,771:INFO:_master_model_container: 37
2023-07-24 17:07:00,771:INFO:_display_container: 5
2023-07-24 17:07:00,771:INFO:LinearRegression(n_jobs=-1)
2023-07-24 17:07:00,771:INFO:create_model() successfully completed......................................
2023-07-24 17:07:00,878:INFO:SubProcess create_model() end ==================================
2023-07-24 17:07:00,879:INFO:Creating metrics dataframe
2023-07-24 17:07:00,901:INFO:Initializing Lasso Regression
2023-07-24 17:07:00,901:INFO:Total runtime is 0.1559667666753133 minutes
2023-07-24 17:07:00,916:INFO:SubProcess create_model() called ==================================
2023-07-24 17:07:00,917:INFO:Initializing create_model()
2023-07-24 17:07:00,917:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcb9140a280>, model_only=True, return_train_score=False, kwargs={})
2023-07-24 17:07:00,917:INFO:Checking exceptions
2023-07-24 17:07:00,917:INFO:Importing libraries
2023-07-24 17:07:00,918:INFO:Copying training dataset
2023-07-24 17:07:00,941:INFO:Defining folds
2023-07-24 17:07:00,941:INFO:Declaring metric variables
2023-07-24 17:07:00,993:INFO:Importing untrained model
2023-07-24 17:07:01,009:INFO:Lasso Regression Imported successfully
2023-07-24 17:07:01,034:INFO:Starting cross validation
2023-07-24 17:07:01,039:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-24 17:07:03,369:INFO:Calculating mean and std
2023-07-24 17:07:03,372:INFO:Creating metrics dataframe
2023-07-24 17:07:03,444:INFO:Uploading results into container
2023-07-24 17:07:03,445:INFO:Uploading model into container now
2023-07-24 17:07:03,445:INFO:_master_model_container: 38
2023-07-24 17:07:03,445:INFO:_display_container: 5
2023-07-24 17:07:03,446:INFO:Lasso(random_state=123)
2023-07-24 17:07:03,446:INFO:create_model() successfully completed......................................
2023-07-24 17:07:03,552:INFO:SubProcess create_model() end ==================================
2023-07-24 17:07:03,552:INFO:Creating metrics dataframe
2023-07-24 17:07:03,573:INFO:Initializing Ridge Regression
2023-07-24 17:07:03,573:INFO:Total runtime is 0.20050219694773355 minutes
2023-07-24 17:07:03,578:INFO:SubProcess create_model() called ==================================
2023-07-24 17:07:03,578:INFO:Initializing create_model()
2023-07-24 17:07:03,579:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcb9140a280>, model_only=True, return_train_score=False, kwargs={})
2023-07-24 17:07:03,579:INFO:Checking exceptions
2023-07-24 17:07:03,579:INFO:Importing libraries
2023-07-24 17:07:03,580:INFO:Copying training dataset
2023-07-24 17:07:03,597:INFO:Defining folds
2023-07-24 17:07:03,597:INFO:Declaring metric variables
2023-07-24 17:07:03,615:INFO:Importing untrained model
2023-07-24 17:07:03,627:INFO:Ridge Regression Imported successfully
2023-07-24 17:07:03,652:INFO:Starting cross validation
2023-07-24 17:07:03,656:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-24 17:07:06,015:INFO:Calculating mean and std
2023-07-24 17:07:06,019:INFO:Creating metrics dataframe
2023-07-24 17:07:06,094:INFO:Uploading results into container
2023-07-24 17:07:06,094:INFO:Uploading model into container now
2023-07-24 17:07:06,095:INFO:_master_model_container: 39
2023-07-24 17:07:06,095:INFO:_display_container: 5
2023-07-24 17:07:06,095:INFO:Ridge(random_state=123)
2023-07-24 17:07:06,095:INFO:create_model() successfully completed......................................
2023-07-24 17:07:06,198:INFO:SubProcess create_model() end ==================================
2023-07-24 17:07:06,198:INFO:Creating metrics dataframe
2023-07-24 17:07:06,222:INFO:Initializing Elastic Net
2023-07-24 17:07:06,222:INFO:Total runtime is 0.24464926719665525 minutes
2023-07-24 17:07:06,228:INFO:SubProcess create_model() called ==================================
2023-07-24 17:07:06,228:INFO:Initializing create_model()
2023-07-24 17:07:06,229:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcb9140a280>, model_only=True, return_train_score=False, kwargs={})
2023-07-24 17:07:06,229:INFO:Checking exceptions
2023-07-24 17:07:06,229:INFO:Importing libraries
2023-07-24 17:07:06,230:INFO:Copying training dataset
2023-07-24 17:07:06,261:INFO:Defining folds
2023-07-24 17:07:06,261:INFO:Declaring metric variables
2023-07-24 17:07:06,277:INFO:Importing untrained model
2023-07-24 17:07:06,289:INFO:Elastic Net Imported successfully
2023-07-24 17:07:06,308:INFO:Starting cross validation
2023-07-24 17:07:06,311:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-24 17:07:08,905:INFO:Calculating mean and std
2023-07-24 17:07:08,906:INFO:Creating metrics dataframe
2023-07-24 17:07:08,981:INFO:Uploading results into container
2023-07-24 17:07:08,981:INFO:Uploading model into container now
2023-07-24 17:07:08,982:INFO:_master_model_container: 40
2023-07-24 17:07:08,982:INFO:_display_container: 5
2023-07-24 17:07:08,984:INFO:ElasticNet(random_state=123)
2023-07-24 17:07:08,984:INFO:create_model() successfully completed......................................
2023-07-24 17:07:09,105:INFO:SubProcess create_model() end ==================================
2023-07-24 17:07:09,105:INFO:Creating metrics dataframe
2023-07-24 17:07:09,131:INFO:Initializing Least Angle Regression
2023-07-24 17:07:09,132:INFO:Total runtime is 0.2931587656339009 minutes
2023-07-24 17:07:09,144:INFO:SubProcess create_model() called ==================================
2023-07-24 17:07:09,145:INFO:Initializing create_model()
2023-07-24 17:07:09,145:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcb9140a280>, model_only=True, return_train_score=False, kwargs={})
2023-07-24 17:07:09,146:INFO:Checking exceptions
2023-07-24 17:07:09,146:INFO:Importing libraries
2023-07-24 17:07:09,146:INFO:Copying training dataset
2023-07-24 17:07:09,211:INFO:Defining folds
2023-07-24 17:07:09,212:INFO:Declaring metric variables
2023-07-24 17:07:09,231:INFO:Importing untrained model
2023-07-24 17:07:09,247:INFO:Least Angle Regression Imported successfully
2023-07-24 17:07:09,279:INFO:Starting cross validation
2023-07-24 17:07:09,284:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-24 17:07:09,841:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-24 17:07:09,847:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-24 17:07:09,876:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-24 17:07:11,269:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-24 17:07:11,345:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-24 17:07:12,901:INFO:Calculating mean and std
2023-07-24 17:07:12,903:INFO:Creating metrics dataframe
2023-07-24 17:07:13,026:INFO:Uploading results into container
2023-07-24 17:07:13,028:INFO:Uploading model into container now
2023-07-24 17:07:13,035:INFO:_master_model_container: 41
2023-07-24 17:07:13,035:INFO:_display_container: 5
2023-07-24 17:07:13,036:INFO:Lars(random_state=123)
2023-07-24 17:07:13,036:INFO:create_model() successfully completed......................................
2023-07-24 17:07:13,167:INFO:SubProcess create_model() end ==================================
2023-07-24 17:07:13,167:INFO:Creating metrics dataframe
2023-07-24 17:07:13,195:INFO:Initializing Lasso Least Angle Regression
2023-07-24 17:07:13,196:INFO:Total runtime is 0.36088236570358273 minutes
2023-07-24 17:07:13,203:INFO:SubProcess create_model() called ==================================
2023-07-24 17:07:13,204:INFO:Initializing create_model()
2023-07-24 17:07:13,204:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcb9140a280>, model_only=True, return_train_score=False, kwargs={})
2023-07-24 17:07:13,204:INFO:Checking exceptions
2023-07-24 17:07:13,205:INFO:Importing libraries
2023-07-24 17:07:13,205:INFO:Copying training dataset
2023-07-24 17:07:13,225:INFO:Defining folds
2023-07-24 17:07:13,225:INFO:Declaring metric variables
2023-07-24 17:07:13,243:INFO:Importing untrained model
2023-07-24 17:07:13,264:INFO:Lasso Least Angle Regression Imported successfully
2023-07-24 17:07:13,291:INFO:Starting cross validation
2023-07-24 17:07:13,293:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-24 17:07:13,964:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-24 17:07:13,965:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-24 17:07:13,979:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-24 17:07:14,005:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-24 17:07:15,195:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-24 17:07:15,247:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-24 17:07:15,275:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-24 17:07:15,379:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-24 17:07:16,065:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-24 17:07:16,106:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-07-24 17:07:16,280:INFO:Calculating mean and std
2023-07-24 17:07:16,283:INFO:Creating metrics dataframe
2023-07-24 17:07:16,447:INFO:Uploading results into container
2023-07-24 17:07:16,447:INFO:Uploading model into container now
2023-07-24 17:07:16,449:INFO:_master_model_container: 42
2023-07-24 17:07:16,449:INFO:_display_container: 5
2023-07-24 17:07:16,450:INFO:LassoLars(random_state=123)
2023-07-24 17:07:16,451:INFO:create_model() successfully completed......................................
2023-07-24 17:07:16,572:INFO:SubProcess create_model() end ==================================
2023-07-24 17:07:16,573:INFO:Creating metrics dataframe
2023-07-24 17:07:16,594:INFO:Initializing Orthogonal Matching Pursuit
2023-07-24 17:07:16,594:INFO:Total runtime is 0.417519215742747 minutes
2023-07-24 17:07:16,602:INFO:SubProcess create_model() called ==================================
2023-07-24 17:07:16,603:INFO:Initializing create_model()
2023-07-24 17:07:16,603:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcb9140a280>, model_only=True, return_train_score=False, kwargs={})
2023-07-24 17:07:16,603:INFO:Checking exceptions
2023-07-24 17:07:16,603:INFO:Importing libraries
2023-07-24 17:07:16,604:INFO:Copying training dataset
2023-07-24 17:07:16,621:INFO:Defining folds
2023-07-24 17:07:16,621:INFO:Declaring metric variables
2023-07-24 17:07:16,644:INFO:Importing untrained model
2023-07-24 17:07:16,658:INFO:Orthogonal Matching Pursuit Imported successfully
2023-07-24 17:07:16,677:INFO:Starting cross validation
2023-07-24 17:07:16,679:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-24 17:07:17,297:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-24 17:07:17,304:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-24 17:07:17,322:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-24 17:07:17,325:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-24 17:07:17,345:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2023-07-24 17:07:18,258:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-24 17:07:18,293:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-24 17:07:18,295:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-24 17:07:18,358:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-24 17:07:18,952:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-24 17:07:18,953:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-07-24 17:07:18,962:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2023-07-24 17:07:19,224:INFO:Calculating mean and std
2023-07-24 17:07:19,225:INFO:Creating metrics dataframe
2023-07-24 17:07:19,311:INFO:Uploading results into container
2023-07-24 17:07:19,312:INFO:Uploading model into container now
2023-07-24 17:07:19,312:INFO:_master_model_container: 43
2023-07-24 17:07:19,312:INFO:_display_container: 5
2023-07-24 17:07:19,313:INFO:OrthogonalMatchingPursuit()
2023-07-24 17:07:19,313:INFO:create_model() successfully completed......................................
2023-07-24 17:07:19,447:INFO:SubProcess create_model() end ==================================
2023-07-24 17:07:19,447:INFO:Creating metrics dataframe
2023-07-24 17:07:19,471:INFO:Initializing Bayesian Ridge
2023-07-24 17:07:19,471:INFO:Total runtime is 0.46546894709269204 minutes
2023-07-24 17:07:19,480:INFO:SubProcess create_model() called ==================================
2023-07-24 17:07:19,481:INFO:Initializing create_model()
2023-07-24 17:07:19,481:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcb9140a280>, model_only=True, return_train_score=False, kwargs={})
2023-07-24 17:07:19,481:INFO:Checking exceptions
2023-07-24 17:07:19,482:INFO:Importing libraries
2023-07-24 17:07:19,483:INFO:Copying training dataset
2023-07-24 17:07:19,508:INFO:Defining folds
2023-07-24 17:07:19,509:INFO:Declaring metric variables
2023-07-24 17:07:19,572:INFO:Importing untrained model
2023-07-24 17:07:19,580:INFO:Bayesian Ridge Imported successfully
2023-07-24 17:07:19,643:INFO:Starting cross validation
2023-07-24 17:07:19,647:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-24 17:07:23,303:INFO:Calculating mean and std
2023-07-24 17:07:23,306:INFO:Creating metrics dataframe
2023-07-24 17:07:23,393:INFO:Uploading results into container
2023-07-24 17:07:23,394:INFO:Uploading model into container now
2023-07-24 17:07:23,395:INFO:_master_model_container: 44
2023-07-24 17:07:23,395:INFO:_display_container: 5
2023-07-24 17:07:23,396:INFO:BayesianRidge()
2023-07-24 17:07:23,396:INFO:create_model() successfully completed......................................
2023-07-24 17:07:23,522:INFO:SubProcess create_model() end ==================================
2023-07-24 17:07:23,522:INFO:Creating metrics dataframe
2023-07-24 17:07:23,548:INFO:Initializing Passive Aggressive Regressor
2023-07-24 17:07:23,548:INFO:Total runtime is 0.5334233959515889 minutes
2023-07-24 17:07:23,559:INFO:SubProcess create_model() called ==================================
2023-07-24 17:07:23,560:INFO:Initializing create_model()
2023-07-24 17:07:23,560:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcb9140a280>, model_only=True, return_train_score=False, kwargs={})
2023-07-24 17:07:23,560:INFO:Checking exceptions
2023-07-24 17:07:23,560:INFO:Importing libraries
2023-07-24 17:07:23,562:INFO:Copying training dataset
2023-07-24 17:07:23,615:INFO:Defining folds
2023-07-24 17:07:23,615:INFO:Declaring metric variables
2023-07-24 17:07:23,661:INFO:Importing untrained model
2023-07-24 17:07:23,675:INFO:Passive Aggressive Regressor Imported successfully
2023-07-24 17:07:23,706:INFO:Starting cross validation
2023-07-24 17:07:23,708:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-24 17:07:27,534:INFO:Calculating mean and std
2023-07-24 17:07:27,537:INFO:Creating metrics dataframe
2023-07-24 17:07:27,704:INFO:Uploading results into container
2023-07-24 17:07:27,712:INFO:Uploading model into container now
2023-07-24 17:07:27,714:INFO:_master_model_container: 45
2023-07-24 17:07:27,716:INFO:_display_container: 5
2023-07-24 17:07:27,725:INFO:PassiveAggressiveRegressor(random_state=123)
2023-07-24 17:07:27,725:INFO:create_model() successfully completed......................................
2023-07-24 17:07:27,845:INFO:SubProcess create_model() end ==================================
2023-07-24 17:07:27,845:INFO:Creating metrics dataframe
2023-07-24 17:07:27,874:INFO:Initializing Huber Regressor
2023-07-24 17:07:27,874:INFO:Total runtime is 0.605518913269043 minutes
2023-07-24 17:07:27,884:INFO:SubProcess create_model() called ==================================
2023-07-24 17:07:27,886:INFO:Initializing create_model()
2023-07-24 17:07:27,886:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcb9140a280>, model_only=True, return_train_score=False, kwargs={})
2023-07-24 17:07:27,886:INFO:Checking exceptions
2023-07-24 17:07:27,887:INFO:Importing libraries
2023-07-24 17:07:27,887:INFO:Copying training dataset
2023-07-24 17:07:27,965:INFO:Defining folds
2023-07-24 17:07:27,966:INFO:Declaring metric variables
2023-07-24 17:07:27,979:INFO:Importing untrained model
2023-07-24 17:07:27,995:INFO:Huber Regressor Imported successfully
2023-07-24 17:07:28,037:INFO:Starting cross validation
2023-07-24 17:07:28,045:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-24 17:07:31,522:INFO:Calculating mean and std
2023-07-24 17:07:31,525:INFO:Creating metrics dataframe
2023-07-24 17:07:31,667:INFO:Uploading results into container
2023-07-24 17:07:31,677:INFO:Uploading model into container now
2023-07-24 17:07:31,678:INFO:_master_model_container: 46
2023-07-24 17:07:31,678:INFO:_display_container: 5
2023-07-24 17:07:31,678:INFO:HuberRegressor()
2023-07-24 17:07:31,678:INFO:create_model() successfully completed......................................
2023-07-24 17:07:31,882:INFO:SubProcess create_model() end ==================================
2023-07-24 17:07:31,882:INFO:Creating metrics dataframe
2023-07-24 17:07:31,947:INFO:Initializing K Neighbors Regressor
2023-07-24 17:07:31,947:INFO:Total runtime is 0.67340616385142 minutes
2023-07-24 17:07:31,989:INFO:SubProcess create_model() called ==================================
2023-07-24 17:07:32,009:INFO:Initializing create_model()
2023-07-24 17:07:32,009:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcb9140a280>, model_only=True, return_train_score=False, kwargs={})
2023-07-24 17:07:32,009:INFO:Checking exceptions
2023-07-24 17:07:32,009:INFO:Importing libraries
2023-07-24 17:07:32,009:INFO:Copying training dataset
2023-07-24 17:07:32,074:INFO:Defining folds
2023-07-24 17:07:32,075:INFO:Declaring metric variables
2023-07-24 17:07:32,106:INFO:Importing untrained model
2023-07-24 17:07:32,139:INFO:K Neighbors Regressor Imported successfully
2023-07-24 17:07:32,175:INFO:Starting cross validation
2023-07-24 17:07:32,182:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-24 17:07:37,582:INFO:Calculating mean and std
2023-07-24 17:07:37,584:INFO:Creating metrics dataframe
2023-07-24 17:07:37,662:INFO:Uploading results into container
2023-07-24 17:07:37,662:INFO:Uploading model into container now
2023-07-24 17:07:37,663:INFO:_master_model_container: 47
2023-07-24 17:07:37,663:INFO:_display_container: 5
2023-07-24 17:07:37,663:INFO:KNeighborsRegressor(n_jobs=-1)
2023-07-24 17:07:37,663:INFO:create_model() successfully completed......................................
2023-07-24 17:07:37,781:INFO:SubProcess create_model() end ==================================
2023-07-24 17:07:37,782:INFO:Creating metrics dataframe
2023-07-24 17:07:37,817:INFO:Initializing Decision Tree Regressor
2023-07-24 17:07:37,817:INFO:Total runtime is 0.7712400476137796 minutes
2023-07-24 17:07:37,828:INFO:SubProcess create_model() called ==================================
2023-07-24 17:07:37,828:INFO:Initializing create_model()
2023-07-24 17:07:37,829:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcb9140a280>, model_only=True, return_train_score=False, kwargs={})
2023-07-24 17:07:37,829:INFO:Checking exceptions
2023-07-24 17:07:37,829:INFO:Importing libraries
2023-07-24 17:07:37,829:INFO:Copying training dataset
2023-07-24 17:07:37,863:INFO:Defining folds
2023-07-24 17:07:37,864:INFO:Declaring metric variables
2023-07-24 17:07:37,916:INFO:Importing untrained model
2023-07-24 17:07:37,935:INFO:Decision Tree Regressor Imported successfully
2023-07-24 17:07:37,967:INFO:Starting cross validation
2023-07-24 17:07:37,970:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-24 17:07:41,767:INFO:Calculating mean and std
2023-07-24 17:07:41,768:INFO:Creating metrics dataframe
2023-07-24 17:07:41,866:INFO:Uploading results into container
2023-07-24 17:07:41,866:INFO:Uploading model into container now
2023-07-24 17:07:41,867:INFO:_master_model_container: 48
2023-07-24 17:07:41,867:INFO:_display_container: 5
2023-07-24 17:07:41,868:INFO:DecisionTreeRegressor(random_state=123)
2023-07-24 17:07:41,868:INFO:create_model() successfully completed......................................
2023-07-24 17:07:41,977:INFO:SubProcess create_model() end ==================================
2023-07-24 17:07:41,977:INFO:Creating metrics dataframe
2023-07-24 17:07:42,001:INFO:Initializing Random Forest Regressor
2023-07-24 17:07:42,001:INFO:Total runtime is 0.8409772157669066 minutes
2023-07-24 17:07:42,012:INFO:SubProcess create_model() called ==================================
2023-07-24 17:07:42,012:INFO:Initializing create_model()
2023-07-24 17:07:42,013:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcb9140a280>, model_only=True, return_train_score=False, kwargs={})
2023-07-24 17:07:42,013:INFO:Checking exceptions
2023-07-24 17:07:42,013:INFO:Importing libraries
2023-07-24 17:07:42,014:INFO:Copying training dataset
2023-07-24 17:07:42,149:INFO:Defining folds
2023-07-24 17:07:42,151:INFO:Declaring metric variables
2023-07-24 17:07:42,170:INFO:Importing untrained model
2023-07-24 17:07:42,184:INFO:Random Forest Regressor Imported successfully
2023-07-24 17:07:42,229:INFO:Starting cross validation
2023-07-24 17:07:42,234:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-24 17:07:46,637:INFO:Calculating mean and std
2023-07-24 17:07:46,639:INFO:Creating metrics dataframe
2023-07-24 17:07:46,761:INFO:Uploading results into container
2023-07-24 17:07:46,762:INFO:Uploading model into container now
2023-07-24 17:07:46,762:INFO:_master_model_container: 49
2023-07-24 17:07:46,763:INFO:_display_container: 5
2023-07-24 17:07:46,764:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-07-24 17:07:46,764:INFO:create_model() successfully completed......................................
2023-07-24 17:07:46,869:INFO:SubProcess create_model() end ==================================
2023-07-24 17:07:46,869:INFO:Creating metrics dataframe
2023-07-24 17:07:46,899:INFO:Initializing Extra Trees Regressor
2023-07-24 17:07:46,899:INFO:Total runtime is 0.9226059953371682 minutes
2023-07-24 17:07:46,909:INFO:SubProcess create_model() called ==================================
2023-07-24 17:07:46,909:INFO:Initializing create_model()
2023-07-24 17:07:46,910:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcb9140a280>, model_only=True, return_train_score=False, kwargs={})
2023-07-24 17:07:46,910:INFO:Checking exceptions
2023-07-24 17:07:46,910:INFO:Importing libraries
2023-07-24 17:07:46,910:INFO:Copying training dataset
2023-07-24 17:07:46,939:INFO:Defining folds
2023-07-24 17:07:46,939:INFO:Declaring metric variables
2023-07-24 17:07:46,951:INFO:Importing untrained model
2023-07-24 17:07:46,981:INFO:Extra Trees Regressor Imported successfully
2023-07-24 17:07:47,013:INFO:Starting cross validation
2023-07-24 17:07:47,022:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-24 17:07:51,279:INFO:Calculating mean and std
2023-07-24 17:07:51,281:INFO:Creating metrics dataframe
2023-07-24 17:07:51,352:INFO:Uploading results into container
2023-07-24 17:07:51,353:INFO:Uploading model into container now
2023-07-24 17:07:51,353:INFO:_master_model_container: 50
2023-07-24 17:07:51,353:INFO:_display_container: 5
2023-07-24 17:07:51,354:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-07-24 17:07:51,354:INFO:create_model() successfully completed......................................
2023-07-24 17:07:51,458:INFO:SubProcess create_model() end ==================================
2023-07-24 17:07:51,458:INFO:Creating metrics dataframe
2023-07-24 17:07:51,482:INFO:Initializing AdaBoost Regressor
2023-07-24 17:07:51,482:INFO:Total runtime is 0.998989951610565 minutes
2023-07-24 17:07:51,495:INFO:SubProcess create_model() called ==================================
2023-07-24 17:07:51,495:INFO:Initializing create_model()
2023-07-24 17:07:51,496:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcb9140a280>, model_only=True, return_train_score=False, kwargs={})
2023-07-24 17:07:51,496:INFO:Checking exceptions
2023-07-24 17:07:51,496:INFO:Importing libraries
2023-07-24 17:07:51,496:INFO:Copying training dataset
2023-07-24 17:07:51,512:INFO:Defining folds
2023-07-24 17:07:51,513:INFO:Declaring metric variables
2023-07-24 17:07:51,568:INFO:Importing untrained model
2023-07-24 17:07:51,590:INFO:AdaBoost Regressor Imported successfully
2023-07-24 17:07:51,629:INFO:Starting cross validation
2023-07-24 17:07:51,631:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-24 17:07:54,822:INFO:Calculating mean and std
2023-07-24 17:07:54,823:INFO:Creating metrics dataframe
2023-07-24 17:07:54,914:INFO:Uploading results into container
2023-07-24 17:07:54,914:INFO:Uploading model into container now
2023-07-24 17:07:54,915:INFO:_master_model_container: 51
2023-07-24 17:07:54,915:INFO:_display_container: 5
2023-07-24 17:07:54,915:INFO:AdaBoostRegressor(random_state=123)
2023-07-24 17:07:54,916:INFO:create_model() successfully completed......................................
2023-07-24 17:07:55,020:INFO:SubProcess create_model() end ==================================
2023-07-24 17:07:55,021:INFO:Creating metrics dataframe
2023-07-24 17:07:55,046:INFO:Initializing Gradient Boosting Regressor
2023-07-24 17:07:55,046:INFO:Total runtime is 1.0583860516548156 minutes
2023-07-24 17:07:55,056:INFO:SubProcess create_model() called ==================================
2023-07-24 17:07:55,057:INFO:Initializing create_model()
2023-07-24 17:07:55,057:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcb9140a280>, model_only=True, return_train_score=False, kwargs={})
2023-07-24 17:07:55,057:INFO:Checking exceptions
2023-07-24 17:07:55,057:INFO:Importing libraries
2023-07-24 17:07:55,058:INFO:Copying training dataset
2023-07-24 17:07:55,075:INFO:Defining folds
2023-07-24 17:07:55,075:INFO:Declaring metric variables
2023-07-24 17:07:55,088:INFO:Importing untrained model
2023-07-24 17:07:55,107:INFO:Gradient Boosting Regressor Imported successfully
2023-07-24 17:07:55,129:INFO:Starting cross validation
2023-07-24 17:07:55,132:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-24 17:07:58,183:INFO:Calculating mean and std
2023-07-24 17:07:58,186:INFO:Creating metrics dataframe
2023-07-24 17:07:58,260:INFO:Uploading results into container
2023-07-24 17:07:58,260:INFO:Uploading model into container now
2023-07-24 17:07:58,261:INFO:_master_model_container: 52
2023-07-24 17:07:58,261:INFO:_display_container: 5
2023-07-24 17:07:58,261:INFO:GradientBoostingRegressor(random_state=123)
2023-07-24 17:07:58,261:INFO:create_model() successfully completed......................................
2023-07-24 17:07:58,360:INFO:SubProcess create_model() end ==================================
2023-07-24 17:07:58,360:INFO:Creating metrics dataframe
2023-07-24 17:07:58,382:INFO:Initializing Extreme Gradient Boosting
2023-07-24 17:07:58,383:INFO:Total runtime is 1.1139960289001465 minutes
2023-07-24 17:07:58,390:INFO:SubProcess create_model() called ==================================
2023-07-24 17:07:58,391:INFO:Initializing create_model()
2023-07-24 17:07:58,391:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcb9140a280>, model_only=True, return_train_score=False, kwargs={})
2023-07-24 17:07:58,391:INFO:Checking exceptions
2023-07-24 17:07:58,392:INFO:Importing libraries
2023-07-24 17:07:58,392:INFO:Copying training dataset
2023-07-24 17:07:58,408:INFO:Defining folds
2023-07-24 17:07:58,409:INFO:Declaring metric variables
2023-07-24 17:07:58,430:INFO:Importing untrained model
2023-07-24 17:07:58,445:INFO:Extreme Gradient Boosting Imported successfully
2023-07-24 17:07:58,467:INFO:Starting cross validation
2023-07-24 17:07:58,469:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-24 17:08:00,803:INFO:Calculating mean and std
2023-07-24 17:08:00,808:INFO:Creating metrics dataframe
2023-07-24 17:08:00,879:INFO:Uploading results into container
2023-07-24 17:08:00,879:INFO:Uploading model into container now
2023-07-24 17:08:00,880:INFO:_master_model_container: 53
2023-07-24 17:08:00,880:INFO:_display_container: 5
2023-07-24 17:08:00,881:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=123, ...)
2023-07-24 17:08:00,881:INFO:create_model() successfully completed......................................
2023-07-24 17:08:00,979:INFO:SubProcess create_model() end ==================================
2023-07-24 17:08:00,979:INFO:Creating metrics dataframe
2023-07-24 17:08:01,003:INFO:Initializing Light Gradient Boosting Machine
2023-07-24 17:08:01,004:INFO:Total runtime is 1.157682148615519 minutes
2023-07-24 17:08:01,012:INFO:SubProcess create_model() called ==================================
2023-07-24 17:08:01,013:INFO:Initializing create_model()
2023-07-24 17:08:01,013:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcb9140a280>, model_only=True, return_train_score=False, kwargs={})
2023-07-24 17:08:01,013:INFO:Checking exceptions
2023-07-24 17:08:01,013:INFO:Importing libraries
2023-07-24 17:08:01,014:INFO:Copying training dataset
2023-07-24 17:08:01,030:INFO:Defining folds
2023-07-24 17:08:01,031:INFO:Declaring metric variables
2023-07-24 17:08:01,051:INFO:Importing untrained model
2023-07-24 17:08:01,065:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-24 17:08:01,096:INFO:Starting cross validation
2023-07-24 17:08:01,098:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-24 17:08:06,095:WARNING:create_model() for lightgbm raised an exception or returned all 0.0, trying without fit_kwargs:
2023-07-24 17:08:06,101:WARNING:Traceback (most recent call last):
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1521, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1116, in _create_model_with_cv
    scores = cross_validate(
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 267, in cross_validate
    results = parallel(
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 1944, in __call__
    return output if self.return_generator else list(output)
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 1587, in _get_outputs
    yield from self._retrieve()
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 1691, in _retrieve
    self._raise_error_fast()
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 1726, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 735, in get_result
    return self._return_or_raise()
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 753, in _return_or_raise
    raise self._result
joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.

The exit codes of the workers are {SIGSEGV(-11)}

2023-07-24 17:08:06,102:INFO:Initializing create_model()
2023-07-24 17:08:06,102:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcb9140a280>, model_only=True, return_train_score=False, kwargs={})
2023-07-24 17:08:06,102:INFO:Checking exceptions
2023-07-24 17:08:06,102:INFO:Importing libraries
2023-07-24 17:08:06,102:INFO:Copying training dataset
2023-07-24 17:08:06,115:INFO:Defining folds
2023-07-24 17:08:06,115:INFO:Declaring metric variables
2023-07-24 17:08:06,130:INFO:Importing untrained model
2023-07-24 17:08:06,136:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-24 17:08:06,163:INFO:Starting cross validation
2023-07-24 17:08:06,166:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-24 17:08:16,267:ERROR:create_model() for lightgbm raised an exception or returned all 0.0:
2023-07-24 17:08:16,270:ERROR:Traceback (most recent call last):
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1521, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1116, in _create_model_with_cv
    scores = cross_validate(
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 267, in cross_validate
    results = parallel(
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 1944, in __call__
    return output if self.return_generator else list(output)
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 1587, in _get_outputs
    yield from self._retrieve()
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 1691, in _retrieve
    self._raise_error_fast()
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 1726, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 735, in get_result
    return self._return_or_raise()
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 753, in _return_or_raise
    raise self._result
joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.

The exit codes of the workers are {SIGSEGV(-11)}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1521, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1116, in _create_model_with_cv
    scores = cross_validate(
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 267, in cross_validate
    results = parallel(
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 1944, in __call__
    return output if self.return_generator else list(output)
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 1587, in _get_outputs
    yield from self._retrieve()
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 1691, in _retrieve
    self._raise_error_fast()
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 1726, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 735, in get_result
    return self._return_or_raise()
  File "/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py", line 753, in _return_or_raise
    raise self._result
joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.

The exit codes of the workers are {SIGSEGV(-11)}

2023-07-24 17:08:16,270:INFO:Initializing Dummy Regressor
2023-07-24 17:08:16,271:INFO:Total runtime is 1.412128182252248 minutes
2023-07-24 17:08:16,280:INFO:SubProcess create_model() called ==================================
2023-07-24 17:08:16,280:INFO:Initializing create_model()
2023-07-24 17:08:16,281:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcb9140a280>, model_only=True, return_train_score=False, kwargs={})
2023-07-24 17:08:16,281:INFO:Checking exceptions
2023-07-24 17:08:16,281:INFO:Importing libraries
2023-07-24 17:08:16,282:INFO:Copying training dataset
2023-07-24 17:08:16,299:INFO:Defining folds
2023-07-24 17:08:16,299:INFO:Declaring metric variables
2023-07-24 17:08:16,313:INFO:Importing untrained model
2023-07-24 17:08:16,318:INFO:Dummy Regressor Imported successfully
2023-07-24 17:08:16,341:INFO:Starting cross validation
2023-07-24 17:08:16,345:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-24 17:08:24,277:INFO:Calculating mean and std
2023-07-24 17:08:24,279:INFO:Creating metrics dataframe
2023-07-24 17:08:24,434:INFO:Uploading results into container
2023-07-24 17:08:24,439:INFO:Uploading model into container now
2023-07-24 17:08:24,440:INFO:_master_model_container: 54
2023-07-24 17:08:24,440:INFO:_display_container: 5
2023-07-24 17:08:24,441:INFO:DummyRegressor()
2023-07-24 17:08:24,441:INFO:create_model() successfully completed......................................
2023-07-24 17:08:24,586:INFO:SubProcess create_model() end ==================================
2023-07-24 17:08:24,586:INFO:Creating metrics dataframe
2023-07-24 17:08:24,686:INFO:Initializing create_model()
2023-07-24 17:08:24,686:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=PassiveAggressiveRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-24 17:08:24,688:INFO:Checking exceptions
2023-07-24 17:08:24,692:INFO:Importing libraries
2023-07-24 17:08:24,693:INFO:Copying training dataset
2023-07-24 17:08:24,709:INFO:Defining folds
2023-07-24 17:08:24,710:INFO:Declaring metric variables
2023-07-24 17:08:24,710:INFO:Importing untrained model
2023-07-24 17:08:24,711:INFO:Declaring custom model
2023-07-24 17:08:24,712:INFO:Passive Aggressive Regressor Imported successfully
2023-07-24 17:08:24,716:INFO:Cross validation set to False
2023-07-24 17:08:24,716:INFO:Fitting Model
2023-07-24 17:08:25,162:INFO:PassiveAggressiveRegressor(random_state=123)
2023-07-24 17:08:25,162:INFO:create_model() successfully completed......................................
2023-07-24 17:08:25,363:INFO:_master_model_container: 54
2023-07-24 17:08:25,363:INFO:_display_container: 5
2023-07-24 17:08:25,364:INFO:PassiveAggressiveRegressor(random_state=123)
2023-07-24 17:08:25,364:INFO:compare_models() successfully completed......................................
2023-07-24 17:13:02,797:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-24 17:13:02,798:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-24 17:13:02,799:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-24 17:13:02,799:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-24 17:18:03,851:WARNING:Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)

2023-07-24 17:24:56,019:INFO:PyCaret ClassificationExperiment
2023-07-24 17:24:56,020:INFO:Logging name: clf-default-name
2023-07-24 17:24:56,020:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-07-24 17:24:56,021:INFO:version 3.0.4
2023-07-24 17:24:56,021:INFO:Initializing setup()
2023-07-24 17:24:56,021:INFO:self.USI: a86a
2023-07-24 17:24:56,021:INFO:self._variable_keys: {'y_train', 'data', 'X_test', 'exp_id', 'log_plots_param', 'n_jobs_param', 'y_test', 'USI', '_ml_usecase', 'y', 'target_param', 'exp_name_log', 'fold_generator', 'html_param', 'fold_groups_param', 'fold_shuffle_param', 'idx', 'X_train', 'is_multiclass', 'gpu_param', 'X', 'logging_param', 'memory', 'gpu_n_jobs_param', 'pipeline', '_available_plots', 'seed', 'fix_imbalance'}
2023-07-24 17:24:56,021:INFO:Checking environment
2023-07-24 17:24:56,021:INFO:python_version: 3.9.13
2023-07-24 17:24:56,021:INFO:python_build: ('main', 'Aug 25 2022 18:29:29')
2023-07-24 17:24:56,021:INFO:machine: x86_64
2023-07-24 17:24:56,021:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-07-24 17:24:56,021:INFO:Memory: svmem(total=8589934592, available=2603057152, percent=69.7, used=4082647040, free=54362112, active=2551078912, inactive=2546442240, wired=1531568128)
2023-07-24 17:24:56,021:INFO:Physical Core: 2
2023-07-24 17:24:56,021:INFO:Logical Core: 4
2023-07-24 17:24:56,021:INFO:Checking libraries
2023-07-24 17:24:56,021:INFO:System:
2023-07-24 17:24:56,022:INFO:    python: 3.9.13 (main, Aug 25 2022, 18:29:29)  [Clang 12.0.0 ]
2023-07-24 17:24:56,022:INFO:executable: /Users/iremkurt/opt/anaconda3/bin/python
2023-07-24 17:24:56,022:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-07-24 17:24:56,022:INFO:PyCaret required dependencies:
2023-07-24 17:24:56,261:INFO:                 pip: 23.2
2023-07-24 17:24:56,261:INFO:          setuptools: 63.4.1
2023-07-24 17:24:56,261:INFO:             pycaret: 3.0.4
2023-07-24 17:24:56,261:INFO:             IPython: 8.14.0
2023-07-24 17:24:56,261:INFO:          ipywidgets: 7.7.5
2023-07-24 17:24:56,261:INFO:                tqdm: 4.64.1
2023-07-24 17:24:56,262:INFO:               numpy: 1.23.5
2023-07-24 17:24:56,262:INFO:              pandas: 1.3.1
2023-07-24 17:24:56,262:INFO:              jinja2: 3.1.2
2023-07-24 17:24:56,262:INFO:               scipy: 1.9.1
2023-07-24 17:24:56,262:INFO:              joblib: 1.3.1
2023-07-24 17:24:56,262:INFO:             sklearn: 1.0.2
2023-07-24 17:24:56,262:INFO:                pyod: 1.1.0
2023-07-24 17:24:56,262:INFO:            imblearn: 0.11.0
2023-07-24 17:24:56,262:INFO:   category_encoders: 2.6.1
2023-07-24 17:24:56,262:INFO:            lightgbm: 4.0.0
2023-07-24 17:24:56,262:INFO:               numba: 0.57.1
2023-07-24 17:24:56,262:INFO:            requests: 2.28.1
2023-07-24 17:24:56,262:INFO:          matplotlib: 3.6.0
2023-07-24 17:24:56,262:INFO:          scikitplot: 0.3.7
2023-07-24 17:24:56,262:INFO:         yellowbrick: 1.5
2023-07-24 17:24:56,262:INFO:              plotly: 5.15.0
2023-07-24 17:24:56,262:INFO:    plotly-resampler: Not installed
2023-07-24 17:24:56,262:INFO:             kaleido: 0.2.1
2023-07-24 17:24:56,262:INFO:           schemdraw: 0.15
2023-07-24 17:24:56,263:INFO:         statsmodels: 0.13.2
2023-07-24 17:24:56,263:INFO:              sktime: 0.20.0
2023-07-24 17:24:56,263:INFO:               tbats: 1.1.3
2023-07-24 17:24:56,263:INFO:            pmdarima: 2.0.3
2023-07-24 17:24:56,263:INFO:              psutil: 5.9.5
2023-07-24 17:24:56,263:INFO:          markupsafe: 2.1.3
2023-07-24 17:24:56,263:INFO:             pickle5: Not installed
2023-07-24 17:24:56,263:INFO:         cloudpickle: 2.2.1
2023-07-24 17:24:56,263:INFO:         deprecation: 2.1.0
2023-07-24 17:24:56,263:INFO:              xxhash: 3.2.0
2023-07-24 17:24:56,263:INFO:           wurlitzer: 3.0.2
2023-07-24 17:24:56,263:INFO:PyCaret optional dependencies:
2023-07-24 17:24:57,030:INFO:                shap: 0.42.1
2023-07-24 17:24:57,034:INFO:           interpret: Not installed
2023-07-24 17:24:57,035:INFO:                umap: Not installed
2023-07-24 17:24:57,035:INFO:    pandas_profiling: 0.0.dev0
2023-07-24 17:24:57,035:INFO:  explainerdashboard: Not installed
2023-07-24 17:24:57,035:INFO:             autoviz: Not installed
2023-07-24 17:24:57,035:INFO:           fairlearn: Not installed
2023-07-24 17:24:57,035:INFO:          deepchecks: Not installed
2023-07-24 17:24:57,035:INFO:             xgboost: 1.7.6
2023-07-24 17:24:57,035:INFO:            catboost: Not installed
2023-07-24 17:24:57,035:INFO:              kmodes: Not installed
2023-07-24 17:24:57,035:INFO:             mlxtend: Not installed
2023-07-24 17:24:57,035:INFO:       statsforecast: Not installed
2023-07-24 17:24:57,035:INFO:        tune_sklearn: Not installed
2023-07-24 17:24:57,035:INFO:                 ray: Not installed
2023-07-24 17:24:57,035:INFO:            hyperopt: Not installed
2023-07-24 17:24:57,035:INFO:              optuna: Not installed
2023-07-24 17:24:57,035:INFO:               skopt: Not installed
2023-07-24 17:24:57,035:INFO:              mlflow: Not installed
2023-07-24 17:24:57,035:INFO:              gradio: Not installed
2023-07-24 17:24:57,035:INFO:             fastapi: 0.100.0
2023-07-24 17:24:57,036:INFO:             uvicorn: 0.23.0
2023-07-24 17:24:57,036:INFO:              m2cgen: Not installed
2023-07-24 17:24:57,036:INFO:           evidently: Not installed
2023-07-24 17:24:57,036:INFO:               fugue: Not installed
2023-07-24 17:24:57,036:INFO:           streamlit: 1.24.1
2023-07-24 17:24:57,036:INFO:             prophet: 1.1.4
2023-07-24 17:24:57,036:INFO:None
2023-07-24 17:24:57,036:INFO:Set up data.
2023-07-24 17:24:57,149:INFO:Set up train/test split.
2023-07-24 17:24:57,246:INFO:Set up index.
2023-07-24 17:24:57,250:INFO:Set up folding strategy.
2023-07-24 17:24:57,250:INFO:Assigning column types.
2023-07-24 17:24:57,279:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-07-24 17:24:57,582:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-24 17:24:57,594:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-24 17:24:57,753:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-24 17:24:57,761:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-24 17:24:57,878:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-24 17:24:57,879:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-24 17:24:57,931:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-24 17:24:57,934:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-24 17:24:57,937:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-07-24 17:24:58,001:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-24 17:24:58,050:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-24 17:24:58,054:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-24 17:24:58,139:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-24 17:24:58,215:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-24 17:24:58,219:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-24 17:24:58,219:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-07-24 17:24:58,360:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-24 17:24:58,364:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-24 17:24:58,502:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-24 17:24:58,512:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-24 17:24:58,518:INFO:Preparing preprocessing pipeline...
2023-07-24 17:24:58,530:INFO:Set up label encoding.
2023-07-24 17:24:58,530:INFO:Set up simple imputation.
2023-07-24 17:24:58,550:INFO:Set up encoding of ordinal features.
2023-07-24 17:24:58,554:INFO:Set up encoding of categorical features.
2023-07-24 17:25:00,849:INFO:Finished creating preprocessing pipeline.
2023-07-24 17:25:00,889:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/q_/m4c7kcfx23lfngmh1d06_9_c0000gn/T/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'final_weight',
                                             'education_num', 'capital_gain',
                                             'capital_loss', 'hours_per_week'],...
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['native_country'],
                                    transformer=TargetEncoder(cols=['native_country'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2023-07-24 17:25:00,890:INFO:Creating final display dataframe.
2023-07-24 17:25:02,049:INFO:Setup _display_container:                     Description                Value
0                    Session id                  123
1                        Target          income_flag
2                   Target type               Binary
3                Target mapping   <=50K: 0,  >50K: 1
4           Original data shape          (32560, 15)
5        Transformed data shape          (32560, 67)
6   Transformed train set shape          (22792, 67)
7    Transformed test set shape           (9768, 67)
8              Ordinal features                    1
9              Numeric features                    6
10         Categorical features                    8
11                   Preprocess                 True
12              Imputation type               simple
13           Numeric imputation                 mean
14       Categorical imputation                 mode
15     Maximum one-hot encoding                   25
16              Encoding method                 None
17               Fold Generator      StratifiedKFold
18                  Fold Number                   10
19                     CPU Jobs                   -1
20                      Use GPU                False
21               Log Experiment                False
22              Experiment Name     clf-default-name
23                          USI                 a86a
2023-07-24 17:25:02,540:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-24 17:25:02,545:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-24 17:25:02,664:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-24 17:25:02,668:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-24 17:25:02,669:INFO:setup() successfully completed in 6.9s...............
2023-07-24 17:25:04,920:INFO:Initializing compare_models()
2023-07-24 17:25:04,920:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbbd04cb8b0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7fbbd04cb8b0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-07-24 17:25:04,921:INFO:Checking exceptions
2023-07-24 17:25:04,940:INFO:Preparing display monitor
2023-07-24 17:25:05,223:INFO:Initializing Logistic Regression
2023-07-24 17:25:05,225:INFO:Total runtime is 2.6913483937581382e-05 minutes
2023-07-24 17:25:05,271:INFO:SubProcess create_model() called ==================================
2023-07-24 17:25:05,273:INFO:Initializing create_model()
2023-07-24 17:25:05,274:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbbd04cb8b0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbbd04cb5e0>, model_only=True, return_train_score=False, kwargs={})
2023-07-24 17:25:05,274:INFO:Checking exceptions
2023-07-24 17:25:05,274:INFO:Importing libraries
2023-07-24 17:25:05,274:INFO:Copying training dataset
2023-07-24 17:25:05,392:INFO:Defining folds
2023-07-24 17:25:05,393:INFO:Declaring metric variables
2023-07-24 17:25:05,406:INFO:Importing untrained model
2023-07-24 17:25:05,426:INFO:Logistic Regression Imported successfully
2023-07-24 17:25:05,465:INFO:Starting cross validation
2023-07-24 17:25:05,482:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-24 17:40:47,336:INFO:Initializing predict_model()
2023-07-24 17:40:47,337:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=PassiveAggressiveRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fcb90d1a1f0>)
2023-07-24 17:40:47,337:INFO:Checking exceptions
2023-07-24 17:40:47,337:INFO:Preloading libraries
2023-07-24 17:40:47,350:INFO:Set up data.
2023-07-24 17:40:47,563:INFO:Set up index.
2023-07-24 17:43:56,905:INFO:PyCaret ClassificationExperiment
2023-07-24 17:43:56,906:INFO:Logging name: clf-default-name
2023-07-24 17:43:56,906:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-07-24 17:43:56,907:INFO:version 3.0.4
2023-07-24 17:43:56,908:INFO:Initializing setup()
2023-07-24 17:43:56,909:INFO:self.USI: 7e49
2023-07-24 17:43:56,909:INFO:self._variable_keys: {'y_train', 'data', 'X_test', 'exp_id', 'log_plots_param', 'n_jobs_param', 'y_test', 'USI', '_ml_usecase', 'y', 'target_param', 'exp_name_log', 'fold_generator', 'html_param', 'fold_groups_param', 'fold_shuffle_param', 'idx', 'X_train', 'is_multiclass', 'gpu_param', 'X', 'logging_param', 'memory', 'gpu_n_jobs_param', 'pipeline', '_available_plots', 'seed', 'fix_imbalance'}
2023-07-24 17:43:56,910:INFO:Checking environment
2023-07-24 17:43:56,910:INFO:python_version: 3.9.13
2023-07-24 17:43:56,911:INFO:python_build: ('main', 'Aug 25 2022 18:29:29')
2023-07-24 17:43:56,911:INFO:machine: x86_64
2023-07-24 17:43:56,911:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-07-24 17:43:56,911:INFO:Memory: svmem(total=8589934592, available=2878226432, percent=66.5, used=4370939904, free=18477056, active=2865332224, inactive=2848509952, wired=1505607680)
2023-07-24 17:43:56,912:INFO:Physical Core: 2
2023-07-24 17:43:56,912:INFO:Logical Core: 4
2023-07-24 17:43:56,912:INFO:Checking libraries
2023-07-24 17:43:56,912:INFO:System:
2023-07-24 17:43:56,912:INFO:    python: 3.9.13 (main, Aug 25 2022, 18:29:29)  [Clang 12.0.0 ]
2023-07-24 17:43:56,912:INFO:executable: /Users/iremkurt/opt/anaconda3/bin/python
2023-07-24 17:43:56,912:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-07-24 17:43:56,912:INFO:PyCaret required dependencies:
2023-07-24 17:43:56,913:INFO:                 pip: 23.2
2023-07-24 17:43:56,913:INFO:          setuptools: 63.4.1
2023-07-24 17:43:56,913:INFO:             pycaret: 3.0.4
2023-07-24 17:43:56,913:INFO:             IPython: 8.14.0
2023-07-24 17:43:56,913:INFO:          ipywidgets: 7.7.5
2023-07-24 17:43:56,913:INFO:                tqdm: 4.64.1
2023-07-24 17:43:56,913:INFO:               numpy: 1.23.5
2023-07-24 17:43:56,913:INFO:              pandas: 1.3.1
2023-07-24 17:43:56,913:INFO:              jinja2: 3.1.2
2023-07-24 17:43:56,913:INFO:               scipy: 1.9.1
2023-07-24 17:43:56,913:INFO:              joblib: 1.3.1
2023-07-24 17:43:56,913:INFO:             sklearn: 1.0.2
2023-07-24 17:43:56,913:INFO:                pyod: 1.1.0
2023-07-24 17:43:56,913:INFO:            imblearn: 0.11.0
2023-07-24 17:43:56,915:INFO:   category_encoders: 2.6.1
2023-07-24 17:43:56,915:INFO:            lightgbm: 4.0.0
2023-07-24 17:43:56,915:INFO:               numba: 0.57.1
2023-07-24 17:43:56,916:INFO:            requests: 2.28.1
2023-07-24 17:43:56,916:INFO:          matplotlib: 3.6.0
2023-07-24 17:43:56,916:INFO:          scikitplot: 0.3.7
2023-07-24 17:43:56,916:INFO:         yellowbrick: 1.5
2023-07-24 17:43:56,916:INFO:              plotly: 5.15.0
2023-07-24 17:43:56,917:INFO:    plotly-resampler: Not installed
2023-07-24 17:43:56,918:INFO:             kaleido: 0.2.1
2023-07-24 17:43:56,918:INFO:           schemdraw: 0.15
2023-07-24 17:43:56,918:INFO:         statsmodels: 0.13.2
2023-07-24 17:43:56,918:INFO:              sktime: 0.20.0
2023-07-24 17:43:56,919:INFO:               tbats: 1.1.3
2023-07-24 17:43:56,919:INFO:            pmdarima: 2.0.3
2023-07-24 17:43:56,919:INFO:              psutil: 5.9.5
2023-07-24 17:43:56,919:INFO:          markupsafe: 2.1.3
2023-07-24 17:43:56,919:INFO:             pickle5: Not installed
2023-07-24 17:43:56,919:INFO:         cloudpickle: 2.2.1
2023-07-24 17:43:56,920:INFO:         deprecation: 2.1.0
2023-07-24 17:43:56,920:INFO:              xxhash: 3.2.0
2023-07-24 17:43:56,920:INFO:           wurlitzer: 3.0.2
2023-07-24 17:43:56,920:INFO:PyCaret optional dependencies:
2023-07-24 17:43:56,921:INFO:                shap: 0.42.1
2023-07-24 17:43:56,921:INFO:           interpret: Not installed
2023-07-24 17:43:56,921:INFO:                umap: Not installed
2023-07-24 17:43:56,921:INFO:    pandas_profiling: 0.0.dev0
2023-07-24 17:43:56,921:INFO:  explainerdashboard: Not installed
2023-07-24 17:43:56,921:INFO:             autoviz: Not installed
2023-07-24 17:43:56,921:INFO:           fairlearn: Not installed
2023-07-24 17:43:56,921:INFO:          deepchecks: Not installed
2023-07-24 17:43:56,921:INFO:             xgboost: 1.7.6
2023-07-24 17:43:56,922:INFO:            catboost: Not installed
2023-07-24 17:43:56,922:INFO:              kmodes: Not installed
2023-07-24 17:43:56,922:INFO:             mlxtend: Not installed
2023-07-24 17:43:56,922:INFO:       statsforecast: Not installed
2023-07-24 17:43:56,923:INFO:        tune_sklearn: Not installed
2023-07-24 17:43:56,923:INFO:                 ray: Not installed
2023-07-24 17:43:56,923:INFO:            hyperopt: Not installed
2023-07-24 17:43:56,923:INFO:              optuna: Not installed
2023-07-24 17:43:56,923:INFO:               skopt: Not installed
2023-07-24 17:43:56,923:INFO:              mlflow: Not installed
2023-07-24 17:43:56,923:INFO:              gradio: Not installed
2023-07-24 17:43:56,923:INFO:             fastapi: 0.100.0
2023-07-24 17:43:56,923:INFO:             uvicorn: 0.23.0
2023-07-24 17:43:56,925:INFO:              m2cgen: Not installed
2023-07-24 17:43:56,925:INFO:           evidently: Not installed
2023-07-24 17:43:56,925:INFO:               fugue: Not installed
2023-07-24 17:43:56,926:INFO:           streamlit: 1.24.1
2023-07-24 17:43:56,926:INFO:             prophet: 1.1.4
2023-07-24 17:43:56,926:INFO:None
2023-07-24 17:43:56,926:INFO:Set up data.
2023-07-24 17:43:57,176:INFO:Set up train/test split.
2023-07-24 17:43:57,256:INFO:Set up index.
2023-07-24 17:43:57,263:INFO:Set up folding strategy.
2023-07-24 17:43:57,263:INFO:Assigning column types.
2023-07-24 17:43:57,289:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-07-24 17:43:57,392:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-24 17:43:57,397:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-24 17:43:57,504:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-24 17:43:57,516:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-24 17:43:57,655:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-24 17:43:57,658:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-24 17:43:57,739:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-24 17:43:57,748:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-24 17:43:57,749:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-07-24 17:43:57,881:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-24 17:43:57,953:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-24 17:43:57,963:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-24 17:43:58,063:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-24 17:43:58,117:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-24 17:43:58,121:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-24 17:43:58,121:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-07-24 17:43:58,278:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-24 17:43:58,282:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-24 17:43:58,518:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-24 17:43:58,528:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-24 17:43:58,531:INFO:Preparing preprocessing pipeline...
2023-07-24 17:43:58,535:INFO:Set up label encoding.
2023-07-24 17:43:58,536:INFO:Set up simple imputation.
2023-07-24 17:43:58,552:INFO:Set up encoding of ordinal features.
2023-07-24 17:43:58,557:INFO:Set up encoding of categorical features.
2023-07-24 17:43:59,748:INFO:Finished creating preprocessing pipeline.
2023-07-24 17:43:59,915:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/q_/m4c7kcfx23lfngmh1d06_9_c0000gn/T/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'final_weight',
                                             'education_num', 'capital_gain',
                                             'capital_loss', 'hours_per_week'],...
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['native_country'],
                                    transformer=TargetEncoder(cols=['native_country'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2023-07-24 17:43:59,915:INFO:Creating final display dataframe.
2023-07-24 17:44:01,911:INFO:Setup _display_container:                     Description                Value
0                    Session id                  123
1                        Target          income_flag
2                   Target type               Binary
3                Target mapping   <=50K: 0,  >50K: 1
4           Original data shape          (32560, 15)
5        Transformed data shape          (32560, 67)
6   Transformed train set shape          (22792, 67)
7    Transformed test set shape           (9768, 67)
8              Ordinal features                    1
9              Numeric features                    6
10         Categorical features                    8
11                   Preprocess                 True
12              Imputation type               simple
13           Numeric imputation                 mean
14       Categorical imputation                 mode
15     Maximum one-hot encoding                   25
16              Encoding method                 None
17               Fold Generator      StratifiedKFold
18                  Fold Number                   10
19                     CPU Jobs                   -1
20                      Use GPU                False
21               Log Experiment                False
22              Experiment Name     clf-default-name
23                          USI                 7e49
2023-07-24 17:44:02,301:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-24 17:44:02,315:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-24 17:44:02,491:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-24 17:44:02,496:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-24 17:44:02,497:INFO:setup() successfully completed in 5.88s...............
2023-07-24 17:44:02,560:INFO:Initializing compare_models()
2023-07-24 17:44:02,561:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbbbaf03400>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7fbbbaf03400>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-07-24 17:44:02,561:INFO:Checking exceptions
2023-07-24 17:44:02,606:INFO:Preparing display monitor
2023-07-24 17:44:02,762:INFO:Initializing Logistic Regression
2023-07-24 17:44:02,762:INFO:Total runtime is 5.185604095458984e-06 minutes
2023-07-24 17:44:02,773:INFO:SubProcess create_model() called ==================================
2023-07-24 17:44:02,777:INFO:Initializing create_model()
2023-07-24 17:44:02,777:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbbbaf03400>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbba354df10>, model_only=True, return_train_score=False, kwargs={})
2023-07-24 17:44:02,778:INFO:Checking exceptions
2023-07-24 17:44:02,778:INFO:Importing libraries
2023-07-24 17:44:02,778:INFO:Copying training dataset
2023-07-24 17:44:02,828:INFO:Defining folds
2023-07-24 17:44:02,828:INFO:Declaring metric variables
2023-07-24 17:44:02,864:INFO:Importing untrained model
2023-07-24 17:44:02,877:INFO:Logistic Regression Imported successfully
2023-07-24 17:44:02,903:INFO:Starting cross validation
2023-07-24 17:44:02,915:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-24 17:44:16,617:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.67s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_transform(

2023-07-24 17:44:16,618:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.63s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_transform(

2023-07-24 17:44:16,813:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.66s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_transform(

2023-07-24 17:44:16,826:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.63s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_transform(

2023-07-24 17:44:27,337:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.78s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-07-24 17:44:27,454:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.85s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-07-24 17:44:27,785:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-07-24 17:44:27,831:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.63s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-07-24 17:44:33,701:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.76s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_transformer = self._memory_fit(

2023-07-24 17:44:33,735:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.80s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_transformer = self._memory_fit(

2023-07-24 17:44:33,921:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.55s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_transformer = self._memory_fit(

2023-07-24 17:44:33,934:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.59s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_transformer = self._memory_fit(

2023-07-24 17:44:34,907:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.96s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_transform(

2023-07-24 17:44:34,943:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.92s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_transform(

2023-07-24 17:44:35,321:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.78s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_transform(

2023-07-24 17:44:35,367:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.81s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_transform(

2023-07-24 17:44:36,802:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.68s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-07-24 17:44:37,184:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.63s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-07-24 17:44:37,239:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-07-24 17:44:37,255:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-07-24 17:44:43,121:INFO:Calculating mean and std
2023-07-24 17:44:43,128:INFO:Creating metrics dataframe
2023-07-24 17:44:43,387:INFO:Uploading results into container
2023-07-24 17:44:43,388:INFO:Uploading model into container now
2023-07-24 17:44:43,389:INFO:_master_model_container: 1
2023-07-24 17:44:43,390:INFO:_display_container: 2
2023-07-24 17:44:43,390:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-24 17:44:43,391:INFO:create_model() successfully completed......................................
2023-07-24 17:44:44,204:INFO:SubProcess create_model() end ==================================
2023-07-24 17:44:44,204:INFO:Creating metrics dataframe
2023-07-24 17:44:44,241:INFO:Initializing K Neighbors Classifier
2023-07-24 17:44:44,241:INFO:Total runtime is 0.6913183848063151 minutes
2023-07-24 17:44:44,272:INFO:SubProcess create_model() called ==================================
2023-07-24 17:44:44,273:INFO:Initializing create_model()
2023-07-24 17:44:44,273:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbbbaf03400>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbba354df10>, model_only=True, return_train_score=False, kwargs={})
2023-07-24 17:44:44,273:INFO:Checking exceptions
2023-07-24 17:44:44,274:INFO:Importing libraries
2023-07-24 17:44:44,274:INFO:Copying training dataset
2023-07-24 17:44:44,445:INFO:Defining folds
2023-07-24 17:44:44,445:INFO:Declaring metric variables
2023-07-24 17:44:44,518:INFO:Importing untrained model
2023-07-24 17:44:44,526:INFO:K Neighbors Classifier Imported successfully
2023-07-24 17:44:44,556:INFO:Starting cross validation
2023-07-24 17:44:44,563:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-24 17:44:48,061:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.75s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 17:44:48,698:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.20s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 17:44:48,721:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.23s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 17:45:02,978:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-24 17:45:03,196:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-24 17:45:03,264:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-24 17:45:03,268:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-24 17:45:27,175:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.92s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_transform(

2023-07-24 17:45:27,494:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.17s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_transform(

2023-07-24 17:45:30,821:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.17s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 17:45:30,907:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:108: UserWarning: Persisting input arguments took 0.77s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-07-24 17:45:31,483:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:108: UserWarning: Persisting input arguments took 1.52s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-07-24 17:45:32,496:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.32s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 17:45:32,887:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.39s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 17:45:46,039:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-24 17:45:48,414:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-24 17:45:50,063:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-24 17:45:50,162:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-24 17:46:08,994:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.51s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_transform(

2023-07-24 17:46:10,635:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:108: UserWarning: Persisting input arguments took 0.52s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-07-24 17:46:11,376:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 17:46:16,653:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-24 17:46:17,833:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-24 17:46:22,841:INFO:Calculating mean and std
2023-07-24 17:46:22,863:INFO:Creating metrics dataframe
2023-07-24 17:46:23,511:INFO:Uploading results into container
2023-07-24 17:46:23,512:INFO:Uploading model into container now
2023-07-24 17:46:23,514:INFO:_master_model_container: 2
2023-07-24 17:46:23,514:INFO:_display_container: 2
2023-07-24 17:46:23,517:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-07-24 17:46:23,517:INFO:create_model() successfully completed......................................
2023-07-24 17:46:24,863:INFO:SubProcess create_model() end ==================================
2023-07-24 17:46:24,864:INFO:Creating metrics dataframe
2023-07-24 17:46:24,924:INFO:Initializing Naive Bayes
2023-07-24 17:46:24,927:INFO:Total runtime is 2.3694116512934364 minutes
2023-07-24 17:46:24,969:INFO:SubProcess create_model() called ==================================
2023-07-24 17:46:24,969:INFO:Initializing create_model()
2023-07-24 17:46:24,970:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbbbaf03400>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbba354df10>, model_only=True, return_train_score=False, kwargs={})
2023-07-24 17:46:24,970:INFO:Checking exceptions
2023-07-24 17:46:24,970:INFO:Importing libraries
2023-07-24 17:46:24,977:INFO:Copying training dataset
2023-07-24 17:46:25,020:INFO:Defining folds
2023-07-24 17:46:25,021:INFO:Declaring metric variables
2023-07-24 17:46:25,113:INFO:Importing untrained model
2023-07-24 17:46:25,137:INFO:Naive Bayes Imported successfully
2023-07-24 17:46:25,200:INFO:Starting cross validation
2023-07-24 17:46:25,208:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-24 17:46:27,479:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.51s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_transform(

2023-07-24 17:46:29,595:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.82s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-07-24 17:46:29,970:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-07-24 17:46:30,028:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.69s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-07-24 17:46:30,703:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 17:46:31,435:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-24 17:46:33,460:WARNING:/Users/iremkurt/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-07-24 18:09:45,297:INFO:Initializing predict_model()
2023-07-24 18:09:45,297:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=PassiveAggressiveRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fcb91cff550>)
2023-07-24 18:09:45,297:INFO:Checking exceptions
2023-07-24 18:09:45,297:INFO:Preloading libraries
2023-07-24 18:09:45,303:INFO:Set up data.
2023-07-24 18:09:45,341:INFO:Set up index.
2023-07-24 18:11:00,842:INFO:Initializing predict_model()
2023-07-24 18:11:00,843:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=PassiveAggressiveRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fcb913af700>)
2023-07-24 18:11:00,843:INFO:Checking exceptions
2023-07-24 18:11:00,843:INFO:Preloading libraries
2023-07-24 18:11:00,845:INFO:Set up data.
2023-07-24 18:11:00,871:INFO:Set up index.
2023-07-24 18:12:09,239:INFO:Initializing predict_model()
2023-07-24 18:12:09,241:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=PassiveAggressiveRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fcb90bbeca0>)
2023-07-24 18:12:09,241:INFO:Checking exceptions
2023-07-24 18:12:09,241:INFO:Preloading libraries
2023-07-24 18:12:09,244:INFO:Set up data.
2023-07-24 18:12:09,278:INFO:Set up index.
2023-07-24 18:13:42,997:INFO:Initializing predict_model()
2023-07-24 18:13:42,998:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=PassiveAggressiveRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fcb762e21f0>)
2023-07-24 18:13:42,998:INFO:Checking exceptions
2023-07-24 18:13:42,999:INFO:Preloading libraries
2023-07-24 18:13:43,006:INFO:Set up data.
2023-07-24 18:13:43,035:INFO:Set up index.
2023-07-24 18:13:57,061:INFO:Initializing predict_model()
2023-07-24 18:13:57,061:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=PassiveAggressiveRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fcb91cff550>)
2023-07-24 18:13:57,061:INFO:Checking exceptions
2023-07-24 18:13:57,061:INFO:Preloading libraries
2023-07-24 18:13:57,065:INFO:Set up data.
2023-07-24 18:13:57,092:INFO:Set up index.
2023-07-24 18:14:11,769:INFO:Initializing predict_model()
2023-07-24 18:14:11,769:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=PassiveAggressiveRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fcb762e2700>)
2023-07-24 18:14:11,770:INFO:Checking exceptions
2023-07-24 18:14:11,770:INFO:Preloading libraries
2023-07-24 18:14:11,772:INFO:Set up data.
2023-07-24 18:14:11,800:INFO:Set up index.
2023-07-24 18:14:51,416:INFO:Initializing predict_model()
2023-07-24 18:14:51,417:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=PassiveAggressiveRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fcb903e7700>)
2023-07-24 18:14:51,417:INFO:Checking exceptions
2023-07-24 18:14:51,418:INFO:Preloading libraries
2023-07-24 18:14:51,421:INFO:Set up data.
2023-07-24 18:14:51,455:INFO:Set up index.
2023-07-24 18:16:37,378:INFO:Initializing predict_model()
2023-07-24 18:16:37,380:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=PassiveAggressiveRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fcb91cff550>)
2023-07-24 18:16:37,380:INFO:Checking exceptions
2023-07-24 18:16:37,380:INFO:Preloading libraries
2023-07-24 18:16:37,382:INFO:Set up data.
2023-07-24 18:16:37,415:INFO:Set up index.
2023-07-24 18:16:43,644:INFO:Initializing predict_model()
2023-07-24 18:16:43,644:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=PassiveAggressiveRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fcb90531af0>)
2023-07-24 18:16:43,644:INFO:Checking exceptions
2023-07-24 18:16:43,644:INFO:Preloading libraries
2023-07-24 18:16:43,647:INFO:Set up data.
2023-07-24 18:16:43,678:INFO:Set up index.
2023-07-24 18:17:02,734:INFO:Initializing predict_model()
2023-07-24 18:17:02,735:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=PassiveAggressiveRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fcb912e51f0>)
2023-07-24 18:17:02,736:INFO:Checking exceptions
2023-07-24 18:17:02,736:INFO:Preloading libraries
2023-07-24 18:17:02,738:INFO:Set up data.
2023-07-24 18:17:02,770:INFO:Set up index.
2023-07-24 18:17:26,039:INFO:Initializing predict_model()
2023-07-24 18:17:26,040:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=PassiveAggressiveRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fcb762e2160>)
2023-07-24 18:17:26,040:INFO:Checking exceptions
2023-07-24 18:17:26,040:INFO:Preloading libraries
2023-07-24 18:17:26,057:INFO:Set up data.
2023-07-24 18:17:26,103:INFO:Set up index.
2023-07-24 18:17:39,843:INFO:Initializing predict_model()
2023-07-24 18:17:39,845:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=PassiveAggressiveRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fcb762e2430>)
2023-07-24 18:17:39,845:INFO:Checking exceptions
2023-07-24 18:17:39,845:INFO:Preloading libraries
2023-07-24 18:17:39,855:INFO:Set up data.
2023-07-24 18:17:39,903:INFO:Set up index.
2023-07-24 18:18:34,212:INFO:Initializing predict_model()
2023-07-24 18:18:34,213:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=PassiveAggressiveRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fcb762e2310>)
2023-07-24 18:18:34,213:INFO:Checking exceptions
2023-07-24 18:18:34,213:INFO:Preloading libraries
2023-07-24 18:18:34,216:INFO:Set up data.
2023-07-24 18:18:34,307:INFO:Set up index.
2023-07-24 18:19:17,914:INFO:Initializing predict_model()
2023-07-24 18:19:17,915:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=PassiveAggressiveRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fcb762e2700>)
2023-07-24 18:19:17,915:INFO:Checking exceptions
2023-07-24 18:19:17,916:INFO:Preloading libraries
2023-07-24 18:19:17,923:INFO:Set up data.
2023-07-24 18:19:17,955:INFO:Set up index.
2023-07-24 18:19:26,805:INFO:Initializing predict_model()
2023-07-24 18:19:26,806:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=PassiveAggressiveRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fcb75305670>)
2023-07-24 18:19:26,806:INFO:Checking exceptions
2023-07-24 18:19:26,806:INFO:Preloading libraries
2023-07-24 18:19:26,830:INFO:Set up data.
2023-07-24 18:19:26,867:INFO:Set up index.
2023-07-24 18:19:50,826:INFO:Initializing predict_model()
2023-07-24 18:19:50,831:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=PassiveAggressiveRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fcb91d25ee0>)
2023-07-24 18:19:50,831:INFO:Checking exceptions
2023-07-24 18:19:50,831:INFO:Preloading libraries
2023-07-24 18:19:50,838:INFO:Set up data.
2023-07-24 18:19:50,908:INFO:Set up index.
2023-07-24 18:20:14,350:INFO:Initializing predict_model()
2023-07-24 18:20:14,351:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcb90954e80>, estimator=PassiveAggressiveRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fcb91cff550>)
2023-07-24 18:20:14,351:INFO:Checking exceptions
2023-07-24 18:20:14,351:INFO:Preloading libraries
2023-07-24 18:20:14,353:INFO:Set up data.
2023-07-24 18:20:14,394:INFO:Set up index.
